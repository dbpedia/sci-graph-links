<http://www.springernature.com/scigraph/things/articles/5ba26caa382333190e03c924802857e0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Applying a spatial competition model to banking, we analyze the effects of the choice of a monetary policy rule by the central bank on banks’ market power as measured by the Lerner index. We show that a procyclical monetary policy may reinforce the countercyclical movement of the Lerner index. That is, this measure of competitiveness of the banking sector may vary more over the business cycle due to the monetary policy rule." .
<http://www.springernature.com/scigraph/things/articles/4cbb04c2c1c8eca5aed7142fd83f6d57> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article investigates the behavior of real exchange rates under fixed and flexible exchange rates. Using data from both the Bretton Woods and the modern floating periods, we decompose real exchange rate movements into components attributable to supply shocks, real demand shocks, monetary shocks, capital flows shocks, and real oil price shocks. Empirical results show that real demand shocks are an important source of real exchange rate movements under both fixed and flexible rates, while monetary shocks are negligible. Supply and oil price shocks seem to be more important under Bretton Woods, while capital flows shocks seem to explain a relatively higher proportion of real exchange rate movements under the modern floating period." .
<http://www.springernature.com/scigraph/things/articles/5bb5b4d2481dcf98d5c2c26fc62ba992> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Modeling and forecasting of time series data are integral parts of many scientific and engineering applications. Increasing precision of the performed forecasts is highly desirable but a difficult task, facing a number of mathematical as well as decision-making challenges. This paper presents a novel approach for linearly combining multiple models in order to improve time series forecasting accuracy. Our approach is based on the assumption that each future observation of a time series is a linear combination of the arithmetic mean and median of the forecasts from all participated models together with a random noise. The proposed ensemble is constructed with five different forecasting models and is tested on six real-world time series. Obtained results demonstrate that the forecasting accuracies are significantly improved through our combination mechanism. A nonparametric statistical analysis is also carried out to show the superior forecasting performances of the proposed ensemble scheme over the individual models as well as a number of other forecast combination techniques." .
<http://www.springernature.com/scigraph/things/articles/d02d19b822f234f71b4795e56efd21d2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The objective of this paper is to examine the spatial distribution of several precipitation indexes in Sierra Nevada, Spain: mean annual number of wet days (R ≥ 1 mm), mean annual number of heavy rainy days (R ≥ 10 mm) and mean annual number of very heavy precipitation days (R ≥ 20 mm) and test the performance of several interpolation methods using these variables. In total, 17 univariate and multivariate methods were tested. A set of 36 metereological stations distributed in Sierra Nevada and neighbouring areas was analysed in this study. The original data did not followed the normal distribution; thus, a logarithm was applied to data meet normality purposes. Interpolator’s performance was assessed using the root mean square error generated from cross-validation. The results showed that the mean annual R ≥ 10 mm and R ≥ 20 mm have a higher variability than R ≥ 1 mm. While the elevation and longitude did not show a significant correlation with the studied indexes, the latitude (i.e. distance to the sea) showed a significant negative correlation. The regressions carried out confirmed that elevation was the covariate with higher capacity to explain the variability of the indexes. The incorporation of elevation and longitude slightly increased the explanation capacity of the models. The data of LogR ≥ 1 mm, LogR ≥ 10 mm and LogR ≥ 20 mm displayed a clustered pattern, especially the last two indexes that also showed a strong spatial dependency attributed to the effects of local topography, slope, aspect and valley orientation. The best fitted variogram model to LogR ≥ 1 mm was the linear one while for the LogR ≥ 10 mm and LogR ≥ 20 mm, the Gaussian was the most appropriate. The best interpolator for LogR ≥ 1 mm was the local polinomyal with the power of 1, whereas for LogR ≥ 10 mm and LogR ≥ 20 mm, regression kriging (ROK) using as auxiliary variables the elevation, latitude and longitude was the most accurate. ROK methods significantly improved the interpolations accuracy, especially in LogR ≥ 10 mm and LogR ≥ 20 mm. Nevertheless, the covariates, when used as auxiliary information in ordinary kriging, did not improve the precision of the interpolation." .
<http://www.springernature.com/scigraph/things/articles/78fcebb6f44b4fc66dccf8dde41e3b81> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract  In this paper, the second of this series, traceability and uncertainty of measurement results by k0-INAA will be described. The role of k0-INAA as a back-up to relative INAA will be discussed." .
<http://www.springernature.com/scigraph/things/articles/5a1109cefa1bef5579ea668a11df5150> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Methods of interrelated forecasting of the regional outputs of individual branches, household income, and consumption are considered. The instrument for the analysis and prediction for the parameters of the region’s economic system is a closed input-output model based on endogenous indicators of household income and demand." .
<http://www.springernature.com/scigraph/things/articles/35209be3d30910590367c9881d6b6cbd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary: In this paper, we calculate a transaction–based price index for apartments in Paris (France). The heterogeneous character of real estate is taken into account using an hedonic model. The functional form is specified using a general Box–Cox function. The data basis covers 84 686 transactions of the housing market in 1990:01–1999:12, which is one of the largest samples ever used in comparable studies. Low correlations of the price index with stock and bond indices (first differences) indicate diversification benefits from the inclusion of real estate in a mixed asset portfolio." .
<http://www.springernature.com/scigraph/things/articles/9da4be1e8945621fbb358c0c11d29356> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract One method that is increasingly being used in health economics to elicit stated preferences concerning health matters is the discrete choice experiment (DCE). This editorial explores four sets of issues facing researchers who wish to employ DCE techniques: (a) normative issues about how data from DCE studies might be used to inform policy, (b) psychological issues concerning the meaningfulness of the data generated, (d) technical issues relating to how the data are generated and (d) issues relating to the generalisability of the data from DCE studies. Given current uncertainties surrounding these issues, it is our view that more caution and greater circumspection towards DCE is appropriate at this stage." .
<http://www.springernature.com/scigraph/things/articles/7df55add4d03e0bda62e57c4b9934274> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Inspired in dynamic systems theory and Brewer’s contributions to apply it to economics, this paper establishes a bond graph model. Two main variables, a set of inter-connectivities based on nodes and links (bonds) and a fractional order dynamical perspective, prove to be a good macro-economic representation of countries’ potential performance in nowadays globalization. The estimations based on time series for 50 countries throughout the last 50 decades confirm the accuracy of the model and the importance of scale for economic performance." .
<http://www.springernature.com/scigraph/things/articles/1ef0aa20dd42384303925d5167922b2c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Discrete choice model acts as one of the most important tools for studies involving mode split in the context of transport demand forecast. As different types of discrete choice models display their merits and restrictions diversely, how to properly select the specific type among discrete choice models for realistic application still remains to be a tough problem. In this article, five typical discrete choice models for transport mode split are, respectively, discussed, which includes multinomial logit model, nested logit model (NL), heteroscedastic extreme value model, multinominal probit model and mixed multinomial logit model (MMNL). The theoretical basis and application attributes of these five models are especially analysed with great attention, and they are also applied to a realistic intercity case of mode split forecast, which results indicating that NL model does well in accommodating similarity and heterogeneity across alternatives, while MMNL model serves as the most effective method for mode choice prediction since it shows the highest reliability with the least significant prediction errors and even outperforms the other four models in solving the heterogeneity and similarity problems. This study indicates that conclusions derived from a single discrete choice model are not reliable, and it is better to choose the proper model based on its characteristics." .
<http://www.springernature.com/scigraph/things/articles/1c089854f52cffddc0c0545dc219ad78> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Geographically weighted regression (GWR) is a popular technique to deal with spatially varying relationships between a response variable and predictors. Problems, however, have been pointed out (see Wheeler and Tiefelsdorf in J Geogr Syst 7(2):161–187, 2005), which appear to be related to locally poor designs, with severe impact on the estimation of coefficients. Different remedies have been proposed. We propose two regularization methods. The first one is generalized ridge regression, which can also be seen as an empirical Bayes method. We show that it can be implemented using ordinary GWR software with an appropriate choice of the weights. The second one augments the local sample as needed while running GWR. We illustrate both methods along with ordinary GWR on an example of housing prices in the city of Bilbao (Spain) and using simulations." .
<http://www.springernature.com/scigraph/things/articles/4c4431da3fb11972f9637edc47c14819> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper surveys various parametric Lorenz curves to be fitted to grouped income data in order to obtain an estimate for the Gini measure of inequality. The curves are fitted to 16 sets of empirical income data. The results are compared to the results of the purely nonparametric method (due to Gastwirth) of computing lower and upper bounds for the Gini measure. It is shown that most of the parametric curves are unreliable in that they may produce estimates outside the bounds." .
<http://www.springernature.com/scigraph/things/articles/9ac695445f15dc0eb70ed815799b6a2e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Bank lending to small firms in the U.S. fell substantially during the recent financial crisis and ensuing recession. Because small firms account for a disproportionate share of new job creation, lending to these firms could have important implications for the pace of economic recovery. This paper examines the extent to which changes in banks’ supervisory ratings are associated with changes in the growth rate of their lending to small businesses. We estimate the relationship between changes in small banks’ supervisory ratings and changes in their small commercial and industrial (C&I) or small commercial real estate (CRE) loans to businesses over 2007–2010. Controlling for a large set of other relevant factors, we find that small banks that experienced ratings downgrades during 2007–2010 exhibited significantly lower rates of growth in small C&I loans and small CRE loans outstanding compared with banks that maintained their ratings at healthy levels during the same period. We employ an innovative approach using the timing of bank exams to address the question of whether the slower growth in small business lending at downgraded banks is attributable mainly to aspects of the banks’ financial health that are not fully reflected in balance sheet data or to the ratings downgrades themselves. Our results suggest that the downgrades themselves did not directly influence bank lending to small businesses during this period." .
<http://www.springernature.com/scigraph/things/articles/8ef51c5547aabcb34a9dfdb2b61f3354> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. The paper provides a comparison of alternative univariate time series models that are advocated for the analysis of seasonal data. Consumption and income series from (West-) Germany, United Kingdom, Japan and Sweden are investigated. The performance of competing models in forecasting is used to assess the adequacy of a specific model. To account for nonstationarity first and annual differences of the series are investigated. In addition, time series models assuming periodic integration are evaluated. To describe the stationary dynamics (standard) time invariant parametrizations are compared with periodic time series models conditioning the data generating process on the season. Periodic models improve the in-sample fit considerably but in most cases under study this model class involves a loss in ex-ante forecasting relative to nonperiodic models. Inference on unit-roots indicates that the nonstationary characteristics of consumption and income data may differ. For German and Swedish data forecasting exercises yield a unique recommendation of unit roots in consumption and income data which is an important (initial) result for multivariate analysis. Time series models assuming periodic integration are parsimonious to specify but often involve correlated one-step-ahead forecast errors." .
<http://www.springernature.com/scigraph/things/articles/ee04dbf17126379b965f2d868f867094> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper extends the analytical and empirical application of the basic indirect utility function of Houthakker–Hanoch—called the CDES specification (constant differences of elasticities of substitution). The non-homothetic CDES preferences are the natural parametric extension on the global domain of the homothetic CES preferences with many commodities, and CDES can conveniently be used in specifying CGE multisector models with a demand side satisfying observable Engel curve patterns. Moreover, all Marshallian own-price elasticities are no longer restricted to exceed one, and positive and negative cross-price effects are allowed for in empirical demand analyses. Explicit calculations of the Allen elasticities of substitution are instrumental in demonstrating the economic implications of the parameters of indirect utility functions with global regularity properties and flexibility of the derived demand systems." .
<http://www.springernature.com/scigraph/things/articles/0ab326a5495c6a78120ed09b53f1928c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper we analyze the effects of restricted participation in a two-period general equilibrium model with incomplete financial markets and two key elements: the competitive trading of real assets, i.e., assets having payouts in terms of vectors of commodities, and household-specific inequality constraints that restrict participation in the financial markets. Similar to certain arrangements in the market for bank loans, household borrowing is restricted by a household-specific wealth dependent upper bound on credit lines in all states of uncertainty in the second period. We first establish that, generically in the set of the economies, equilibria exist and are finite and regular. We then show that equilibria are generically suboptimal. Finally, we provide a robust example demonstrating that the equilibrium allocations can be Pareto improved through a tightening of the participation constraints. This suggests, contrary to what is often cited as economic wisdom in the popular press, that in a setting with frictions resulting in an inefficient allocation the regulation of markets may have a Pareto-improving effect on the economy." .
<http://www.springernature.com/scigraph/things/articles/46cb5d4d31cf8828c5c8646d7c566030> <http://www.springernature.com/scigraph/ontologies/core/abstract> "We show that for any k-connected graph having cocircumference c*, there is a cycle which intersects every cocycle of size c*-k + 2 or greater. We use this to show that in a 2-connected graph, there is a family of at most c* cycles for which each edge of the graph belongs to at least two cycles in the family. This settles a question raised by Oxley. A certain result known for cycles and cocycles in graphs is extended to matroids. It is shown that for a k-connected regular matroid having circumference c ≥ 2k if C1 and C2 are disjoint circuits satisfying r(C1)+r(C2)=r(C1∪C2), then |C1|+|C2|≤2(c-k + 1)." .
<http://www.springernature.com/scigraph/things/articles/e66528511796ad67658613b4876edb77> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Pollen and spores are biological particles that are ubiquitous to the atmosphere and are pathologically significant, causing plant diseases and inhalant allergies. One of the main objectives of aerobiological surveys is forecasting. Prediction models are required in order to apply aerobiological knowledge to medical or agricultural practice; a necessary condition of these models is not to be chaotic. The existence of chaos is detected through the analysis of a time series. The time series comprises hourly counts of atmospheric pollen grains obtained using a Burkard spore trap from 1987 to 1989 at Mar del Plata. Abraham's method to obtain the correlation dimension was applied. A low and fractal dimension shows chaotic dynamics. The predictability of models for atomspheric pollen forecasting is discussed." .
<http://www.springernature.com/scigraph/things/articles/4daf61bd573ae779f785908fcc7a0e2e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Empirical studies of variations in debt ratios across firms have analyzed important determinants of capital structure using statistical models. Researchers, however, rarely employ nonlinear models to examine the determinants and make little effort to identify a superior prediction model among competing ones. This paper reviews the time-series cross-sectional (TSCS) regression and the predictive abilities of neural network (NN) utilizing panel data concerning debt ratio of high-tech industries in Taiwan. We built models with these two methods using the same set of measurements as determinants of debt ratio and compared the forecasting performance of five models, namely, three TSCS regression models and two NN models. Models built with neural network obtained the lowest mean square error and mean absolute error. These results reveal that the relationships between debt ratio and determinants are nonlinear and that NNs are more competent in modeling and forecasting the test panel data. We conclude that NN models can be used to solve panel data analysis and forecasting problems." .
<http://www.springernature.com/scigraph/things/articles/22bb9afc9b737b65137a5f7ef2e656ec> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The main objective of this paper is to control the geometry of null cones with time foliation in Einstein vacuum spacetime under the assumptions of small curvature flux and a weak condition on the deformation tensor for the future directed unit normal T to each leaf. We establish a series of estimates on Ricci coefficients, which play a crucial role to prove the improved breakdown criterion in Wang (Commun. Pure Appl. Math. 65(1):0021–0076, 2012)." .
<http://www.springernature.com/scigraph/things/articles/e0d4366b114d8fe334ed48741ebb3590> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This contribution seeks to measure preferences for health insurance of individuals with and without chronic conditions in two countries, Germany and the Netherlands. The objective is to test the presumption that preferences between these two subpopulations differ and to see whether having a chronic condition has a different influence on preferences depending on the country. The evidence comes from two Discrete Choice Experiments performed in 2005 (Germany) and 2006 (the Netherlands, right after a major health reform). Results point to an even more marked resistance against restrictions of physician choice among individuals with chronic conditions in both countries. Thus, the alleged beneficiaries of Disease Management Programs would have to be highly compensated for accepting the restrictions that go with them." .
<http://www.springernature.com/scigraph/things/articles/034da8a824f967644d9abdc2c72281e2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study examined the relationship between generic drug market shares and the number of reported side effects. Yearly time-series data for the number of reported side effects and information on market shares, prices, and quantities from 1972 to 1996 were used in this study. Poisson and negative binomial regression models were used in the statistical analysis. The results show that increased generic market share increases the number of reported side effects for all estimated models. When studying the relationship at the substance level, increasing generic market shares increases the number of side effects for 7 of the 15 substances. Generic substitution laws and measures to increase generic competition may thus have unintended consequences since these results show a positive relationship between generic market shares and reported side effects." .
<http://www.springernature.com/scigraph/things/articles/bdf0ede5642af1279b6b2f7473b5f59e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We use a replica approach to deal with portfolio optimization problems. A given risk measure is minimized using empirical estimates of asset values correlations. We study the phase transition which happens when the time series is too short with respect to the size of the portfolio. We also study the noise sensitivity of portfolio allocation when this transition is approached. We consider explicitely the cases where the absolute deviation and the conditional value-at-risk are chosen as a risk measure. We show how the replica method can study a wide range of risk measures, and deal with various types of time series correlations, including realistic ones with volatility clustering." .
<http://www.springernature.com/scigraph/things/articles/0e4a25e5363e07b4b2e5fc793e92ab36> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract For the investigation of the chatter modes, the power spectrum of the parametric time series model was adopted and analyzed at several mixed conditions of different revolution. This paper describes a methodology for an application of several time series such asAR (forward-backward, burg, least square, Yule Walker, geometric lattice, instrumental variable),ARX (least square, instrumental variable),ARMAX, ARMA, Box Jenkins, Output Error. To estimate the chatter mode using their spectral analysis their results were compared with one another. As a result, it was proven that several time series methods can be used for chatter mode estimation. Among them, theARX, ARMAX and instrumental variable methods (iv4) are more desirable and reliable than the other algorithm for the exact calculation of the chatter mode in endmilling. Among three cutting forces, the z direction cutting force,Fz, has more powerful characteristics of chatter occurring than the cutting forces,Fx andFy, in the sense that weak mode is calculated exactly and there is no shifted or pseudo mode in the estimated power spectra of endmilling forces." .
<http://www.springernature.com/scigraph/things/articles/d1ac264ded9ad9f6767ead0ba37af4fb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Detrending is a widely used technique for obtaining stationary time series data in residual analysis and risk assessment. The technique is frequently applied in crop yield risk assessment and insurance ratings. Although several trend models have been proposed in the literature, whether these models achieve consistent detrending results and successfully extract the true yield trends is rarely discussed. In the present article, crop insurance pricing is evaluated by different trend models using real and historical yield data, and hypothetical yield data generated by Monte Carlo simulations. Applied to real historical data, the linear, loglinear, autoregressive integrated moving average trend models produce different risk assessment results. The differences among the model outputs are statistically significant. The largest deviation in the county crop assessment reaches 6–8 %, substantially larger than the present countrywide gross premium rate of 5–7 %. In performance tests on simulated yield trends, popular detrending methods based on smoothing techniques proved overall superior to linear, loglinear, and integrated autoregression models. The best performances were yielded by the moving average and robust locally weighted regression models." .
<http://www.springernature.com/scigraph/things/articles/e40b192290323912280da395993da0a0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract According to proponents of zero-inflation policies, even low rates of inflation create distortions in capital allocation and in price signals, which result in lower rates of productivity growth. This paper tests the hypothesis that inflation has a causal impact (in the Granger sense) on labor productivity growth in manufacturing for 12 countries of the Organization for Economic Cooperation and Development (OECD). In bivariate tests of inflation and productivity and in multivariate tests using controls for cyclical effects, there is no evidence of a consistent relationship between inflation and productivity growth with regard to either sign or magnitude. Therefore, the present analysis does not support the view that further reductions in inflation from already low single-digit levels would have a positive impact on labor productivity growth for major industrial countries." .
<http://www.springernature.com/scigraph/things/articles/f458312b14e821ad986b80d7cd7b0cb3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper we reconsider the degree of international comovement of inflation rates. We use a dynamic hierarchical factor model that is able to decompose Consumer Price Index (CPI) inflation in a panel of countries into (i) a factor common to all inflation series and all countries, (ii) a factor specific to a given sub-section of the CPI, (iii) a country group-factor and (iv) a country-specific component. With its pyramidal structure, the model allows for the possibility that the global factor affects the country-group factor and other subordinated factors but not vice versa. Using quarterly data for industrialized and emerging economies from 1996 to 2011 we find that about two thirds of overall inflation volatility is due to country-specific determinants. For CPI inflation net of food and energy, the global factor and the CPI basket-specific factor account for less than 20 % of inflation variation. Only energy price inflation in industrial economies is dominated by common factors." .
<http://www.springernature.com/scigraph/things/articles/95d3ea2898ac8a6b6db739cbf48bec14> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The R / S statistic is used to detect long-range dependence in a time series and to estimate its intensity. One of its virtues is robustness against different distributions. We show here that the R / S statistic continues to be robust if the time series is a moving average with long-range dependence with innovations that are in the domain of attraction of an infinite variance stable process." .
<http://www.springernature.com/scigraph/things/articles/cfa2de242ce6c6dad6a829d711b1c93d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper elaborates upon the effect of political stability on economic growth using a novel approach. Unlike the literature on growth that emphasizes the turnover of decision makers, this paper focuses on the volatility of economic policies as the relevant indicator of stability. The literature on growth ignores the microeconomic instability associated with frequent changes of government policies. The empirical results of this paper indicate that the effect of political instability on economic growth is not conclusive. Most of the commonly used proxies for political instability have failed to explain growth differences across countries. The political instability indices have no significant effect on growth when a reasonable set of core variables is also included in the regression equation. The results also show that almost all of the policy uncertainty variables are significantly and negatively correlated with economic growth. However, the instability of economic policies has no significant impact on the accumulation of capital." .
<http://www.springernature.com/scigraph/things/articles/e3d7171641e464c96fc0a09a7363129c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper demonstrates effects of economic convergence processes on the foreign exchange behaviour in a monetary modelling approach. Since the exchange rate represents the relative price of two currencies, commonness of stochastic trends between the fundamental determinants of supply and demand of the underlying monies restricts exchange rate movements to transitory fluctuations. In the spirit of optimal currency areas, this has the potential to serve as a criterion for an all-round integration of two economies. Empirically, such a constellation is found between Australia and New Zealand, whereas diverging trends in money and interest rates characterise the relation of Australia towards the US." .
<http://www.springernature.com/scigraph/things/articles/783675d255dfc3566e8f30343f0c8bc7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We use several models using classical and Bayesian methods to forecast employment for eight sectors of the US economy. In addition to using standard vector-autoregressive and Bayesian vector autoregressive models, we also augment these models to include the information content of 143 additional monthly series in some models. Several approaches exist for incorporating information from a large number of series. We consider two multivariate approaches—extracting common factors (principal components) and Bayesian shrinkage. After extracting the common factors, we use Bayesian factor-augmented vector autoregressive and vector error-correction models, as well as Bayesian shrinkage in a large-scale Bayesian vector autoregressive models. For an in-sample period of January 1972 to December 1989 and an out-of-sample period of January 1990 to March 2010, we compare the forecast performance of the alternative models. More specifically, we perform ex-post and ex-ante out-of-sample forecasts from January 1990 through March 2009 and from April 2009 through March 2010, respectively. We find that factor augmented models, especially error-correction versions, generally prove the best in out-of-sample forecast performance, implying that in addition to macroeconomic variables, incorporating long-run relationships along with short-run dynamics play an important role in forecasting employment. Forecast combination models, however, based on the simple average forecasts of the various models used, outperform the best performing individual models for six of the eight sectoral employment series." .
<http://www.springernature.com/scigraph/things/articles/13281b463043a6ab38d06a7dc6c25623> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The role of recommended prices, especially when used as a basis from which traders may claim price reductions, has received unfavourable comment from several sources in Britain in recent years. It has been claimed that they are likely to cause economic detriment to consumers. Proposals have been made to prohibit the use of recommended prices either generally or on specific products. This paper reviews the general issues concerning the role of recommended prices and the major official reports produced on this question. The author argues that, contrary to the proposals at present under consideration, the economic interests of consumers are, on balance, more likely to be enhanced by the continuation of the use of recommended prices rather than their prohibition. However some controls on the use of recommended prices may be required and suggestions for policy developments are made." .
<http://www.springernature.com/scigraph/things/articles/5f99c026ee5b1da8ba0ce552a3b8a659> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we apply empirical likelihood method to study the semi-parametric varying-coefficient partially linear errors-in-variables models. Empirical log-likelihood ratio statistic for the unknown parameter β, which is of primary interest, is suggested. We show that the proposed statistic is asymptotically standard chi-square distribution under some suitable conditions, and hence it can be used to construct the confidence region for the parameter β. Some simulations indicate that, in terms of coverage probabilities and average lengths of the confidence intervals, the proposed method performs better than the least-squares method. We also give the maximum empirical likelihood estimator (MELE) for the unknown parameter β, and prove the MELE is asymptotically normal under some suitable conditions." .
<http://www.springernature.com/scigraph/things/articles/f7e1e7f5b98e64c6998f6840a7d6e545> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Water level forecasting using recorded time series can provide a local modelling capability to facilitate local proactive management practices. To this end, hourly sea water level time series are investigated. The records collected at the Hillarys Boat Harbour, Western Australia, are investigated over the period of 2000 and 2002. Two modelling techniques are employed: low-dimensional dynamic model, known as the deterministic chaos theory, and genetic programming, GP. The phase space, which describes the evolution of the behaviour of a nonlinear system in time, was reconstructed using the delay-embedding theorem suggested by Takens. The presence of chaotic signals in the data was identified by the phase space reconstruction and correlation dimension methods, and also the predictability into the future was calculated by the largest Lyapunov exponent to be 437 h or 18 days into the future. The intercomparison of results of the local prediction and GP models shows that for this site-specific dataset, the local prediction model has a slight edge over GP. However, rather than recommending one technique over another, the paper promotes a pluralistic modelling culture, whereby different techniques should be tested to gain a specific insight from each of the models. This would enable a consensus to be drawn from a set of results rather than ignoring the individual insights provided by each model." .
<http://www.springernature.com/scigraph/things/articles/760705d73033d6a9ab6ddb79816fe4fc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The bookCapital Flows and Financial Crises contains nine scholarly essays written by authors such as Barry Eichengreen, Albert Fishlow, Carrmen M. Reinhart, Vincent Raymond Reinhart, and Jeffrey D. Sachs. The essays are grounded in reality and include a detailed review of capital control usage in emerging countries. Four of the essays are case studies that explain how different conditions and levels of development may lead to different policies with varying degrees of success.Capital Flows and Financial Crises encourages economists to consider the particulars of a developing country before applying an economic cure, reexamines accepted economic theory in light of recent financial crises, and suggests a more moderate approach to financial liberalization given the inefficiencies and lack of regulation in emerging markets." .
<http://www.springernature.com/scigraph/things/articles/77b0a48d0e1f0a19b72d86127b841005> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The present paper attempts an empirical investigation on price volatility linkages between two important agricultural commodities: corn and wheat, by using a multivariate GARCH-BEKK model. Evidence of bidirectional linkages were found between corn and wheat in terms of returns and volatility. Multivariate conditional Student’s-t distribution results show a unidirectional volatility transmission from corn to wheat. Diagnostic tests reveal that the Student’s-t distribution will better model the volatility of returns when compared to the Gaussian distribution. Overall, the results show that the conditional variances and covariances between agricultural commodity market returns exhibit significant changes over time." .
<http://www.springernature.com/scigraph/things/articles/b0666bcaca23d1cf2fd7db361de3d09c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper provides evidence that forecasts based on global stock returns transmission yield better returns in day trading, for both developed and emerging stock markets. The study investigates the performance of global stock market price transmission information in forecasting stock prices using support vector regression for six global markets—USA (Dow Jones, S&P500), UK (FTSE-100), India (NSE), Singapore (SGX), Hong Kong (Hang Seng) and China (Shanghai Stock Exchange) over the period 1999–2011. The empirical analysis shows that models with other global market price information outperform forecast models based merely on auto-regressive past lags and technical indicators. Shanghai stock index movement was predicted best by Hang Seng Index opening price (57.69), Hang Seng Index by previous day’s S&P500 closing price (54.34), FTSE by previous day’s S&P500 closing price (57.94), Straits Times Index by previous day’s Dow Jones closing price (54.44), Nifty by HSI opening price (60), S&P500 by STI closing price (55.31) and DJIA by HSI opening price (55.22), and Nifty was found to be the most predictable stock index. Trading using global cues-based forecast model generates greater returns than other models in all the markets. The study provides evidence that stock markets across the globe are integrated and the information on price transmission across markets, including emerging markets, can induce better returns in day trading." .
<http://www.springernature.com/scigraph/things/articles/2c422568ea9b72fa716cff28ef059935> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Economic liberalization creates potential instability in money demand. The introduction of liberalization in the early 1990s coincided with instability in the long-run demand for broad money (M2). OLS estimates confirm the presence of a structural break in the M2 model. Monetary policy should be based on a narrow definition of money. Moreover, the demand for money function must take explicit account of the openness of the economy. The results have important implications for policymakers in other Caribbean countries that are contemplating economic liberalization." .
<http://www.springernature.com/scigraph/things/articles/653141b1402c29c4de4882cf819f06a1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract After introducing the main topic of this paper (the study of purchase incidence and brand choice decisions) we explain basic concepts of hazard models and describe the probability distributions considered in the empirical study presented later. After a review of pure purchase incidence (product category) models as well as integrated models that include brand choice as well, we specify and discuss properties of one-state and multi-state hazard models, respectively. Our conclusions are based on applying hazard models to household scanner data." .
<http://www.springernature.com/scigraph/things/articles/b117a2d307ff748bf6bacface005ee7c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Volatility plays a key role in microstructure issues in the study of financial markets. Stochastic volatility (SV) models have been applied to the study of the behavior of financial variables. Two stock markets exist in China: Shanghai Stock Exchange and Shenzhen Stock Exchange. As emerging stock markets, investors are increasingly concerned about the volatilities of these two stock markets. We briefly introduce how to estimate SV models using the Markov chain Monte Carlo (MCMC) method. In order to do full and comprehensive analyses of the volatilities of stock returns, we estimated SV models using most of the historical data and the different data frequencies of the two Chinese markets. We found that estimated values of volatility parameters are very high for all data frequencies. This suggests that stock returns are extremely volatile even at long-term intervals in Chinese markets." .
<http://www.springernature.com/scigraph/things/articles/71079ae645bf8a433f7d157fb5ea995c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Data envelopment analysis (DEA) is an approach for measuring the relative efficiency of peer decision making units that have multiple inputs and outputs. In most practical applications of DEA presented in the literature, the presented models assume that outputs are produced perfectly (see Charnes et al. Eur J Oper Res 2:429–444, 1978). However, in many real situations, some outputs are imperfect and they need to be repaired. This paper develops a DEA approach for measuring the efficiency of decision processes which can be divided into two interdependent stages, arranged in series. The novelty of the proposed approach is the existence of perfect and imperfect outputs in a two-stage decision process. This application of two-stage process involves shared resources and the paper gives a best split of these shared resources between two stages. The case of Iranian car representatives is presented." .
<http://www.springernature.com/scigraph/things/articles/e83aaabae7f363ea28ad02a92b6fe4b3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper presents and analyses appraisal methods used for the assessment of potential investments in Nodal Centers for Goods (also called Freight Villages), which constitute an essential element of the Trans-European Network for Intermodal Transport. A methodological procedure is applied to identify the underlying factors that influence the choice of an appraisal method, without assessing or comparing the appraisal methods themselves. Following this procedure, issues addressed by the methods are grouped into three broad dimensions and with the use of non-parametric statistical tests, existing relationships are identified between nodal centres' characteristics, the appraisal methods, as well as the actors involved in the decision process. On applying the above procedure to European Nodal Centres for goods, it is found that the choice of appraisal method and the decision criteria for the investment are linked primarily to the nodal centre's size, catchment area, and the support or absence of political approval for the investment. The results of the analysis can be particularly useful at the policy making level, serving as non-formal \"qualitative guidelines\" to identify the appraisal method to be applied, as well as the options and impacts to be considered." .
<http://www.springernature.com/scigraph/things/articles/5ea54efa8e38282a321897b3fe1f056a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Empirical findings point out that the scaling and multiscaling properties can be found in many dealer markets. But how do these properties emerge from these financial markets? What are the dynamical causes for these nonlinear properties? Are they the results of random perturbations, or of the intrinsic characteristics of the markets? To answer these questions, first of all, I proposed a minimally structured agent-based model of a dealer market, and then conducted many experiments under several scenarios. This artificial financial market is occupied with heterogeneous agents characterized with bounded rationality and heterogeneity, and a dealer who is responsible for market liquidity and supply-demand balance. By means of simulations based on different scenarios, trading time series (prices, volumes, volatilities, etc) are generated and then are analyzed by Multi-Fractal Detrended Fluctuation Analysis (MF-DFA). Interestingly, the generated price series display scaling and multiscaling features, which is consistent with empirical findings in the real markets. Furthermore, the plausible explanation for these properties is nonlinear temporal correlation instead of probability distribution after the series are shuffled and phase randomized. All of the results imply that these properties of nonlinearity may derive from market participants’ heterogeneity and mutual interactions; thereby, they may be the underlying characteristics of dealer markets." .
<http://www.springernature.com/scigraph/things/articles/6e6d4a8f004778f1c673859bd984e437> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, under some fairly general conditions, a first-order Edgeworth expansion for the standardized statistic of β in partial linear models is given, then a non-residual type of consistent estimation for the error variance is constructed, and finally an Edgeworth expansion for the corresponding studentized version is presented." .
<http://www.springernature.com/scigraph/things/articles/21f9d16c5af08d9414f927e99c193394> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The problem of finding the best-possible lower bound on the distribution of a non-decreasing function of n dependent risks is solved when n=2 and a lower bound on the copula of the portfolio is provided. The problem gets much more complicated in arbitrary dimensions. When no information on the structure of dependence of the random vector is available, we provide a bound on the distribution function of the sum of risks which we prove to be better than the one generally used in the literature." .
<http://www.springernature.com/scigraph/things/articles/4b94b796aecd08b41b655046483ecb9c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Have tax policies affected entrepreneurial activity in the U.S.? We extend the time series literature on this topic by using more recent data and modern econometric techniques to examine the importance of federal income, payroll, capital gains, corporate income, and estate taxes on self-employment rates. Regression results show that most of these taxes have significant but small effects on self-employment activity. A battery of cointegration and causality tests confirms the general finding that taxes can have significant influences on entrepreneurship, but they are likely to be ineffective tools for generating meaningful changes in entrepreneurial activity." .
<http://www.springernature.com/scigraph/things/articles/f5a078246d090cb0918e89c44e7681fa> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper introduces two new characterizations of the top trading cycles algorithm. The key to our characterizations is a new condition, independence of irrelevant rankings (IIR). Intuitively, a mechanism satisfies IIR if whenever an agent’s ranking at an object is irrelevant to her assignment, then it is irrelevant to the assignment of all agents. We demonstrate that a mechanism is Pareto efficient, strategy-proof, IIR, and satisfies mutual best if and only if it is top trading cycles. This provides a new insight into what distinguishes top trading cycles from all other efficient and strategy-proof assignment mechanisms. We provide a second characterization in terms of weak Maskin monotonicity. A mechanism satisfies Pareto efficiency, weak Maskin monotonicity, IIR, and mutual best if and only if it is top trading cycles. This allows us to directly compare top trading cycles to known characterizations of the deferred acceptance algorithm in terms of weak Maskin monotonicity." .
<http://www.springernature.com/scigraph/things/articles/743fbfddd56f0b4a82a70f81b5044fea> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper proposes a method to design freezing damage policy-based agricultural insurance contracts for tea trees (an economic crop) in the Zhejiang Province of China, using a weather index. Data of economic losses caused by freezing damage, and the beginning dates of tea plucking (BDTP) from the Agricultural Bureau of each county in Zhejiang Province and tea planters, and meteorological observations were collected to establish the prediction model for BDTP, and to determine the relationship between economic loss rates caused by freezing damage at or before BDTP, and the minimum temperatures for “Wuniuzao,” “Longjing-43,” and “Jiukeng” teas. Based on the information diffusion theoretical model, occurrence probabilities of BDTP from 1 February to 20 April and lower temperatures at different levels are calculated. Then, the insurance premium rates of the three tea tree species can be estimated. Lastly, the tea tree freezing damage insurance contracts are designed, combining the advantages of regional yield-based index insurance and weather-based index insurance." .
<http://www.springernature.com/scigraph/things/articles/9c89c38e3c0a96318f1c4644db0e899a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Reliable forecasting of the next eruption at Vesuvius is the main scientific factor in defining effective strategies to reduce volcanic risk in one of the most dangerous volcanic areas of the world. In this paper, we apply a recently developed probabilistic code for eruption forecasting to new and independent historical data related to the pre-eruptive phase of the 1631 eruption. The results obtained point out three main issues: (1) the importance of “cold” historical data (according to Guidoboni 2008) related to pre-eruptive phases for evaluating forecasting tools and possibly refining them; (2) the BET_EF code implemented for Vesuvius would have forecasted the 1631 eruption satisfactorily, marking different stages of the pre-eruptive phase; (3) the code shows that pre-eruptive signals that significantly increase the probability of eruption were likely detected more than 2 months before the event." .
<http://www.springernature.com/scigraph/things/articles/6daeaad298ef09eb81539b360754c40c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper examines the choices for fiscal stabilisation policy that maximise aggregate welfare and long-run growth. This is done in the context of a stochastic dynamic general equilibrium model where premeditated learning provides the engine of human capital accumulation and growth, and technology shocks provide the impulse source of fluctuations. Contrary to existing conventional wisdom, the results indicate a conflict between the two policy objectives: the choice of no stabilisation, associated with maximum growth, is also associated with minimum welfare. Welfare maximisation requires a full counter-cyclical response to the occurrence of business cycles." .
<http://www.springernature.com/scigraph/things/articles/8751c9b97b6e75dcf70597e65382849c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract There is a growing focus on the economics of adaptation as policy moves from theory to practice. However, the techniques commonly used in economic appraisal have limitations in coping with climate change uncertainty. While decision making under uncertainty has gained prominence, economic appraisal of adaptation still uses approaches such as deterministic cost-benefit analysis. Against this background, this paper provides a critical review and assessment of existing economic decision support tools (cost-benefit analysis and cost-effectiveness analysis) an uncertainty framework (iterative risk management) and alternative tools that more fully incorporate uncertainty (real options analysis, robust decision making and portfolio analysis). The paper summarises each method, provides examples, and assesses their strengths and weaknesses for adaptation. The tools are then compared to identify key differences, and to identify when these approaches might be appropriate for specific applications in adaptation decision making." .
<http://www.springernature.com/scigraph/things/articles/07ac53280473a4c81863bff8fecbb969> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We perform non-linearity tests using daily data for leading currencies that include the Australian dollar, British pound, Brazilian real, Canadian dollar, euro, Japanese yen, Mexican peso, and the Swiss franc to resolve the issue of whether these currencies are driven by fundamentals or exogenous shocks to the global economy. In particular, we use a new method of testing for linear and nonlinear lead/lag relationships between time series, introduced by Brooks and Hinich (J Empir Finance 20:385–404, 1999), based on the concepts of cross-correlation and cross-bicorrelation. Our evidence points to a relatively rare episodic nonlinearity within and across foreign exchange rates. We also test the validity of specifying ARCH-type error structures for foreign exchange rates. In doing so, we estimate Bollerslev’s (J Econom 31:307–327, 1986) generalized ARCH (GARCH) model and Nelson’s (1988) exponential GARCH (EGARCH) model, using a variety of error densities [including the normal, the Student-t distribution, and the Generalized Error Distribution (GED)] and a comprehensive set of diagnostic checks. We apply the Brooks and Hinich (1999) nonlinearity test to the standardized residuals of the optimal GARCH/EGARCH model for each exchange rate series and show that the nonlinearity in the exchange rates is not due to ARCH-type effects. This result has important implications for the interpretation of the recent voluminous literature which attempts to model financial asset returns using this family of models." .
<http://www.springernature.com/scigraph/things/articles/3ba3fb2c25283a581303f916b1d38614> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper investigates patterns of daily evolutions of CO2 in the lower atmosphere at a rural site over 2 years. The first part is devoted to observation analysis using a clustering procedure. However, direct application of the average-linkage method yielded undesirable results. In order to improve this procedure, data were previously processed using three smoothing procedures: the kernel smoothing method, the elliptical procedure, and the second-order cylindrical model. These procedures successfully revealed that clusters were based on daily concentration and range. However, the unequal distribution of frequencies in the clusters proved to be a noticeable disadvantage. Four alternative and simpler schemes for grouping observations were proposed in the second part of this paper. The first, comprising groups following fixed values of daily range and mean concentration, provided a sharp contrast between spring, with a marked daily cycle linked to the biological peak, and summer with a smooth daily cycle and low concentration when the biological minimum was reached. The second scheme is based on isopleth analysis and considers observation groups of similar frequencies following an increasing order of mean concentration and daily range. As a result, seasonal evolution was less marked. Straight lines were the borders for groups in the third scheme, which was similar and simpler than the second. The final scheme divided observations by means of equations of daily range as a quadratic function of daily concentration. The groups formed may be linked to seasons, with the group prevailing in summer presenting a noticeable daily range." .
<http://www.springernature.com/scigraph/things/articles/c82b7b5c35c0acc72f069c2fb2a151a5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A heteroskedastic random coefficients model was described for analyzing weight performances between the 100th and the 650th days of age of Maine-Anjou beef cattle. This model contained both fixed effects, random linear regression and heterogeneous variance components. The objective of this study was to analyze the difference of growth curves between animals born as twin and single bull calves. The method was based on log-linear models for residual and individual variances expressed as functions of explanatory variables. An expectation-maximization (EM) algorithm was proposed for calculating restricted maximum likelihood (REML) estimates of the residual and individual components of variances and covariances. Likelihood ratio tests were used to assess hypotheses about parameters of this model. Growth of Maine-Anjou cattle was described by a third order regression on age for a mean growth curve, two correlated random effects for the individual variability and independent errors. Three sources of heterogeneity of residual variances were detected. The difference of weight performance between bulls born as single and twin bull calves was estimated to be equal to about 15 kg for the growth period considered." .
<http://www.springernature.com/scigraph/things/articles/b82e1679d1c1add11948e2c15c40020d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract There is widespread concern about the impact of recent food price rises on the welfare and food security of poor people and about future impacts of high prices. Responses to these concerns are, however, sometimes clouded by lack of clarity about the nature of short and medium term impacts of food price changes for different people. This paper reviews both theory and empirical evidence on these impacts. It finds that theory and empirical evidence are broadly complementary and consistent, with a high degree of variability in impacts. In broad terms staple food price increases have had very serious effects on the poor in national or local economies which have experienced high food price shocks without broad based growth processes. Poor net buyers of food, in both rural and urban communities, have been most negatively affected, with limited second order benefits from high staple food prices tightening labour markets in poor rural economies. Short term impacts can be ameliorated by economic growth and, for international food price increases, by limited price transmission. Economic growth and lower domestic price transmission of high international prices in different countries, notably India and China, have led to lower increases in global poverty, hunger and malnourishment than hunger and poverty simulations have suggested. However these findings should not detract from the very serious impacts high food prices have had for very large numbers of very poor people in poor countries, and the need for policies and action to address this." .
<http://www.springernature.com/scigraph/things/articles/02e859e537e768c4a9839c82f80e26c0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We present an updated analysis of the rare decay $K_{\\mathrm{L}} \\rightarrow\\pi^{0} \\mu^{ + } \\mu^{-}$ within the standard model. In particular, we present the first complete calculation of the two-photon CP-conserving amplitude within chiral perturbation theory, at the lowest non-trivial order. Our results confirm the previous findings that the CP-conserving contribution to the decay rate cannot be neglected. By means of an explicit two-loop calculation, we show that this contribution can be estimated with sufficient accuracy compared to the CP-violating terms. We predict ${\\cal B}(K_{\\mathrm{L}}\\rightarrow\\pi^{0}\\mu^{ + } \\mu^{-})_{\\mathrm{SM}} = (1.5\\pm0.3)\\times10^{-11}$, with approximately equal contributions from the CP-conserving component, the indirect-CP-violating term, and the interesting direct-CP-violating amplitude. The error of this prediction is mainly of parametric nature and could be substantially reduced with better data on the $K_{\\mathrm{S}}\\rightarrow\\pi^{0}\\ell^{ + }\\ell^{-}$ modes. The standard model predictions for various differential distributions and the sensitivity to possible new-physics effects are also briefly discussed." .
<http://www.springernature.com/scigraph/things/articles/f42ffe57b87268d78e23c9aac83a06bc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Conclusions The following main conclusions can be drawn from the analysis:(a)The ordinary neo-classical equilibrium growth model considering only process innovations is inconsistent, if it is accepted that there exists satiation for existing goods. In such a model there is a continuous lack of demand so that the neo-classical “equilibrium” cannot persist.(b)A growing market economy can stay in equilibrium only if there is a balance between technical change used to create new products and applied to processes.(c)The natural growth rate of the economy is no longer exogeneous as in the orthodox neo-classical model, but depends on the interaction with the rest of the economy.(d)There are two structural changes going withequilibrium growth, namely (i) a constant rise of the proportion of income to employment and (ii) a secular fall in the share of old products in favour of new products in total output.(e)Phases of inflation and price stability are (partly) due to imbalances in the introduction of product and process innovations.(f)Allowing for advertising, the preference function of consumers becomes an endogeneous part of a growing economy; it changes continuously to adjust to evolving technical conditions in the society, and at the same time it influences other parts of the economy." .
<http://www.springernature.com/scigraph/things/articles/6cb4377cd7ca5078f1076ec09577fe9f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Econometric theory has achieved much. Still, there is a feeling in the profession that we are not providing the applied economist with the tools that he needs. In this paper I attempt to highlight the things that have occurred to me as being wrong or strange. The link between the items I discuss is the necessity of a focus. I discuss what an econometrician actually does, the relationship between econometrics and physics and econometrics and mathematical statistics, the gap between theory and practice, top-down and bottom-up methodology, weak links, aggregation and hierarchy, and how to take account of other studies. I conclude with an example from the theory of estimation under model uncertainty." .
<http://www.springernature.com/scigraph/things/articles/473ae0cbfaaf7086e2c88c4f0d7bcb7b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract An agent-based financial price model is developed by percolation system on the Sierpinski carpet lattice, in an attempt to reproduce and investigate fluctuation behaviors of price changes in the financial market. The percolation theory is usually used to describe the behaviors of connected clusters in a random graph, and the Sierpinski carpet lattice is an infinitely ramified fractal. We forecast and investigate the stock prices of the financial model by an improved Legendre neural network–Legendre neural network with random time strength function (LeNNRT). To test the LeNNRT and study the fluctuation behaviors of the stock prices on different time lag, the k-day moving average of Shanghai Composite Index and the simulated price series of the proposed model are predicted by the LeNNRT model. We exhibit the predictive results and compare the forecasting accuracies with different values of k for both the real data and the simulated data." .
<http://www.springernature.com/scigraph/things/articles/804bf1177ecb233608472dcd05d97fe3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper presents an analysis of the homogenised mean maximum (T max) and minimum (T min) temperatures. The data used in the analysis were collected at eight stations in the Autonomous Province of Vojvodina (Serbia) during the 1949–2008 period. The trends obtained from the slopes of the regression lines using the least square method show 0.9 °C/60 years for T max and 1.1 °C/60 years for T min; the non-parametric Mann–Kendall test was used to determine the statistically significant increasing trends of these two extreme parameters. In this paper, we analyse the influence of the Vangengeim–Girs classification of atmospheric circulation on the T max and T min trends in the Autonomous Province of Vojvodina (Serbia) using linear and quadratic models based on the least square method. Linear stepwise regression and the forward method reveal the highest dependence of T max and T min when the W or E circulation types are included in the model. Non-linear models show a greater contribution of T max and T min at W, E and C circulation types, respectively. The correction of the variance contribution of quadratic models ranges from approximately 16 to 44 % for T max and 32 to 38 % for T min." .
<http://www.springernature.com/scigraph/things/articles/907fbb642ab6e09b2b25019327a2196b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Cupressaceae includes species cultivated as ornamentals in the urban environment. This study aims to investigate airborne pollen data for Cupressaceae on the southwestern Iberian Peninsula over a 21-year period and to analyse the trends in these data and their relationship with meteorological parameters using time series analysis. Aerobiological sampling was conducted from 1993 to 2013 in Badajoz (SW Spain). The main pollen season for Cupressaceae lasted, on average, 58 days, ranging from 55 to 112 days, from 24 January to 22 March. Furthermore, a short-term forecasting model has been developed for daily pollen concentrations. The model proposed to forecast the airborne pollen concentration is described by one equation. This expression is composed of two terms: the first term represents the pollen concentration trend in the air according to the average concentration of the previous 10 days; the second term is obtained from considering the actual pollen concentration value, which is calculated based on the most representative meteorological parameters multiplied by a fitting coefficient. Temperature was the main meteorological factor by its influence over daily pollen forecast, being the rain the second most important factor. This model represents a good approach to a continuous balance model of Cupressaceae pollen concentration and is supported by a close agreement between the observed and predicted mean concentrations. The novelty of the proposed model is the analysis of meteorological parameters that are not frequently used in Aerobiology." .
<http://www.springernature.com/scigraph/things/articles/48388a50cd70e6a40f1023f040d825de> <http://www.springernature.com/scigraph/ontologies/core/abstract> "We introduce and formalize a class of multi-round (dynamic) procedures for collective estimation and choice among options. A technique is developed for investigating models of this class by entropy functions of a special form. Methods are proposed for the analysis of convergence, stability, accuracy, completeness, and adequacy of the proposed procedures. The analysis identifies a certain type of sufficiently simple models that have the best characteristics in the given class." .
<http://www.springernature.com/scigraph/things/articles/369432ced4e569c0ce328629b4019edb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The regulation of pharmacists in Belgium and the Netherlands is analysed in order to test the rent-seeking hypothesis put forward in the private interest literature. Both the self-regulation issued by the professional bodies and public regulations are examined. It appears that many regulations in both countries either restrict the entry into the profession or restrict competition within the profession. A qualitative comparative analysis of these regulations in both countries is presented as well as some empirical findings. The economic analysis and the empirical data seem to give some support to the rent-seeking hypothesis." .
<http://www.springernature.com/scigraph/things/articles/4f2494d6afc1c179c10482d566d55a62> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The aim of this paper is to analyze the role that aggregate R&D-expenditure plays in economic growth. We introduce a technology of innovation based on expenditure that generates endogenous sustainable growth in absence of any scale effect. This R&D-model permits us to study the effects of some fiscal policies. In particular, we analyze how subsidies to R&D-investment and physical capital accumulation affect the long-run growth rate. For the empirical cross-country analysis we directly derive a structural econometric model." .
<http://www.springernature.com/scigraph/things/articles/74d61c7b859be596452c2fb0bc9ee051> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper compares R&D productivity change across countries considering the fact that national R&D expenditure may produce multiple outputs, including patents and journal articles. Based on the concept of directional distance function and Luenberger productivity index, this paper develops a Luenberger R&D productivity change (LRC) index and then decomposes it into R&D efficiency change (catch-up effect) and R&D technical change (innovation effect). Utilizing a panel dataset of 29 countries over the 1998–2005 period to implement the empirical estimation, the results show that the R&D productivity growth is mainly attributed to the innovation effect; meanwhile, non-OECD countries have better performance on both efficiency change and technical change than their OECD counterparts. Moreover, patent-oriented R&D productivity growth serves as the main source of national R&D productivity growth than the journal article-oriented one." .
<http://www.springernature.com/scigraph/things/articles/88a8cfd1118043fbed46b05e6b87526a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This research examines the Phillips curve price adjustment mechanism allowing for the conditional variance of inflation to be time varying. Specifically, we estimate ARCH and GARCH models of inflation for Canada, Japan, and the U.K. The results suggest that an increase in the conditional variability of inflation leads to higher levels of inflation. In addition, inclusion of inflation variability in the Phillips curve model results in a higher weight being attributed to the output gap than in traditional models. (JEF E24)" .
<http://www.springernature.com/scigraph/things/articles/304abec33fd1fcd38356ddd98771af55> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study investigates long-term trends in annual and seasonal precipitation at 16 stations in the upper Blue Nile River basin. The non-parametric Mann–Kendall test modified by effective sample size is used to detect linear trends in the precipitation time series. The trends magnitudes and starting time of significant trends are determined using the Sen’s slope approach and the sequential Mann–Kendall test, respectively. Albeit annual precipitation shows a tendency to decrease in more than 80 % of the stations, statistically significant trends are found at only two stations. The significant decreasing trends of −40.3 and −168.1 mm/year per decade in annual precipitation at Debre Brihan and Gore stations started in the late 1970s and early 1980s respectively, which is consistent with the devastating droughts and famine during that period in the region. Owing to the great contribution of the main rainy season’s (June to September: JJAS) precipitation to annual precipitation in the upper Blue Nile basin, the variation pattern of the JJAS precipitation is very similar to that of annual precipitation. Insignificant decreasing/increasing trends in the short rainy season’s (March to May: MAM) precipitation are clearly predominant in the basin, where only one significant decreasing trend is detected in the time series." .
<http://www.springernature.com/scigraph/things/articles/df55992bf29157fda2e2e555182640d7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. In the context of complete financial markets, we study dynamic measures of the form \\[ \\rho(x;C):=\\sup_{\\nu\\in\\D} \\inf_{\\pi(\\cdot)\\in\\A(x)}{\\bf E}_\\nu\\left(\\frac{C-X^{x, \\pi}(T)}{S_0(T)}\\right)^+, \\] for the risk associated with hedging a given liability C at time t = T. Here x is the initial capital available at time t = 0, ${\\cal A}(x)$ the class of admissible portfolio strategies, $S_0(\\cdot)$ the price of the risk-free instrument in the market, ${\\cal P}=\\{{\\bf P}_\\nu\\}_{\\nu\\in{\\cal D}}$ a suitable family of probability measures, and [0,T] the temporal horizon during which all economic activity takes place. The classes ${\\cal A}(x)$ and ${\\cal D}$ are general enough to incorporate capital requirements, and uncertainty about the actual values of stock-appreciation rates, respectively. For this latter purpose we discuss, in addition to the above “max-min” approach, a related measure of risk in a “Bayesian” framework. Risk-measures of this type were introduced by Artzner, Delbaen, Eber and Heath in a static setting, and were shown to possess certain desirable “coherence” properties." .
<http://www.springernature.com/scigraph/things/articles/d56e1d3402dd2876eefe5a40253ab980> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Recent economic crises have affected different countries in the last decade. Crises shook not only countries that were directly affected but also other more developed countries. Part of the risk of crises derives from the considerable negative effects imposed on economies by the volatility and reversibility of short-term capital flow. International financial reforms should consider (1) regulation and supervision, (2) statistical standards, (3) the goods and services trade, (4) liquidity and lender of last resort, (5) unified action, (6) private-sector involvement, and (7) other contingency measures. The Venezuelan experience suggests some other domestic reforms, but reforming the international financial system, in the direction of globalization, has to be the principle goal of international organizations." .
<http://www.springernature.com/scigraph/things/articles/d302013e7dae611b4c48b48457248b8a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In a unified model-free framework that includes long-expiry, short-expiry, extreme-strike, and jointly-varying strike-expiry regimes, we generate implied volatility and implied variance approximations, with rigorous error estimates asymptotically smaller than any given power of L, where L denotes the exogenously given absolute log of an option price that approaches zero. Our results, therefore, sharpen to arbitrarily high order of accuracy (and, moreover, extend to general extreme regimes) the model-free asymptotics of implied volatility. We then apply these general formulas to particular examples: Heston (using a previously known L expansion) and Lévy (using saddlepoint methods to derive L expansions)." .
<http://www.springernature.com/scigraph/things/articles/be0e84735612b2222578c09033e9b5fa> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Electricity price is an important aspect in a restructured power market. Because of nonlinearity, nonstationary, and volatility of electricity price, it is highly essential to forecast the price on a short-term scale. This paper presents an efficient method based on a hybrid functional link dynamic neural network (DNN) trained by an adaptive robust unscented Kalman filter (UKF). The proposed method forecasts hourly prices for the day-ahead electricity market. The functional block helps to introduce nonlinearity by expanding the input space to higher-dimensional space through a basis function without using any hidden layer like multilayer perceptron structure. The DNN includes one or more infinite impulse response filters in the forward path providing feedback connections between outputs and inputs. This allows signal flow in both forward and backward directions, giving the network a dynamic memory useful to mimic dynamic systems. Also to improve the accuracy of the forecast, the noise covariance matrices of the UKF are adapted recursively. The proposed method is tested on PJM electricity market, and the residuals mean absolute error is compared with other forecasting methods, indicating the improved accuracy of the approach and its suitability to produce a real-time forecast. Further, to compare the accuracy of the forecast, an alternative UKF noise covariance optimization is attempted using differential evolution." .
<http://www.springernature.com/scigraph/things/articles/e2c05b2b44825cd9775f5e4ba9c64e37> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper focuses on the design of a consumption tax in a world of capital risk. The certainty literature discusses two standard options, namely the cash flow method and the pre-payment method (i.e., the wage tax), and finds the two approaches to be equivalent. Models that consider capital risk (via asset choice) reach different conclusions. This discrepancy arises in part due to a different choice of the social discount rate. In light of the failure of the discount-rate argument to resolve the issue at hand, we explore the market certainty equivalence of risky government revenue. We let revenue risks stay in the private sector, and examine the market value of the feasible transfer (e.g., in the form of a public good) back to households. We reach three broad conclusions. First, we find that if the state returns to each household its own tax-revenue risks, equivalence will be re-established as in certainty models. Next, we show that if the state engages in intergenerational risk sharing (e.g., through a system of stochastic tax transfers), the wage tax cannot be construed to be a valid pre-payment alternative to the cash flow or a modified wage-tax-ation system. Efficient risk allocation across generations under a cash flow tax (or, one that includes future capital gains as well as wages in the tax base) leads to a Pareto improvement over the simple wage tax. Finally, a major policy implication follows; in order to be practicable, a consumption tax would have to be implemented via registered savings accounts much in the fashion of the Canadian registered retirement savings plans program rather than through the pre-payment route." .
<http://www.springernature.com/scigraph/things/articles/f9344681acca3a2b039148e1655d99cd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract As an important macroeconomic variable and monetary policy tool, interest rate has been included in the core of the economic analysis for a long time. Reasonable interest rate is significant in the aspects of improving the social credit level and playing the economic leverage role, so the modeling approach of interest rate is our concern. This paper proposes a new interest rate model on the basis of exponential Ornstein–Uhlenbeck equation under the uncertain environment. Based on the model, the pricing formulas of the zero-coupon bond, interest rate ceiling and interest rate floor are derived through the Yao–Chen formula. In addition, some numerical algorithms are designed to calculate the prices of derivations according to the pricing formulas above." .
<http://www.springernature.com/scigraph/things/articles/0cf274341c31db46358af4668bd1468f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We investigate optimal consumption policies in the liquidity risk model introduced by Pham and Tankov (Math. Finance 18:613–627, 2008). Our main result is to derive smoothness C 1 results for the value functions of the portfolio/consumption choice problem. As an important consequence, we can prove the existence of the optimal control (portfolio/consumption strategy) which we characterize both in feedback form in terms of the derivatives of the value functions and as the solution of a second-order ODE. Finally, numerical illustrations of the behavior of optimal consumption strategies between two trading dates are given." .
<http://www.springernature.com/scigraph/things/articles/90c6ae1354e91289a7187a3918b1e3e4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary It is well-known that ifC is the class of rectangles 0≦x 1≦a 1, 0≦x 2≦a 2 or the class of circular discs then the normalized empirical measure onC behaves like a Brownian bridge. Our main result shows that for these two classes the distances between the normalized empirical measure and the nearest Brownian measure have entirely different order of magnitudes." .
<http://www.springernature.com/scigraph/things/articles/b007b7f3ca3e8daebca0216430be2cbe> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Due to the rapid economic growth and urbanization, China’s real estate industry has been undergoing a fast-paced development in recent decades. However, the spatial imbalance between the economic growth in urban and that in rural areas and the excessive growth and fluctuations of house prices in both areas had quickly caught public’s attention. Not surprisingly, these issues had become a focus of urban and regional economic research. Efficient and accurate prediction of housing prices remains a much needed but disputable topic. Currently, based on the trends and changes in the financial market, population migration and urbanization processes, numerous case studies have been developed to evaluate the mechanism of real estate’s price fluctuations. However, few studies were conducted to examine the space-time dynamics of how housing prices fluctuated from a big data perspective. Using data from China’s leading online real estate platform {sofang.com}, we investigated the spatiotemporal trends of the fluctuations of housing prices in the context of big data. This paper uses spatial data analytics and modeling techniques to: first, identify the spatial distribution of housing prices at micro level; second, explore the space-time dynamics of residential properties in the market; and third, detect if there exist geographic disparity in terms of housing prices. Results from our analysis revealed the space-time patterns of the housing prices in a large metropolitan area, demonstrating the utility of big data and means of analyzing big data." .
<http://www.springernature.com/scigraph/things/articles/85b4d5cdc65835198bd38255d250bcb7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We study the groups of definable automorphisms of constructive models. We introduce parametric groups of definable automorphisms and obtain a full description of all possible parametric groups of definable automorphisms of strongly constructive models, as well as corollaries for models in finite signatures." .
<http://www.springernature.com/scigraph/things/articles/7163da6624326fc1c66feaa56ce88b06> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Monthly averages of the Helsinki Ak-values have been reduced to the equivalent aa-indices to extend the aa-data set back to 1844. A periodicity of about five cycles was found for the correlation coefficient (r) between geomagnetic indices and sunspot numbers for the ascending phases of sunspot cycles 9 to 22, confirming previous findings based on a minor number of sunspot cycles. The result is useful to researchers in topics related to solar-terrestrial physics, particularly for the interpretation of long-term trends in geomagnetic activity during the past, and to forecast geomagnetic activity levels in the future." .
<http://www.springernature.com/scigraph/things/articles/fdace79020e5495511be8201cea70b06> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary So far, the labour market has not received any special attention from macro-econometric model builders. In this article an attempt has been made to describe the labour market in detail, paying attention to such important phenomena as the friction between labour supply and demand, the heterogeneity of labour, the dependence of labour supply on the labour-market situation, the Phillips mechanism and the impact of real wages on labour demand. To make it suitable for policy simulations, the model has been extended to a complete macro-econometric model, taking account of the fact that both labour and capital limit the production possibilities." .
<http://www.springernature.com/scigraph/things/articles/689314ff1d2e101cb79e999d02da7cfe> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we study the supply of quality in imperfectly competitive markets, and explore the role of regulation in markets where firms may use both quality and price to compete for customers. In a model where firms first choose qualities and then prices, we find that quality decisions have strategic effects: firms react to quality disadvantages by price reductions. Because of this strategic effect, firms do not have the correct incentive to set socially efficient quality levels. Price and quality competition results in a socially suboptimal quality level. Efficiency can be restored by lump-sum transfers and price regulatory policies. Simple price regulation may result in lower price and higher quality." .
<http://www.springernature.com/scigraph/things/articles/2f166ec703a7098d21ce683ff575cd4e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper investigates the cointegration relationship among a group of international stock indices in light of new developments of econometric methods. Kasa (1992) first documented strong evidence for cointegration relations among five national stock indices, which suggests that there exists a common trend among those stock indices. Using Johansen multivariate cointegration test, we find that his findings are persistent in a sample of longer periods and more countries. In order to investigate whether these results are driven by statistical biases related to the sample size, we apply to our tests the Johansen’s small sample correction factor. The results still point toward the existence of a cointegration relationship but the evidence becomes much weaker. We next examine the empirical patterns emerged from different lag specifications and argue that Kasa’s findings are more likely due to the size distortion in extreme long lag VAR models. Indeed, when we employ a newly developed non-parametric test that does not require estimation VAR models, the null hypothesis of no cointegration cannot be rejected for the original sample of Kasa’s five-country stock indices from 1974 to 1990, nor for the extended period from 1970 to 2003." .
<http://www.springernature.com/scigraph/things/articles/3c7aa7efc0020270ffb49ab594e2362a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The block bootstrap has been largely developed for weakly dependent time processes and, in this context, much research has focused on the large-sample properties of block bootstrap inference about sample means. This work validates the block bootstrap for distribution estimation with stationary, linear processes exhibiting strong dependence. For estimating the sample mean’s variance under long-memory, explicit expressions are also provided for the bias and variance of moving and non-overlapping block bootstrap estimators. These differ critically from the weak dependence setting and optimal blocks decrease in size as the strong dependence increases. The findings in distribution and variance estimation are then illustrated using simulation." .
<http://www.springernature.com/scigraph/things/articles/30cd345266403a54ed1b290a41be3439> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary Estimation of orientation is a key operation at each step in projection pursuit. Since projection pursuit is a nonparametric algorithm, and since even low-dimensional approximations to the target function must converge to their limits at rates considerably slower than n -12(where n is sample size), then it might be thought that the same is true of orientation estimates. It is shown in the present paper that this is not the case, and that estimation of orientation is a parametric operation, in the sense that, under mild nonparametric assumptions, correctly-chosen kernel-type orientation estimates converge to their limits at rate n -12. This property is not enjoyed by standard projection pursuit orientation estimates, which converge at a slower rate than n -12. Most attention in the present paper is focussed on the case of projection pursuit density approximation, but it is pointed out that our arguments hold generally. An important practical conclusion is that data should be smoothed less when estimating orientation than when constructing the final projection pursuit approximation." .
<http://www.springernature.com/scigraph/things/articles/193d0524591479340c3457a5995fc99c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A return scaling cross-correlation function of exponential parameter is introduced in the present work, and a stochastic time strength neural network model is developed to predict the return scaling cross-correlations between two real stock market indexes, Shanghai Composite Index and Shenzhen Component Index. In the proposed model, the stochastic time strength function gives a weight for each historical data and makes the model have the effect of random movement. The empirical research is performed in testing the model forecasting effect of long-term cross-correlation relationships by training short-term cross-correlations, and a corresponding comparison analysis is made to the backpropagation neural network model. The empirical results show that the proposed neural network is advantageous in increasing the forecasting precision." .
<http://www.springernature.com/scigraph/things/articles/73b4f9a65b952e9a2bd9d58efa4cf456> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper applied time series analysis to examine the nexus between firearm robberies and homicide in Hong Kong Special Administrative Region (HK). Recent years have seen a reduction in firearm related offences in HK compared to Britain. For instance, only three cases of firearm robbery in 2004 in HK (0.1% of all robbery; 2,237 incidents) involved genuine firearms, compared to 4,117 firearm robbery incidents (4% of all robbery) in Britain in the same year. This paper established a cross-correlation coefficient of 0.50 at lag 0 for the annual rate of two serious crimes, genuine firearm robbery and homicide, after identifying an ARMA(1,0) model from each time series (1972–2002). The results suggest that the prevalence of firearm robbery is moderately associated with the prevalence of homicide in HK." .
<http://www.springernature.com/scigraph/things/articles/49d5c19318f894cfb07d73597b384010> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We introduce a class of stochastic volatility models whose parameters are modulated by a hidden nonlinear dynamical system. Our aim is to incorporate the impact of economic cycles, or business cycles, into the long-term behavior of volatility dynamics. We develop a discrete-time nonlinear filter for the estimation of the hidden volatility and the nonlinear dynamical system based on return observations. By exploiting the technique of a reference probability measure we derive filters for the hidden volatility and the nonlinear dynamical system." .
<http://www.springernature.com/scigraph/things/articles/c349ce7d1e7153a93648923fb504b2b6> <http://www.springernature.com/scigraph/ontologies/core/abstract> " The literature overwhelmingly believes that the size of a financial premium could be an indicator of the extent of the real exchange rate misalignment under dual exchange rates. We wish to oppose this view. The strategy in this paper is to investigate the effects that monetary and real shocks from domestic or foreign origin have on these variables. We also extend the analysis of the theoretical model by discussing numerical simulations. Both theoretical and numerical examinations together show that such a relationship does not exist. Moreover, we find that the more volatile the financial premium, the more stable the real exchange rate." .
<http://www.springernature.com/scigraph/things/articles/0b3e716c13d63fd3165b65823ec1f9f4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Sensitivity analysis is indispensable to structural design and optimization. This paper focuses on sensitivity analysis for models with correlated inputs. To explore the contributions of correlated inputs to the uncertainty in a model output, the universal expressions of the variance contributions of the correlated inputs are first derived in the paper based on the high dimensional model representation (HDMR) of the model function. Then by analyzing the composition of these variance contributions, the variance contributions by an individual correlated input to the model output are further decomposed into independent contribution by the individual input itself, independent contribution by interaction between the individual input and the others, contribution purely by correlation between the individual input and the others, and contribution by interaction associated with correlation between the individual input and the others. The general expressions of these components are also derived. Based on the characteristics of these general expressions, a universal framework for estimating the various variance contributions of the correlated inputs is developed by taking the efficient state dependent parameter (SDP) method as an illustration. Numerical and engineering tests show that this decomposition of the variance contributions of the correlated inputs can provide useful information for exploring the sources of the output uncertainty and identifying the structure of the model function for the complicated models with correlated inputs. The efficiency and accuracy of the SDP-based method for estimating the various variance contributions of the correlated inputs are also demonstrated by the examples." .
<http://www.springernature.com/scigraph/things/articles/d6dd05b88418eb043ebb6ba6d3627696> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Using different indicators of financial development, recent empirical studies have discovered various patterns of nonlinearity in the relationship between financial development and economic growth. By adding consumption loans, which are nonproductive, into a standard model of asymmetric information, this paper generates a model that is able to replicate all possible nonlinear finance–growth relationships found in recent empirical studies." .
<http://www.springernature.com/scigraph/things/articles/7b89a2bb21118be93c7bf795fbf66c3f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study seeks to the answer the question of how an individual would trade off between listing fee (i.e., cost of listing an auction item) and transaction probability (i.e., the chance that a product will be sold). Applying the trade-off decision-making paradigm into the auction context, we examine a seller’s choice of online auction outlet and subsequent starting price strategies when facing the trade-off between transaction probability and listing fee. Results from a set of laboratory experiments suggest that a seller would be willing to incur a high cost in exchange for a higher transaction prospect. Furthermore, if the expected transaction probability is high, a seller is more likely to set a high starting price despite incurring a high listing fee. The implications for theory and practice are discussed." .
<http://www.springernature.com/scigraph/things/articles/3f51b2caef203f839f231696618ff9d1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The literature on optimum currency areas states that large inflation differentials can undermine monetary union. In the euro area, inflation rates diverged after the creation of the single currency, but started to converge again from mid-2002. Against this background, we assess the convergence of inflation rates and business cycles and study the relationship between them. The analysis is made using an unobserved component model estimated with the Kalman filter. In general, from 1980 to 2008 inflation rates and business cycles became more aligned in the euro area, but inflation rates converged more quickly than business cycles. The output gap is found to be a better indicator of the business cycle than unit labour cost when studying convergence. By looking at the causality between the convergence of inflation and output gap, it is found that inflation divergence has a limited destabilising economic impact." .
<http://www.springernature.com/scigraph/things/articles/284e9412c3a02fc8ffbfd86c3814ad66> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper brings four new insights into the Purchasing Power Parity (PPP) debate. First, we show that a half-life PPP (HL) model is able to forecast real exchange rates better than the random walk (RW) model at both short and long-term horizons. Second, we find that this result holds if the speed of adjustment to the sample mean is calibrated at reasonable values rather than estimated. Third, we find that it is preferable to calibrate, rather than to elicit as a prior, the parameter determining the speed of adjustment to PPP. Fourth, for most currencies in our sample, the HL model outperforms the RW also in terms of nominal exchange rate forecasting." .
<http://www.springernature.com/scigraph/things/articles/ecb2cb203e9469a752870dec4b5da793> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The present paper analyses the relations between food and oil prices for Malaysia using a nonlinear autoregressive distributed lags (NARDL) model. The bounds test of the NARDL specification suggests the presence of cointegration among the variables, which include the food price, oil price and real GDP. The estimated NARDL model affirms the presence of asymmetries in the food price behavior. Namely, in the long run, we find a significant relation between oil price increases and food price. Meanwhile, the long run relation between oil price reduction and the food price is absent. Furthermore, in the short run, only changes in the positive oil price exert significant influences on the food price inflation. With the absence of significant influence of oil price reduction on the food price both in the long run and in the short run, the role of market power in shaping the behavior of Malaysia’s food price is likely to be significant." .
<http://www.springernature.com/scigraph/things/articles/a06663feda42d23c3ed4372e06bd7a3b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract An integer partition {λ1,λ2,...,λ v } is said to be graphical if there exists a graph with degree sequence 〈λ i 〉. We give some results corcerning the problem of deciding whether or not almost all partitions of even integer are non-graphical. We also give asymptotic estimates for the number of partitions with given rank." .
<http://www.springernature.com/scigraph/things/articles/68df8fbe1aa0bfc7cbcfc710a82c31ff> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The dramatic decline in inflation across the world over the last 20 years has been largely credited to improved monetary policy. The universal nature of the phenomenon, however, indicates that globalization, which occurred simultaneously, also played a role. We build a model based on Melitz (2003) in which falling transport cost lead to greater openness, higher productivity and lower inflation. Following a decline in transport cost openness increases and firm selection eliminates the least productive domestic firms. The consequent increase in average productivity leads to falling relative prices for goods. A cash-in-advance constraint allows analyzing how falling relative prices can lead to lower inflation. Using a data set of macroeconomic variables for 123 countries from all world regions, we disentangle the influences of monetary policy and globalization by showing that openness-induced productivity growth leads to a significant decline in inflation world-wide. The results can be further confirmed in a calibration exercise." .
<http://www.springernature.com/scigraph/things/articles/473de65f11dd2f256af1b34e6803aeb8> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper considers a closed macroeconomy where the monetary authority pursues an inflation target and policy outcomes are the consequence of a Nash game between fiscal and monetary authorities. The specification of the macroeconomic framework is characterized by nonlinearities which lead to multiple equilibria with differing stability properties. Employing a calibrated model and simulations derived using the Mathematica package, the stability properties of the economy and the likely choice of equilibrium are examined. Within this framework, the dynamic consequences of different time discount rates for the fiscal authority are investigated, both in a world of certainty and also in a world of uncertainty. It is shown that, in a world of certainty, it will be optimal to choose the fiscal authority's time discount rate equal to the market rate of interest. However, depending on the degree of uncertainty in evaluating the time discount rates of consumers and of the fiscal authority, it may be appropriate to bias the fiscal authority's discount rate above or below the expected interest rate." .
<http://www.springernature.com/scigraph/things/articles/7e35b2ab2af4914f38d988285494d298> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Space deformation modelling and estimation techniques based on Multidimensional Scaling (MDS) methods play an important role in nonparametric approaches to the covariance structure analysis of the spatiotemporal processes underlying environmental studies. Since any related procedure depends on the planar MDS representation, the stability of the estimated dispersion, together with the determination of the most influential stations in the estimation of the dispersion space, are important issues that must be analysed before performing the final mapping. In this paper, stability analysis, both in terms of the MDS model and of the variogram function, as well as concerning the derivation of kriging interpolation estimates, is addressed using a special analytical jackknife procedure. Furthermore, the influence of each station in the solution given is assessed, thus providing relevant information regarding not only the MDS procedure but also the interpolation process and the variogram estimation of the spatial dispersion." .
<http://www.springernature.com/scigraph/things/articles/29078920d14a53c1f2bd2e34375f2204> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract AR* models contain Autoregressive Moving Average and Generalized Autoregressive Conditional Heteroscedastic class model which are widely used in time series. Recent researches in forecasting with Generalized Regression Neural Network (GRNN) suggest that GRNN can be a promising alternative to the linear and nonlinear time series models. In this paper, a model composed of AR* and GRNN is proposed to take advantage of their feathers in linear and nonlinear modeling. In the AR*-GRNN model, AR* modeling improves the forecasting performance of the combined model by capturing statistical and volatility information from the time series. The relative experiments testify that the combined model provides an effective way to improve forecasting performance which can be achieved by either of the models used separately." .
<http://www.springernature.com/scigraph/things/articles/ab1cde952d95abcf835e65c12c5bdfc1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary We examined the demographic costs of Chaoborus-induced defensive spine structures in Daphnia pulex. Our aim was to assess the role of resource limitation and the interaction effects of limiting food level and antipredator structures on fitness of D. pulex and to pinpoint those life stages that are most sensitive to changes in the defence regime. Chaoborus-induced and typical morphotypes of D. pulex were reared at high and low food concentrations. Instar-based matrix population models were used to quantify the effects of predator-induction, food and their interaction on fitness of D. pulex. Predator-induction caused a statistically significant reduction in fitness at low food levels, but not at high food levels. Sensitivity analyses revealed that the fitness effects were primarily due to changes in the growth rate in instars 1–5, and secondarily to small reductions in the fertility of instars 5–10. The interaction between Chaoborus exposure and low food concentration was negative, and mediated through growth and fertility components. Both these components were reduced more in the Chaoborus-exposed, low food treatment than would be expected in the absence of interaction." .
<http://www.springernature.com/scigraph/things/articles/28055d7c1d369dbf56a6ab69b872a05f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The detection of community structure in stock market is of theoretical and practical significance for the study of financial dynamics and portfolio risk estimation. We here study the community structures in Chinese stock markets from the aspects of both price returns and turnover rates, by using a combination of the PMFG and infomap methods based on a distance matrix. An empirical study using the overall data set shows that for both returns and turnover rates the largest communities are composed of specific industrial or conceptional sectors and the correlation inside a sector is generally larger than the correlation between different sectors. However, the community structure for turnover rates is more complex than that for returns, which indicates that the interactions between stocks revealed by turnover rates may contain more information. This conclusion is further confirmed by the analysis of the changes in the dynamics of community structures over five sub-periods. Sectors like banks, real estate, health care and New Shanghai take turns to comprise a few of the largest communities in different sub-periods, and more interestingly several specific sectors appear in the communities with different rank orders for returns and turnover rates even in the same sub-period. To better understand their differences, a comparison between the evolution of the returns and turnover rates of the stocks from these sectors is conducted. We find that stock prices only had large changes around important events while turnover rates surged after each of these events relevant to specific sectors, which shows strong evidence that the turnover rates are more susceptible to exogenous shocks than returns and its measurement for community detection may contain more useful information about market structure." .
<http://www.springernature.com/scigraph/things/articles/191e0a735191e1d086a5532e405e8d44> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We calculate the low-redshift Taylor expansion for the luminosity distance for an observer at the center of a spherically symmetric matter inhomogeneity with a non-vanishing cosmological constant. We then test the accuracy of the formulas comparing them to the numerical calculation for different cases for both the luminosity distance and the radial coordinate. The formulas can be used as a starting point to understand the general non-linear effects of a local inhomogeneity in the presence of a cosmological constant, without making any special assumption as regards the inhomogeneity profile." .
<http://www.springernature.com/scigraph/things/articles/5748d8d8c904382b3dc8f93efba713ad> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The 1995 Survey of Consumer Finances was used to determine holdings of selected financial products by low-to-moderate income households, defined as households with incomes less than or equal to 80% of median household income for their region. First, we estimated determinants of holding bank accounts. Next, we estimated determinants of holding other selected products, contingent on holding a transaction account. Finally, we estimated the potential demand for these other products by households without accounts, should they become account holders. We found that if non-account holding households were to obtain accounts, they would increase their demand for credit cards, first mortgages, car loans, consumer loans, certificates of deposit, and IRA/Keogh accounts. The implications for financial institutions, policy makers, and consumer educators are presented." .
<http://www.springernature.com/scigraph/things/articles/4d9554ea904ce01fe57c54ae9a302f99> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Regional frequency analysis is an important tool to properly estimate hydrological characteristics at ungauged or partially gauged sites in order to prevent hydrological disasters. The delineation of homogeneous groups of sites is an important first step in order to transfer information and obtain accurate quantile estimates at the target site. The Hosking–Wallis homogeneity test is usually used to test the homogeneity of the selected sites. Despite its usefulness and good power, it presents some drawbacks including the subjective choice of a parametric distribution for the data and a poorly justified rejection threshold. The present paper addresses these drawbacks by integrating nonparametric procedures in the L-moment homogeneity test. To assess the rejection threshold, three resampling methods (permutation, bootstrap and Pólya resampling) are considered. Results indicate that permutation and bootstrap methods perform better than the parametric Hosking–Wallis test in terms of power as well as in time and procedure simplicity. A real-world case study shows that the nonparametric tests agree with the HW test concerning the homogeneity of the volume and the bivariate case while they disagree for the peak case, but that the assumptions of the HW test are not well respected." .
<http://www.springernature.com/scigraph/things/articles/03b5d75cb51d9c891ff026473edfa8c4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper examines purchasing power parity (PPP) behavior using error correction models (ECM) and allowing for structural breaks. We distinguish four different objectives: first, this paper examines which variable or variables (the exchange rate and/or international relative prices) exhibit a significant error correction mechanism. Second, this paper presents empirical evidence about the adjustment velocity to the long-run equilibrium. Third, it examines the evidence regarding cointegration and the adjustment coefficients parameter instability, and finally, it analyzes whether traded and non-traded sectors exhibit different behavior. The most important results are: (1) the predominant adjustment is in the exchange rate with a larger velocity adjustment than in relative prices; (2) the evidence suggests that when there are strong depreciations or appreciations in the exchange rate, the international relative prices adjust (i.e., there is evidence of pass-through); (3) the dynamic adjustment to equilibrium is, in general, stable." .
<http://www.springernature.com/scigraph/things/articles/59a7a337c93c376fdb68755bfcade15d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Many firms and organizations compete for customers while at the same time receiving substantial funding from outside sources, such as government subsidies. In this paper, we study the effects of two commonly observed subsidy systems on the strategic behavior of competing firms. We compare a per unit subsidy to a subsidy allocated according to the firms’ market shares. We show that, holding the total subsidy budget constant, the per unit subsidy results in lower prices, higher output, lower profits and higher overall welfare as compared to the market-share based alternative. However, we also find that a market-share based subsidy makes collusive behavior between firms much harder. Our results suggest a potential trade-off between short-run and long-run objectives: subsidy systems designed to widen participation may favor collusive behavior. The welfare implications of this trade-off are discussed. Our findings have important policy implications for the design of subsidy systems." .
<http://www.springernature.com/scigraph/things/articles/7b72b0591a8372c75e760e781b043a51> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The poor are in a disadvantaged position in the financial market. In this article, a review is given of public policy initiatives that are implemented to help the poor as well as an examination of how the poor are served in the financial market, using data from the 1995 and 1998 Survey of Consumer Finances provided by the Federal Reserve Board. Specifically, poor households' use of depository and credit products, the financial institutions that provide these products to the poor, and the way in which the poor conduct their financial business (e.g., visit to branch offices, ATMs, etc.) are compared to that of non-poor households. Marketing and public policy implications are drawn from the findings." .
<http://www.springernature.com/scigraph/things/articles/0e2a24242c0abd87e69eb5cec82f8cec> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We consider kernel-based non-parametric estimation of second-order product densities of spatial point patterns. We present a new family of optimal and positive kernels that shows less variance and more flexibility than optimal kernels. This family generalises most of the classical and widely used kernel functions, such as Box or Epanechnikov kernels. We propose an alternative asymptotically unbiased estimator for the second-order product density function, and compare the performance of the estimator for several members of the family of optimal and positive kernels through MISE and relative efficiency. We present a simulation study to analyse the behaviour of such kernel functions, for three different spatial structures, for which we know the exact analytical form of the product density, and under small sample sizes. Some known datasets are revisited, and we also analyse the IMD dataset in the Rhineland Regional Council in Germany." .
<http://www.springernature.com/scigraph/things/articles/03657ed1126cbc2609042d3e43adabc4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper analyses the stabilising potential of simple fiscal policy rules for a small open economy in monetary union in a 2-region DSGE model with nominal and real rigidities. We consider simple fiscal instrument rules for government purchases, transfers, and consumption, labour and capital taxes in analogy to interest rate rules in monetary policy. The paper finds a dichotomy in the welfare effects of fiscal policy for liquidity-constrained and intertemporal optimising households, i.e. policies enhancing the welfare of one group tend to reduce the welfare of the other one. The moderate average welfare gains from optimal policy contrast with potentially large welfare losses from non-optimal policy. Fiscal rules that respond to employment fluctuations may be preferred to fiscal rules responding to indicators of price competitiveness, because optimal policy corresponds more closely to the idea of countercyclical stabilisation in the former case. The simulations also emphasise the crucial impact of the budgetary closure rule on the welfare consequences of fiscal business-cycle stabilisation." .
<http://www.springernature.com/scigraph/things/articles/84fa6f9cd31a448856ea988676019fc9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We propose a simple, parsimonious, and easily implementable method for stress-testing banks using a top-down approach that captures the heterogeneous impact of shocks to macroeconomic variables on banks’ capitalization. Our approach relies on a variable selection method to identify the macroeconomic drivers of banking variables as well as the balance sheet and income statement factors that are key in explaining bank heterogeneity in response to macroeconomic shocks. We perform a principal component analysis on the selected variables and show how the principal component factors can be used to make projections, conditional on exogenous paths of macroeconomic variables. We apply our approach, using alternative estimation strategies and assumptions, to the 2013 and 2014 stress tests of medium- and large-size U.S. banks mandated by the Dodd-Frank Act, and obtain stress projections for capitalization measures at the bank-by-bank and industry-wide levels. Our results suggest that accounting for bank heterogeneity yields expected capital shortfalls that can be over 30 percent larger than in the case where heterogeneity is ignored. Furthermore, we find that while capitalization of the U.S. banking industry has improved in recent years, under reasonable assumptions regarding growth in assets and loans, the stress scenarios continue to imply sizable deterioration in banks’ capital positions." .
<http://www.springernature.com/scigraph/things/articles/b3f1fba0b5ec98cb33b300c7e4886d24> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper analyzes data from the British Household Panel Survey on households' financial management and financial decision-making. Direct subjective information was collected by asking questions like ‘Who has the final say in big financial decisions?’. All questions were answered separately by both partners. We consider two competing models explaining how finances are organized. The first model is based on a household production approach, in which behaviour is determined by an efficient allocation of both partners' time to market work, financial management, and leisure. In the second model, which is game-theoretic in nature, financial management is a reflection of bargaining power. The two models have different implications for the effect of explanatory variables, in particular wages, on the dependent variables. Empirical results indicate that financial management is primarily determined by bargaining considerations." .
<http://www.springernature.com/scigraph/things/articles/10af78037ab7faceba1992af34df8f65> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Kinetic evaluation of thermogravimetry data was used to understand the ageing behavior of beeswax used as an artists’ paint medium on ancient mummy shrouds and Fayum portraits. Individual components of beeswax were subjected to dynamic thermogravimetry to assess their evaporation rates, and three methods of kinetic analysis were evaluated for accuracy. The results showed that although it is impossible to accurately predict the volatility at room temperature for individual components of beeswax due mostly to their high molecular mass, relative trends and ranking of the volatility of the compounds can be obtained which may explain compositional changes over time." .
<http://www.springernature.com/scigraph/things/articles/47738690eea9453be4f2a20752a1a081> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper focuses on current use of elderly care services in Ireland and France. In light of health care resource allocation problems, it is important to know the level of current use of home care on which future projections may be based. With the availability of SHARE (Survey of Health Ageing and Retirement in Europe) data, it is now possible to analyse this process and estimate the relationship between formal and informal care, and our econometric model tests for endogeneity of informal care. Previous research has not included Ireland into the analysis. Given that Ireland has a younger population base, lessons could be learned from countries with older populations, such as France. Results suggest informal care is endogenous and negatively linked with formal care in the pooled (France and Ireland) model. There is a higher unmet need for care in Ireland. These results have important policy implications for Ireland as the demographic makeup will change from 11 per cent to 15 per cent of older people over the next 10 years." .
<http://www.springernature.com/scigraph/things/articles/25e6de78698c8ec893e2179d5e31452b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Pricing decisions of exporters who are facing imperfect competition in their destination markets might depend on exchange rate changes. While empirical literature often assumes that the impact of the exchange rate on the exporters’ prices is linear and the markup adjustment does not depend on magnitude or direction of the exchange rate change (or allows for short-run asymmetries only), we question this statement and test for the long-run hysteresis and asymmetry of pricing-to-market (PTM). Using the German export beer market as an example, we show that both types of nonlinearities play an important role in PTM decisions." .
<http://www.springernature.com/scigraph/things/articles/545ce97864bba089db079627ef9fb38c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The literature assumes that Taiwan’s international tourist hotels have identical frontier technology to evaluate non-radial efficiencies, even if they characterize different operating types. This study develops a non-radial systems model, for which the different operating types are evaluated based on different frontier technologies in order to calculate efficiencies. Compared to the radial systems model, the new model is able to practice two verifications. First, efficient units can be separated into strong and weak efficient sets. The second finds the benchmark among the different types for each input and output. The empirical results show that most efficient units reflect strong efficiency while only one hotel reflects weak efficiency. Inefficient hotels should refer to the chain type in order to improve excess utilizations in employees, rooms, catering space, and revenue deficits. For improving excess operating expenses and occupancy rate deficits, inefficient hotels should refer to the independent type." .
<http://www.springernature.com/scigraph/things/articles/04fd7aa854d39512a94a8fea4439843a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Anna Schwartz has long promoted a policy of stable money. She also has advocated sound financial policy. The financial environment, according to her work, is strongly influenced by the degree of aggregate price stability. In this article historical evidence for the U.S. is presented that shows a strong association between aggregate price movements and measures of financial distress. Even in an environment of aggregate price stability in the face of shocks, however, a monetary authority should follow the financial policies of a lender of last resort as advocated over a century ago by Walter Bagehot—to promote adequate funds to allay the public's demand for means of payment in the face of a “real” financial crisis. Other circumstances involving asset market reversals that Schwartz calls “pseudo crises” should not be the subject of the monetary authorities' actions." .
<http://www.springernature.com/scigraph/things/articles/6bfa74d759a317d16d688e558db97a5d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Studies on persistence are important for the clarification of statistical properties of the analyzed time series and for understanding the dynamics of the systems which create these series. In climatology, the analysis of the autocorrelation function has been the main tool to investigate the persistence of a time series. In this paper, we propose to use a more sophisticated econometric instrument. Using this tool, we obtain an estimate of the persistence in global land and ocean and hemispheric temperature time series." .
<http://www.springernature.com/scigraph/things/articles/df0bc4c2c2fb829fb84f44fba9726af3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The present research explains environmental performance using an ecological composite index as the dependent variable and focusing on two national dimensions: sociopolitical characteristics and economics. Environmental performance is measured using the Composite Index of Environmental Performance (CIEP) indicator proposed by García-Sánchez et al. (2015). The first model performs a factor analysis to aggregate the variables according to each analyzed dimension. In the second model, the estimation is run using only single variables. Both models are estimated using generalized least square estimation (GLS) using panel data from 152 countries and 6 years. The results show that sociopolitical factors and international trade have a positive effect on environmental performance. When the variables are separately analyzed, democracy and social policy have a positive effect on environmental performance while transport, infrastructure, consumption of goods, and tourism have a negative effect. Further observation is that the trade-off between importing and exporting countries overshadows the pollution caused by production. It was also observed that infrastructure has a negative coefficient for developing countries and positive for developed countries. The best performances are in the democratic and richer countries that are located in Europe, while the worst environmental performance is by the nondemocratic and the poorest countries, which are on the African continent." .
<http://www.springernature.com/scigraph/things/articles/c1d5f996f640a9206c420c9763b34ef1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The effect of weather variables on sugarcane ripening is a process still not completely understood, despite its huge impact on the quality of raw material for the sugar energy industry. The aim of the present study was to evaluate the influence of weather variables on sugarcane ripening in southern Brazil, propose empirical models for estimating total recoverable sugar (TRS) content, and evaluate the performance of these models with experimental and commercial independent data from different regions. A field experiment was carried out in Piracicaba, in the state of São Paulo, Brazil, considering eight sugarcane cultivars planted monthly, from March to October 2002. In 2003, at the harvest, 12 months later, samples were collected to evaluate TRS (kg t−1). TRS and weather variables (air temperature, solar radiation, relative humidity, and rainfall) were analyzed using descriptive and multivariate statistical analysis to understand their interactions. From these correlations, variables were selected to generate empirical models for estimating TRS, according to the cultivar groups and their ripening characteristics (early, mid, and late). These models were evaluated by residual analysis and regression analysis with independent experimental data from two other locations in the same years and with independent commercial data from six different locations from 2005 to 2010. The best performances were found with exponential models which considered cumulative rainfall during the 120 days before harvest as an independent variable (R 2 adj ranging from 0.92 to 0.95). Independent evaluations revealed that our models were capable of estimating TRS with reasonable to high precision (R 2 adj ranging from 0.66 to 0.99) and accuracy (D index ranging from 0.90 to 0.99), and with low mean absolute percentage errors (MAPE ≤ 5 %), even in regions with different climatic conditions." .
<http://www.springernature.com/scigraph/things/articles/c397984111871e1eaabe95cc791b98ed> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper discusses the effects of parasitic quality-factor modulation in a tuned circuit arising on parametric modulation and influencing a capacitance-sensor analyzer. Varicaps may be used for parametric modulation of a semiconductor capacitance in order to improve not only the reliability but also the accuracy of a dielcometric analyzer." .
<http://www.springernature.com/scigraph/things/articles/ea3f97cddbe2a1452b4d9295cb2a43c4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary In this article, the results of an empirical application for ten countries of Willis' economic theory of fertility are presented. In a further analysis for The Netherlands the model developed by Willis is confronted with some alternative models. It is concluded that among the models considered the Willis model is the most satisfactory one. However, in conformity with Leibenstein's propostition that economic factors are only relevant with respect to the question whether parents want more than two children, Willis' model proves to offer only an explanation for the question whether a married couple which has already two children wants to have a third child." .
<http://www.springernature.com/scigraph/things/articles/4866df782b4612f92125e6bb49950620> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Nonlinear nonstationary models for time series are considered, where the series is generated from an autoregressive equation whose coefficients change both according to time and the delayed values of the series itself, switching between several regimes. The transition from one regime to the next one may be discontinuous (self-exciting threshold model), smooth (smooth transition model) or continuous linear (piecewise linear threshold model). A genetic algorithm for identifying and estimating such models is proposed, and its behavior is evaluated through a simulation study and application to temperature data and a financial index." .
<http://www.springernature.com/scigraph/things/articles/eef854944938ad0299181c0373228c95> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper is inspired by the stress–strength models in the reliability literature, in which given the strength (Y) and the stress (X) of a component, its reliability is measured by P(X < Y). In this literature, X and Y are typically modeled as independent. Since in many applications such an assumption might not be realistic, we propose a copula approach in order to take into account the dependence between X and Y. We then apply a copula-based approach to the measurement of household financial fragility. Specifically, we define as financially fragile those households whose yearly consumption (X) is higher than income (Y), so that P(X > Y) is the measure of interest and X and Y are clearly not independent. Modeling income and consumption as non-identically Dagum distributed variables and their dependence by a Frank copula, we show that the proposed method improves the estimation of household financial fragility. Using data from the 2008 wave of the Bank of Italy’s Survey on Household Income and Wealth we point out that neglecting the existing dependence in fact overestimates the actual household fragility." .
<http://www.springernature.com/scigraph/things/articles/79928e4917cd262fb81bbb5465233500> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In the random utility modelling context, choice probabilities are unaffected by increasing linear transformations of the systematic utility; hence its empirical specification is derived on the basis that only differences in utility matters and that the scale of utility is arbitrary. We argue that choice probabilities remain unchanged if these linear transformations are made under the deterministic perspective of a single individual choosing several times. But, in the random utility setting, parameter estimates might be significantly affected by these transformations. In particular we focus on the effect of two order-preserving transformations usually applied in the derivation of the representative utility from the conditional indirect utility function: adding a constant to the utility of all alternatives and multiplying each alternative utility by a constant. We concentrate on the two most popular specifications in transport mode choice: the “wage rate” (Train and McFadden Transport Res 12:349–353, 1978) and the “expenditure rate” (Jara-Díaz and Farah Transport Res 22B:159–171, 1987) specifications. Using a collection of synthetic datasets generated in a new fashion directly from the conditional indirect utility function, i.e. before applying any expansion or transformation, we demonstrate how taking this class of order-preserving transformations could lead to misinterpretation of the econometric results, such as detecting randomly distributed and correlated parameters and/or income and time effects which are in fact not present." .
<http://www.springernature.com/scigraph/things/articles/6c8ffcefb4d3543ea6e63f7442ba6ecf> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Accurate forecasting is critically important in many time series applications. In this paper, we consider forecasting chaotic problems by proposing a hybrid model composed of scaled unscented Kalman filter with reduced sigma points and non-linear autoregressive network with exogenous inputs, trained using a modified Bayesian regulation backpropagation algorithm. To corroborate developments of the proposed hybrid model, real-life chaotic and simulated time series which are both non-linear in nature are applied to validate the proposed hybrid model. Experiment results show that the proposed hybrid model outperforms other forecasting models reported in the literature in forecasting of chaotic time series." .
<http://www.springernature.com/scigraph/things/articles/1648cbd97a742057087e59ed30ddbfd4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In 2010 Zenga introduced a new three-parameter model for distributions by size that can be used to represent income, wealth, financial and actuarial variables. This paper proposes a summary of its main properties, followed by a focus on the interpretation of the parameters in terms of inequality. The scale parameter μ is equal to the expectation, and it does not affect the inequality, while the two shape parameters α and θ are inverse and direct inequality indicators respectively. This result is obtained through stochastic orders based on inequality curves. A procedure to generate a random sample from Zenga distribution is also proposed. The second part of this article looks at the parameter estimation. Analytical solution of method of moments is obtained. This result is used as a starting point of numerical procedures to obtain maximum likelihood estimates both on ungrouped and grouped data. In the application, three empirical income distributions are considered and the aforementioned estimates are evaluated. A comparison with other well-known models is provided, by the evaluation of three goodness-of-fit indexes." .
<http://www.springernature.com/scigraph/things/articles/6a6b8c492b54aa9ca6ac596caefe8849> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This research employs a new technique to estimate agglomeration economies, which are omitted from standard Input-Output (I-O) models. The overall economic impact of an economic entity includes the direct and indirect impacts as well as the agglomeration economies. I-O analysis is employed to assess the direct and indirect economic impacts of a research facility. The overall economic impact is estimated by employing a demographic projection model that estimates employment, population, and income in the region without the facility's contribution to the economic landscape. The difference between the overall economic impact and the direct and indirect impacts are attributed to the agglomeration effects of the facility. The findings indicate that agglomeration economies are significant part of the overall economic impact." .
<http://www.springernature.com/scigraph/things/articles/18da573c358baaaabd6bf87219385e39> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This publication discusses new development directions of cognitive economics charted based on cognitive processes of financial data analysis. Semantic analysis tasks will be dedicated to cognitive economics systems. Such systems, which semantically analyse the economic situation of enterprises/organisations/business structures, execute their tasks using semantic information available to them (contained in data sets). The foundation for the operation of economic cognitive systems consists in both the semantic analysis of the situation of an enterprise described by various economic/financial ratios and the assessment of the future situation of this enterprise. Hence cognitive economics is geared towards the semantic analysis of the economic/financial situation of enterprises carried out by means of an in-depth description, an analysis, a reasoning and a projection of the future condition of enterprises. The subject of cognitive economics discussed for the purpose of indicating and elaborating on the directions of this discipline and of semantic analysis of economic/financial data goes hand in hand with the currently growing trend of soft computing. Methods of semantic analysis, just like e.g. neural networks, were developed by researchers inspired by the operation of the human mind. The cognitive, decision-making, reasoning, understanding and prediction processes running in this mind have become the basis for attempts to create information systems analysing various data. This type of analysis, based on extracting semantic aspects and information from the analysed data sets has been aimed at using computational methods to help solve various problems. Since such solutions are dedicated to bioinformatics, cognitive informatics and artificial intelligence, it appeared likely that they could also be used in economics. It is in this regard that the development of semantic data analysis methods (dedicated to economic/financial problems) puts cognitive economics in the same group with all other scientific disciplines making use of soft computing techniques." .
<http://www.springernature.com/scigraph/things/articles/47bb80f027993268a3f8f643cd77d178> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We use a dynamic stochastic general equilibrium model to address two questions about U.S. monetary policy: 1) Can monetary policy elevate output when it is below potential? and 2) Is the zero lower bound a trap? The model’s answer to the first question is yes it can, but the effect is only temporary and probably not welfare enhancing. The answer to the second question is more complicated because it depends on policy. It also depends on whether it is the inflation rate or the real interest rate that will adjust over the longer run if the policy rate is held near zero for an extended period. We use the Fisher equation to analyze possible outcomes for situations where the central bank has promised to keep the interest rate near zero for an extended period." .
<http://www.springernature.com/scigraph/things/articles/c9ec5cea97add5caa6a7affc203f329c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper offers evidence on the sensitivity of child poverty in South Africa to changes in the adult equivalence scale (AES) and updates the child poverty profile based on the Income and Expenditure Survey 2005/06. Setting the poverty line at the 40th percentile of households calculated with different AESs the scope and composition of child poverty are found to be relatively insensitive to the scale used. The rankings of children of different ages, girls versus boys, racial groupings and children living in rural versus urban areas are unaffected by choice of AES, although some provincial rankings on the poverty headcount measure are. The proportions of children and households ‘correctly’ identified as poor for the full range of scales is extremely high. These findings support the argument that it may be appropriate for profiling poverty in South Africa to use a poverty line based on a per capita welfare measure. For the construction of the child poverty profile, per capita income is used as the welfare indicator with the poverty line set at the 40th percentile of household. The profile suggests that poverty amongst children is more extensive than amongst the population or adults even after the massive injection of transfers into households with poor children through the child support grant. The child poverty headcount, depth and severity are all highest amongst children age 0–4 and lowest amongst those aged 15–17, who are not yet beneficiaries of the grants. They are also highest amongst African and Coloured children. Large variations across provinces remain. The analysis underlines the importance of prioritising children in the fight against poverty, particularly in their earliest years." .
<http://www.springernature.com/scigraph/things/articles/b0ac33b4559c6277b4333eb205985cea> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. A small Almost Ideal Demand System is estimated for Greek meat consumption using the Johansen procedure in conjunction with parametric bootstrapping and Bartlett corrections. Asymptotic Wald and likelihood ratio tests broadly support the predicted number of cointegrating relationships but reject symmetry and homogeneity. Bootstrapping and Bartlett corrections give support to symmetry and homogeneity but give less support for the predicted number of cointegrating relationships." .
<http://www.springernature.com/scigraph/things/articles/c5ef9f22eb368c2689263a97f5335a68> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Forecasting has often played predominant roles in daily life as necessary measures can be taken to bypass the undesired and detrimental future prompted by this fact, the issue of forecasting becomes one of the most important topics of research for the modern scientists and as a result several innovative forecasting techniques have been developed. Amongst various well-known forecasting techniques, fuzzy time series-based methods are successfully used, though they are suffering from some serious drawbacks, viz., fixed sized intervals, using some fixed membership values (0, 0.5, and 1) and moreover, the defuzzification process only deals with the factor that is to be predicted. Additionally, most of the existing and widely used fuzzy time series-based forecasting algorithms employ their own clustering techniques that may be data-dependent and in turn the predictive accuracy decrease. Prompted by the fact, the present author developed a novel multivariate fuzzy forecasting algorithm that is able to remove all the drawbacks as also can predict the future occurrences with better predictive accuracy. Moreover, the comparisons with the thirteen other existing frequently used forecasting algorithms (viz., conventional, fuzzy time series-based algorithms and ANN) were performed to demonstrate its better efficiency and predictive accuracy. Towards the end, the applicability and predictive accuracy of the developed algorithm has been demonstrated using three different data sets collected from three different domains, such as: oil agglomeration process (coal washing technique), frequently occurred web error prediction and the financial forecasting. The real dataset related to oil agglomeration was collected from CIMFER, Dhanbad, India, that regarding the frequently occurred web error codes of www.ismdhanbad.ac.in, the official website of ISM Dhanbad, was collected from the Indian School of Mines (ISM) Dhanbad, India server and the finance data set was collected from the Ministry of Statistical and Program Implementation (Govt. of India)." .
<http://www.springernature.com/scigraph/things/articles/ffeefcfc7f86ebbbd89b07e65b675f5d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In the present study, a stationary stochastic ARMA/ARIMA [Autoregressive Moving (Integrated) Average] modelling approach has been adapted to forecast daily mean ambient air pollutants (O3, CO, NO and NO2) concentration at an urban traffic site (ITO) of Delhi, India. Suitable variance stabilizing transformation has been applied to each time series in order to make them covariance stationary in a consistent way. A combination of different information-criterions, namely, AIC (Akaike Information Criterion), HIC (Hannon–Quinn Information Criterion), BIC (Bayesian Information criterion), and FPE (Final Prediction Error) in addition to ACF (autocorrelation function) and PACF (partial autocorrelation function) inspection, has been tried out to obtain suitable orders of autoregressive (p) and moving average (q) parameters for the ARMA(p,q)/ARIMA(p,d,q) models. Forecasting performance of the selected ARMA(p,q)/ARIMA(p,d,q) models has been evaluated on the basis of MAPE (mean absolute percentage error), MAE (mean absolute error) and RMSE (root mean square error) indicators. For 20 out of sample forecasts, one step (i.e., one day) ahead MAPE for CO, NO2, NO and O3, have been found to be 13.6, 12.1, 21.8 and 24.1%, respectively. Given the stochastic nature of air pollutants data and in the light of earlier reported studies regarding air pollutants forecasts, the forecasting performance of the present approach is satisfactory and the suggested forecasting procedure can be effectively utilized for short term air quality forewarning purposes." .
<http://www.springernature.com/scigraph/things/articles/5dcbe27a150eef93dd2cfecb8c31bc05> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In various markets around the country, some real estate professionals are employing a new pricing strategy that involves marketing homes for sale with a price range rather than a single asking price. This strategy is often touted as a mechanism that will attract more potential buyers to look at a house and thus result in reduced marketing times for existing homes, with prices determined by competitive forces. The purpose of this study is to empirically examine whether houses using range pricing, often referred to as value range marketing, sell in the same amount of time and sell for similar prices as those marketed in the traditional manner. Two staged least squares with a correction for sample selection and Weibull duration models are used to test the hypotheses, employing a sample of 5,852 residential houses that were sold during the period January 1999 to December 2000. In contrast to claims of the strategy’s proponents, the results indicate that houses take longer to sell when using the range pricing strategy after controlling for physical characteristics and market conditions. Furthermore, there is no evidence that this strategy has any significant impact on transaction prices." .
<http://www.springernature.com/scigraph/things/articles/3615b8c45c0616c95341b8bd1b6d3a99> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract An improved empirical method for the plotting of field data and the calculation of tephra fall volumes is presented. The widely used “area” plots of ln(thickness) against ln(isopach area) are curved, implying an exponential thinning law. Use of ln(thickness)−(area)1/2 diagrams confirm the exponential dependence of many parameters (e.g. thickness, maximum and median clast size) with distance from source, producing linear graphs and allowing volumes to be calculated without undue extrapolation of field data. The agreement between theoretical models of clast dispersion and observation is better than previously thought. Two new quantitative parameters are proposed which describe the rates of thinning of the deposit (b t the thickness half-distance) and the maximum clast size (b c the clast half-distance). Many deposits exhibit different grainsize and thickness thinning rates, with the maximum clast size diminishing 1–3 times slower than the thickness. This implies that the entrained grainsize population influences the morphologic and granulometric patterns of the resulting deposit, in addition to the effects of column height and wind-speed. The grainsize characteristics of a deposit are best described by reference to the half-distance ratio (b c /b t ). A new classification scheme is proposed which plots the half-distance ratio against the thickness half-distance and may be contoured in terms of the column height." .
<http://www.springernature.com/scigraph/things/articles/6092159ff54a797a24b26af4c7c5f7d4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The long-term effects of different cadmium (0.2 and 0.4 ppm) and salinity levels (30, 25, and 20 ‰ S) on growth and egg-mass production ofOphryotrocha labronica (La Greca & Bacci) were investigated over three generations. Low salinity levels and the presence of cadmium resulted in reduced growth rates, prolonged times to reach sexual maturity, and reduced size at maturity. Three-way analysis of variance showed significant interaction effects of generation and cadmium for the different growth processes tested. Using response-surface methods, 0.2 ppm cadmium was shown to have a greater effect on growth rate at the third generation than the first and second generations at the three salinities tested. Increased effects were observed from first to second generation at 0.4 ppm cadmium and 30 and 25 ‰ S, whereas effects decreased from second to third generation. At 0.4 ppm cadmium and salinity of 20 ‰ the first generation was not able to produce viable larvae." .
<http://www.springernature.com/scigraph/things/articles/7b603b28c31134c494b5c6b2689f2157> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The discussions on Renminbi (RMB) exchange rate could not depart from the ongoing reform of RMB exchange rate regime, which must be designed and promoted as an integral part of the large open economy macroeconomic policy framework. As a large open economy facing the Trilemma, China should explicitly establish the principle of domestic monetary policy dominance in the impossible trinity, with the exchange rate policy and capital account management should both conform to this fundamental principle. Simplistically pegging RMB to the US dollar will result in lack of flexibility and violate this principle, especially against the backdrop of unsynchronized economic cycles of major economies and the prospect of further Fed tighten up that the real effective exchange rate of RMB moves passively along with the US dollar which cannot reflect the relative changes in economic fundamentals in China and abroad, which will cause distortions, resulting in resource misallocations and loss of welfare. The reform of RMB exchange rate regime should be market-oriented, towards a direction with more flexibility." .
<http://www.springernature.com/scigraph/things/articles/4797174bb4ac80b08bb5e52a064f1548> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Neural network time series forecasting error comprises autocorrelation error, due to an imperfect model, and random noise, inherent in the data. Both problems are addressed here, the first using a two stage training, growth-network neuron: the autocorrelation error (ACE) neuron. The second is considered as a post-processing noise filtering problem. These techniques are applied in forecasting the sunspot time series, with comparison of stochastic, BFGS and conjugate gradient solvers." .
<http://www.springernature.com/scigraph/things/articles/eaeb56f4dc4c9b6fc891e895745f27c9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we develop a monitoring procedure for an early detection of parameter changes in time series models. We design the monitoring procedure in general time series models and apply it to the changes for the autocovariances of linear processes, GARCH parameters, and underlying distributions. Simulation results are provided for illustration." .
<http://www.springernature.com/scigraph/things/articles/e5c5629d425e250776e6d3bd36266fee> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. Using $J/\\psi$ and open charm photoproduction data, we apply the vector meson dominance model to obtain constraints on the energy dependence of the inelastic $J/\\psi$-nucleon cross section. Predictions of short distance QCD are in accord with these constraints, while recently proposed hadronic models for $J/\\psi$ dissociation strongly violate them." .
<http://www.springernature.com/scigraph/things/articles/4da6ac341faa53c80efae356b7489400> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this study an attempt is made to establish new bibliometric indicators for the assessment of research in the Humanities. Data from a Dutch Faculty of Humanities was used to provide the investigation a sound empirical basis. For several reasons (particularly related to coverage) the standard citation indicators, developed for the sciences, are unsatisfactory. Target expanded citation analysis and the use of oeuvre (lifetime) citation data, as well as the addition of library holdings and productivity indicators enable a more representative and fair assessment. Given the skew distribution of population data, individual rankings can best be determined based on log transformed data. For group rankings this is less urgent because of the central limit theorem. Lifetime citation data is corrected for professional age by means of exponential regression." .
<http://www.springernature.com/scigraph/things/articles/a584d43963ea5b1af4ee2f1b4fa69f25> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The alternative and graduated methods for estimation of fast-reversible effects of ethanol are compared. Estimation of the myorelaxing and anticonvulsive effects of ethanol by the alternative method can be used with some limitations for the effector analysis of ethanol pharmacokinetics. It is shown that the effector expectation of pharmacokinetic profile for ethanol based on the minimal effective doses of bicuculline inducing clonic convulsions and tonic extension is comparable to experimentally determined brain contents of14C-ethanol." .
<http://www.springernature.com/scigraph/things/articles/1db15defdc3fe544d0813c3c71140a3b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Using panel data for 94 countries in 1975–97, we estimate OLS, 2SLS and GMM regressions to explain IMF and IBRD lending as well as monetary and fiscal policies in the recipient countries. With respect to moral hazard, we find that a country's government budget deficit and its rate of monetary expansion are higher the larger its borrowing potential in the Fund. New net lending of the Bank (relative to GDP) raises monetary expansion but lowers budget deficits of the recipient countries while new net credit from the Fund is associated with less expansionary policies. As for political business cycles, our evidence indicates that new net credits from the IMF are significantly larger prior to elections and that borrowing from the IBRD is significantly smaller after elections." .
<http://www.springernature.com/scigraph/things/articles/a7a76d3d005c9da6e43e97bf8370fc05> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Studies of U.S. loan and deposit markets have found that consumer interest rates respond asymmetrically to changes in market rates. If this finding is repeated across many different consumer finance product markets, then it could have important implications for the transmission mechanism of monetary policy. This paper tests for significant interest rate asymmetries in consumer finance markets that differ markedly from those examined in the existing literature. The main result of this paper is to reject the hypothesis of significant asymmetries in most (but not all) of the longer-term loan and deposit markets examined in Canada and the United States. This indicates that the explanations for asymmetries given in the literature are not generalizable across different product markets in different countries." .
<http://www.springernature.com/scigraph/things/articles/570b1356e76e2a1c85889f12bd2154c6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We pursue the robust approach to pricing and hedging in which no probability measure is fixed, but call or put options with different maturities and strikes can be traded initially at their market prices. We allow the inclusion of robust modelling assumptions by specifying a set of feasible paths on which (super)hedging arguments are required to work. In a discrete-time setup with no short selling, we characterise absence of arbitrage and show that if call options are traded, then the usual pricing–hedging duality is preserved. In contrast, if only put options are traded, a duality gap may appear. Embedding the results into a continuous-time framework, we show that the duality gap may be interpreted as a financial bubble and link it to strict local martingales. This provides an intrinsic justification of strict local martingales as models for financial bubbles arising from a combination of trading restrictions and current market prices." .
<http://www.springernature.com/scigraph/things/articles/75f7ad37de7d75b4aa22c7eaf450da3c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper proposes a nonparametric approach to estimating the dependence relationships between circular variables and other circular or linear variables using copulas. The proposed method is based on the use of Bernstein copulas which are a very flexible class of non-parametric copulas which allows for the approximation of any kind of dependence structure, including non symmetric relationships. In particular, we present a simple procedure to adapt Bernstein copulas to the circular framework and guarantee that the constructed bivariate distributions are strictly continuous. We provide two illustrative case studies, the first on the relation between wind direction and quantity of rainfall in the North of Spain and the second on the dependence between the wind directions in two nearby buoys at the Atlantic ocean." .
<http://www.springernature.com/scigraph/things/articles/d8cf294c9b7146951069ed510e4bf058> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article employs a Theil decomposition analysis to examine various dimensions of income inequality, using the 2007 Indonesian Family Life Survey. The empirical strategy is based on the individual-level income data—instead of group means as in the existing literature—and thus accounts for within-group dispersion of individual incomes. The decomposition exercise reveals that income inequality across education levels constitutes about 13 % of total income inequality. The urban–rural and interprovincial dimensions individually explain 6.0–6.5 %, but the contribution of income inequality by genders appears to be negligible. The findings highlight educational reform as an effective redistributive policy." .
<http://www.springernature.com/scigraph/things/articles/187ffaedde2d502e7694e1ac29cbac01> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Forecasts of seasonal snowmelt runoff volume provide indispensable information for rational decision making by water project operators, irrigation district managers, and farmers in the western United States. Bayesian statistical models and communication frames have been researched in order to enhance the forecast information disseminated to the users, and to characterize forecast skill from the decision maker's point of view. Four products are presented: (i) a Bayesian Processor of Forecasts, which provides a statistical filter for calibrating the forecasts, and a procedure for estimating the posterior probability distribution of the seasonal runoff; (ii) the Bayesian Correlation Score, a new measure of forecast skill, which is related monotonically to theex ante economic value of forecasts for decision making; (iii) a statistical predictor of monthly cumulative runoffs within the snowmelt season, conditional on the total seasonal runoff forecast; and (iv) a framing of the forecast message that conveys the uncertainty associated with the forecast estimates to the users. All analyses are illustrated with numerical examples of forecasts for six gauging stations from the period 1971–1988." .
<http://www.springernature.com/scigraph/things/articles/c9cb564da2fdc5f48a7f96b4ebe9616b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We consider a (nonlinear) autoregressive model with unknown parameters (vector θ). The aim is to estimate the density of the residuals by a kernel estimator. Since the residuals are not observed, the usual procedure for estimating the density of the residuals is the following: first, compute an estimator $$\\hat \\theta $$ for θ; second, calculate the residuals by use of the estimated model; and third, calculate the kernel density estimator by use of these residuals. We show that the resulting density estimator is strong consistent at the best possible convergence rate. Moreover, we prove asymptotic normality of the estimator." .
<http://www.springernature.com/scigraph/things/articles/82e61c029d2ad1f68a4680afc420ac48> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The development of activity-based models as a tool to analyse travel behaviour and forecast transport demand has been motivated by the growing complexity in activity patterns resulting from socio-economic changes, growing congestion, and negative externalities, as well as the need to estimate changes in travel behaviour in response to innovative policies designed to achieve sustainability. This paper reviews how the trade-off between behavioural realism and complexity, one of the main challenges facing the travel-demand modeler, is made in the best practical activity-based models. It proposes an approach that captures key behavioural aspects and policy sensitivities, while remaining practical with reasonable requirements of computational resources. The three main model elements in this trade-off—model structure, data, and application method—are analysed. Drawing on examples from a model developed for Tel Aviv and from existing US models, this paper shows that behavioural realism and policy sensitivity can be achieved with a reasonable level of model complexity." .
<http://www.springernature.com/scigraph/things/articles/0c84c5eab89e4793afbf1f2d557ec4cb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study aimed at characterization of rainfall dynamics in a hot arid region of Gujarat, India by employing time-series modeling techniques and sustainability approach. Five characteristics, i.e., normality, stationarity, homogeneity, presence/absence of trend, and persistence of 34-year (1980–2013) period annual rainfall time series of ten stations were identified/detected by applying multiple parametric and non-parametric statistical tests. Furthermore, the study involves novelty of proposing sustainability concept for evaluating rainfall time series and demonstrated the concept, for the first time, by identifying the most sustainable rainfall series following reliability (R y), resilience (R e), and vulnerability (V y) approach. Box–whisker plots, normal probability plots, and histograms indicated that the annual rainfall of Mandvi and Dayapar stations is relatively more positively skewed and non-normal compared with that of other stations, which is due to the presence of severe outlier and extreme. Results of Shapiro–Wilk test and Lilliefors test revealed that annual rainfall series of all stations significantly deviated from normal distribution. Two parametric t tests and the non-parametric Mann–Whitney test indicated significant non-stationarity in annual rainfall of Rapar station, where the rainfall was also found to be non-homogeneous based on the results of four parametric homogeneity tests. Four trend tests indicated significantly increasing rainfall trends at Rapar and Gandhidham stations. The autocorrelation analysis suggested the presence of persistence of statistically significant nature in rainfall series of Bhachau (3-year time lag), Mundra (1- and 9-year time lag), Nakhatrana (9-year time lag), and Rapar (3- and 4-year time lag). Results of sustainability approach indicated that annual rainfall of Mundra and Naliya stations (R y = 0.50 and 0.44; R e = 0.47 and 0.47; V y = 0.49 and 0.46, respectively) are the most sustainable and dependable compared with that of other stations. The highest values of sustainability index at Mundra (0.120) and Naliya (0.112) stations confirmed the earlier findings of R y–R e–V y approach. In general, annual rainfall of the study area is less reliable, less resilient, and moderately vulnerable, which emphasizes the need of developing suitable strategies for managing water resources of the area on sustainable basis. Finally, it is recommended that multiple statistical tests (at least two) should be used in time-series modeling for making reliable decisions. Moreover, methodology and findings of the sustainability concept in rainfall time series can easily be adopted in other arid regions of the world." .
<http://www.springernature.com/scigraph/things/articles/0f7dbc63ae9f2bc09c0d9425dc092f3c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study examines the price discovery process and relative efficiency of ten most liquid agricultural commodities’ futures contracts, traded on the largest agricultural commodity exchange of India (National Commodity and Derivative Exchange Limited). Three different common factor methodologies—component share method (Gonzalo and Granger in J Bus Econ Stat 13:27–35, 1995), information share method (Hasbrouck in J Financ 50:1175–1199, 1995), and modified information share method (Lien and Shrestha in J Futures Mark 29:377–395, 2009)—have been employed to determine the extent of price discovery contribution by spot and futures markets. The sample consists of daily data for the period from January 1, 2009 to October 20, 2015. Stationarity and Cointegration test results reveal that spot and futures prices are integrated and cointegrated for all commodities. The price discovery results show that the futures market leads the spot market in case of six commodities, i.e., castor seed, coriander, cottonseed oilcake, soy oil, sugarM and turmeric. Whereas, in the case of four commodities (chana (chickpea), guar seed, jeera, and mustard seed), price discovery takes place in the spot market. Therefore, it could be inferred that futures market is more efficient in price discovery of agricultural commodities. Policymakers could use these results to design futures contracts on other commodities or to plan concrete policies to curb speculation without hampering the efficiency of the agricultural commodity derivatives market." .
<http://www.springernature.com/scigraph/things/articles/9a2d764c2fcc344b360e8a3d67c53f2f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Electricity, an indispensable resource in daily life and industrial production, is hard to store, so accurate short-term load forecasting (STLF) plays a vital role in resource allocation, capital budgeting of power companies, energy deployment and government control. In recent decades, the strong dependency relationships of time series have been considered in many researches, but the discrete information has not proven to be very useful in their experiments. In general, while discrete information is weak, it can provide macro trends compared to the micro trends of continuous information. In this research, we aim to combine macro and micro information by continuous and discrete time series to generate multiple time series (MTS). The MTS comprise four information sequences: short-term, cycle, long short-term and cross-long short-term. These MTS are used to build a STLF system using a recurrent neural network (RNN) model that can learn sequential information between continuous and discrete series. Therefore, the RNN model with MTS information can improve the forecasting performance for short-term load forecasting. The experimental results show that our proposed forecasting system outperforms the state-of-the-art approach." .
<http://www.springernature.com/scigraph/things/articles/7db16e0baa593892b1261150274e3408> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The relationships between growth, inequality, and poverty is widely discussed area in the development economics, which fairly overcrowded by linear and non-linear growth components, however, while developing an index for pro-poor growth, the non-linearity portion of growth has been widely ignored that address in this study by using a panel of 18 selected Latin America and the Caribbean countries from 1981 to 2012. The study proposed a new measure of pro-poor growth index, called ‘Poverty Interdependence Growth Index (PIGI)’, which further extended in order to satisfy the monotonicity criterion of pro-poor growth and poverty reduction, called ‘Poverty Interdependence Equivalent Growth Rate (PIEGR)’. The results show that the impact of per capita survey income and income inequality on poverty measures are ‘linear’ in nature when controlling the non-linear components of growth, however, if this assumption is relaxed, the study doesn’t established either ‘U-shaped’ and/or ‘asymptotic’ relationship between the variables. The non-poverty measures including educational expenditures, health expenditures and population growth significantly increases F–G–T measures of poverty. The estimates of PIGI and PIEGR reveal that out of 18 countries, there are 4 countries shows highly pro-poor growth, 11 countries shows negative pro-poor growth index (i.e., immiserizing growth scenarios, where a positive growth increases poverty), and the remaining 3 countries shows pro-rich. The study illustrates that our new measure of pro-poor growth index fairly provides conclusive findings." .
<http://www.springernature.com/scigraph/things/articles/e32638d090849fe20ecf2ad0f5c4f81b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The past two decades have witnessed an increasing interest in the use of space-time models for a wide range of environmental problems. The fundamental tool used to embody both the temporal and spatial components of the phenomenon in question is the covariance model. The empirical estimation of space-time covariance models can prove highly complex if simplifying assumptions are not employed. For this reason, many studies assume both spatiotemporal stationarity, and the separability of spatial and temporal components. This second assumption is often unrealistic from the empirical point of view. This paper proposes the use of a model in which non-separability arises from temporal non-stationarity. The model is used to analyze tropospheric ozone data from the Emilia-Romagna Region of Italy." .
<http://www.springernature.com/scigraph/things/articles/fd130f279803c835292d5382252c7160> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The issue of whether the UK should join the European single currency has been fiercely debated for the past two decades. However little research has been devoted to forecasting hypothetical projections for important UK economic variables, assuming that the UK had in fact joined the euro at its inception in 1999. This paper focuses on estimating counterfactual series for two key macroeconomic variables: unemployment and output. We do this by estimating Phillips curves for the UK, which we then use to compute counterfactual series for what unemployment and output may have looked like for the UK had they adopted the single currency in 1999. Based on the comparison of our forecasts with observed data, we find that the UK was correct in not joining the euro; had they adopted the European single currency in 1999, unemployment would have been higher and output would have been lower." .
<http://www.springernature.com/scigraph/things/articles/23918a4c3759779c153891d45577e0a4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper tests for the existence of adverse selection in the Brazilian individual health insurance market in 2003. The testing approach adapts that conceived by Chiappori and Salanié (Eur Econ Rev 41, 943–950, 1997; J Polit Econ 108, 56–78, 2000). After controlling for sex, age, income, number of dependents, occupational groups and schooling levels, the evidence favors adverse selection as indicated by a positive correlation between the coverage of the contract and occurrence of illnesses (as approximated by hospitalization) was not strong. The consideration of complex sampling in the probit estimations led to empirical evidence that does not indicate the presence of adverse selection, but which highlighted some interesting features of the relationship between the selected variables." .
<http://www.springernature.com/scigraph/things/articles/22ecdf7e5c1f5c67a728933bf9b128dd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A stochastic growth model with money introduced via a cash-in-advance constraint is used to analyze the behavior of the income velocity of real monetary balances and money demand. Agents can purchase consumption goods only using government issued money. The cash-in-advance constraint may become nonbinding because of the uncertainty about the realization of the state of the economy. We find that the precautionary money demand may introduce significant changes into the volatility of the income velocity if it happens almost always. Its presence can also alter the relationship between the average growth rate of money supply and the average growth rate of the economy." .
<http://www.springernature.com/scigraph/things/articles/c9a95e3f1b13b8404246a061a33aed20> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Objective of this paper is to enhance the understanding of modelling jumps and to analyse the model risk based on the jump component in electricity markets. We provide a common modelling framework that allows to incorporate the main jump patterns observed in electricity spot prices and compare the effectiveness of different jump specifications. To this end, we calibrate the models to daily European Energy Exchange (EEX) market data through Markov Chain Monte Carlo based methods. To assess the quality of the estimated jump processes, we analyse their trajectorial and statistical properties. Moreover, even when the models are calibrated to a cross-section of derivative prices substantial model risk remains." .
<http://www.springernature.com/scigraph/things/articles/554356f1c10437aec29c6da89569a597> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper looks at the relationship between output variability and economic growth in Australia using the ARCH-M model. Quarterly data for growth rates of industrial production and of GDP are used for the analyses. However, the growth of GDP does not show any ARCH effects. The variability is found to be significantly negatively related to the growth rate of industrial production. Unlike Caporale and McKiernan (1998), our empirical results do not support Black's (1987) hypothesis, which is that there is a positive relationship between output variability and economic growth. Our results support the Keynesian position." .
<http://www.springernature.com/scigraph/things/articles/b6a16989e3f90c7965db273c15dc2392> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A sequential adjustment procedure is proposed for the direct estimation of point—velocities in deformation analysis networks. At any intermediate stage of the adjustment the up-to-date covariance matrix of those velocities tells the evolving story of the network in terms of solvability and reliability. A pre-zero-epoch covariance matrix is utilized for a smooth and flexible treatment of two characteristic problems of deformation analysis:- high turnover of points in the network- processing variable and generally incomplete observational batches. A small numerical example is presented at the end as an illustration." .
<http://www.springernature.com/scigraph/things/articles/c5086fbb01c23804ca6d7e70d029fcc2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Ventricular fibrillation (BF) is a poorly understood yet potentially lethal cardiac arrhythmia. The electrocardiogram (ECG) time series of VF is investigated by comparison of the linear and non-linear features of VF time series and surrogates in which internal correlations have been destroyed. From 40 ECG time series of human VF and 40 surrogate time series, three quantities are evaluated: the percentage of the linear time-frequency distribution (TFD) exceeding a threshold, the non-linear coarsegrained correlation dimension (Dcg), and the percentage of diagonal lines in the non-linear recurrence plot longer than 10 elements (D10). It is found that the mean (SD) percent threshold TFD and Dcg are higher for the surrogates (6.7% (1.3) and 5.3 (0.6)) than the VF time series (5.6% (0.7) and 3.8(0.9)) whereas the mean D10 is higher for the VF time series (49% (13)) than the surrogates (32% (7)). All of these differences are significant (p<0.0001) and indicate greater order in the VF time series than in the surrogates. It is therefore shown that both linear and non-linear signal analysis demonstrate order in the ECG time series of VF." .
<http://www.springernature.com/scigraph/things/articles/f06704884d671c9092314e3d44aa6ee4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary. An auction with a buyout option is modelled. Such an option allows a bidder to purchase the item being auctioned at a pre-specified buyout price, instead of attempting to obtain the item through the traditional auction procedure. This analysis is motivated by internet auctions where such options are present. If all auction participants are risk neutral, the seller will choose a buyout price high enough so that the option is never exercised. However, a risk averse seller facing risk neutral bidders will choose a price low enough so that the option is exercised with positive probability. Further, if bidders are risk neutral and the seller is risk averse, this option may result in a Pareto improvement compared to a sealed bid second price auction." .
<http://www.springernature.com/scigraph/things/articles/eddbbac6c40447a4ba9fcd1c7640d360> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper, the second in the series, verifies the entropy-based univariate model developed in the first paper for long-term streamflow forecasting on five rivers from different regions of the world. The results of the model are compared with the corresponding results of ARIMA and state-space model. The Lagrange multipliers of the univariate model are found similar to autocorrelation coefficients of the ARIMA model. Forecasts by ARIMA and univariate models were comparable for periodic streamflow, but for forecasting of highly variable streamflows the univariate model was superior." .
<http://www.springernature.com/scigraph/things/articles/ff481801db680ff5ee010edecddf49de> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract If a given dynamical process contains an inherently unpredictable component, it may be modeled as a stochastic process. Typical examples from financial markets are the dynamics of prices (e.g. prices of stocks or commodities) or fundamental rates (exchange rates etc.). The unknown future value of the corresponding stochastic process is usually estimated as the expected value under a suitable measure, which may be determined from distribution of past (historical) values. The predictive power of this estimation is limited by the simplifying assumptions of common calibration methods. Here we propose a novel method of “intelligent” calibration, using learning (2-layer) neural networks in order to dynamically adapt the parameters of a stochastic model to the most recent time series of fixed length (memory depth) to the past. The process parameters are determined by the weights of the intermediate layer of the neural network. The final layer combines these parameters in a meaningful manner yielding the forecasting value for the stochastic process. On each actual finite memory, the neural network is trained by back-propagation, obtaining a much more flexible and realistic parameter calibration than an analogous fit to an autoregressive models could do. In the context of processes related to financial assets, the final combination of the output layer relates to their market-price-of-risk. The back propagation is limited to the typical memory length of the financial market (for example 10 previous business days). We demonstrate the learning efficiency of the new algorithm by tracking the next-day forecasts with one typical examples each, for the asset classes of currencies and stocks." .
<http://www.springernature.com/scigraph/things/articles/2c7a876ebe372b34842ec53baa64499d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Following the 2008–2009 Global Financial Crisis, many countries, including Australia, enacted fiscal stimulus packages in the hope of reviving their economies by encouraging aggregate demand. For the success of these efforts, it is vital that fiscal policies have some positive impact on the real economy. However, tax reductions and cash handouts are virtually ineffective if consumers are Ricardian and internalise the intertemporal budget constraint of the government. This paper aims to test the Ricardian equivalence hypothesis for Australia from 1960 to 2011 by exploiting the links between (1) Ricardian equivalence and the Lucas critique; (2) the Lucas critique and super exogeneity, and (3) testing for super exogeneity with impulse-indicator saturation. As there is no evidence of a structural break in the conditional model for the growth rate of per capita real gross domestic savings, we conclude that policy-regime shifts did not lead to substantial changes in the estimated relationship, so the Lucas critique does not apply. Consequently, our results indicate that during the past half-century Ricardian equivalence held in Australia. This implies that tax and cash bonuses of the government may not lead to the desired economic outcomes as Ricardian-type consumers tend to offset the dissaving of the government by saving more and leaving household consumption unchanged." .
<http://www.springernature.com/scigraph/things/articles/725bd74da84ad83d59f2cca237f9e7a9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Models that assume bonds denominated in different currencies are perfect substitutes can not explain certain empirical puzzles: the exchange rate volatility puzzle is that these models can not explain the observed volatility in real and nominal exchange rates; the Backus-Smith puzzle is that these models can not explain the observed low correlation between real exchange rates and the ratio of home to foreign consumption; the Backus-Kehoe-Kydland puzzle is that these models can not explain the observed low correlation between home and foreign consumption; and finally, the uncovered interest parity puzzle is that these models can not explain the observed deviations from that parity. These long standing puzzles make the models harder to defend. In this paper, we present a symmetric two country portfolio balance model in which home and foreign bonds are imperfect substitutes for money in each country’s transactions technology; this of course makes home and foreign bonds imperfect substitutes for each other. Our calibrated model is capable of addressing the Backus-Smith puzzle and the Backus-Kehoe-Kydland puzzle. It does not fully resolve the exchange rate volatility puzzle, but it makes some headway. And finally it generates deviations from uncovered interest parity, though by some estimates these deviations are not large enough to be consistent with the data." .
<http://www.springernature.com/scigraph/things/articles/7bcf508a7bc1f28f8deb6cecd22c8149> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Mail-order and internet sellers must decide how customers pay shipping charges. Typically, these sellers choose between two pricing policies: either “uniform pricing,” where the firm delivers to any customer at a fixed delivery charge (that may be volume dependent), or “mill pricing,” where the firm bills the customer a distance-related shipping charge. This paper studies price competition between a mail-order (or internet) seller and local retailers, and the mail-order firm’s choice of pricing policy. The price policy choice is studied when retailers do not change price in reaction to the mail-order firm’s policy choice, and when they do. In the second case, a two-stage non-cooperative game is used and it is found that for low customer willingness to pay, mill pricing is favored but as willingness to pay rises, uniform pricing becomes more attractive. These results are generalized showing that larger markets, higher transportation rates, higher unit production cost, and greater competition between retailers all increase profit under mill pricing relative to uniform pricing (and vice versa). On the other hand, cost asymmetries that favor the mail-order firm will tend to induce uniform rather than mill pricing. Some empirical data on retail and mail-order sales that confirm these results are presented." .
<http://www.springernature.com/scigraph/things/articles/61f13c832805492abc932b921b1e0d24> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This research paper attempts to develop an appropriate econometric model for regional incentives and location choice of new firms in India. The alternative econometric models of location choice include ordinary least squares, multinomial logit model, Poisson (count) model, conditional logit model and nested logit model. The present study utilised two-level Nested logit model, a discrete choice regression technique, to estimate the influence of regional incentives on the location choice of new firms in India. In considering what groupings of location choices to use for the upper nest of the tree structure, we simply categorised areas into designated and non-designated status, as defined by policy. We divided the area in two nests or subgroups, or regions: the Special Category States or the Beneficiary States (Jammu and Kashmir, Himachal Pradesh and Uttarakhand) which have been granted special investment incentives package and the Control Group or the Non-Beneficiary Neighbouring States (Haryana, Punjab and Uttar Pradesh) which were given no regional incentives. We have considered only firms established between 2002–2003 and 2010–2011. The independent variables considered for the analysis include investment incentives (dummy variable), manufacturing agglomeration, market potential and land cost. The nested logit model was estimated with full information maximum likelihood estimation using Stata software. The estimation validated the importance of regional fiscal incentives and manufacturing agglomeration as the most important determinants of industrial location." .
<http://www.springernature.com/scigraph/things/articles/af7a7e495a7c23247d3e49640a3ccb1a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A Nearest Neighbor Method (NNM) is used to forecast daily river flows that were measured at a single location over a time period spanning about seventy years. A parsimonious three parameter NNM is developed in the context of Nonlinear Dynamics and the dependence between forecast error and length of history used to construct forecasts is investigated. Comparison is made to Auto-Regressive Integrated Moving Average (ARIMA) models. The NNM is found to provide improved forecasts." .
<http://www.springernature.com/scigraph/things/articles/6a298e392703c301f8b345278d24b432> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract By applying the non-parametric Data Envelopment Analysis (DEA) method, even with all the limitations where error could cause significant problems, this paper attempts to investigate the efficiency of 35 Microfinance institutions in the Mediterranean zone during the period of 2004–2005. The estimated results prove that eight institutions are relatively efficient, and have a notable level of average efficiency and a potential of evolution while being referent to their technical efficiency. The survey also reveals that the size of the MFIs has a negative effect on their efficiency since the MFIs of medium size are more efficient than the eminent." .
<http://www.springernature.com/scigraph/things/articles/d57cca4f24c42b359be116297bf5f4b7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We construct a simple two-phase model of the nucleon structure functions valid for both small and large $Q^2$ and in the broad range of Bjorken x. The model incorporates hadron dominance at small x and $Q^2$ and parton model at large $Q^2$. The VDM contribution is modified for small fluctuation times of the hadronic state of the photon. With two free parameters we describe SLAC, CERN NMC, Fermilab E665 and CERN BCDMS data for both proton and deuteron structure functions. Our model explains some phenomenological higher-twist effects extracted from earlier analyses. A good description of the NMC $F_2^p(x) - F_2^n(x)$ data is obtained in contrast to other models in the literature. We predict faster vanishing of the partonic component at low $Q^2$ than previously expected and strong $Q^2$ dependence of the Gottfried Sum Rule below $Q^2 \\approx$ 4 GeV$^2$." .
<http://www.springernature.com/scigraph/things/articles/021ec7022619f3660c49bdcfaa3440fd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Large external imbalances and fragile fiscal positions have emerged as major policy challenges for the euro area in the financial crisis. The paper analyses whether shifting government purchases between tradable and non-tradable goods could help reduce external fluctuations without large swings in the overall fiscal stance. The policy rules considered are budgetary-neutral in the sense that the overall level of government expenditure is kept constant. We compare the policy rules to fiscal devaluation as a strategy to reduce external imbalances and find that state-dependent changes in the composition of government purchases between tradables and non-tradables can stabilise excessive fluctuations in the event of economy-wide supply and demand shocks. Contrary to fiscal devaluation, the expenditure-shifting rule faces a trade-off between stabilising domestic activity and enhancing household welfare, on the one hand, and reducing excessive fluctuations in external positions, on the other hand. The excess volatility of domestic variables associated less volatility in the external position implies welfare losses for standard specifications of household utility. The adverse welfare effect is absent in the case of fiscal devaluation." .
<http://www.springernature.com/scigraph/things/articles/0214fb214f730fd23480d11b9f311cf2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We consider different models for intraday log-returns: Lévy models, symmetric models, and Lévy processes subjected to independent continuous time-changes. For these models, we show bivariate interchangeability of intraday up- and downside volatility ratios which are built using daily high-low prices. Using conditional inference permutation tests on bivariate interchangeability, we develop an omnibus test for the above-mentioned models. Empirically, we find strong evidence against intraday returns belonging to these model classes, as we reject bivariate interchangeability of the volatility ratios for half of the components of the DJIA, two thirds of the S&P 500 shares and almost all stocks of the German DAX." .
<http://www.springernature.com/scigraph/things/articles/74fc20fab699a641fc4b617f1681a42f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Given a time series of intra-day tick-by-tick price data, how can realized variance be estimated? The obvious estimator—the sum of squared returns between trades—is biased by microstructure effects such as bid–ask bounce and so in the past, practitioners were advised to drop most of the data and sample at most every five minutes or so. Recently, however, numerous alternative estimators have been developed that make more efficient use of the available data and improve substantially over those based on sparsely sampled returns. Yet, from a practical viewpoint, the choice of which particular estimator to use is not a trivial one because the study of their relative merits has primarily focused on the speed of convergence to their asymptotic distributions, which in itself is not necessarily a reliable guide to finite sample performance (especially when the assumptions on the price or noise process are violated). In this paper we compare a comprehensive set of nineteen realized variance estimators using simulated data from an artificial “zero-intelligence” market that has been shown to mimic some key properties of actual markets. In evaluating the competing estimators, we concentrate on efficiency but also pay attention to implementation, practicality, and robustness. One of our key findings is that for scenarios frequently encountered in practice, the best variance estimator is not always the one suggested by theory. In fact, an ad hoc implementation of a subsampling estimator, realized kernel, or maximum likelihood realized variance, delivers the best overall result. We make firm practical recommendations on choosing and implementing a realized variance estimator, as well as data sampling." .
<http://www.springernature.com/scigraph/things/articles/bb1eca78de7441ee7b5792aefafc52f3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The increasing globalization of economies and the concurrent increase in the risk of currency exposure has stimulated the development of new instruments to allow both investors and traders to hedge their currency risk. The expansion of these derivatives, however, has raised some concerns. This paper studies the determinants of the dynamics of exchange rate future contracts as a means to identify the sources of such concerns. By using a mean-exponential generalized autoregressive conditional heteroskedasticity (M-EGARCH) model for five different future contract lengths and six developed economies, it is found that an M-EGARCH(1,1) effectively describes the exchange rate futures' daily dynamic. Sign, size, and persistence effects on the volatility of future contracts are all significant, thus providing important information to both policy makers and market participants." .
<http://www.springernature.com/scigraph/things/articles/32bb53004a131cce213728a2dcbe5532> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This article describes the operational procedure for a mechanical monthly forecast of the money stock in The Netherlands for up to twelve months ahead. In addition to time series data of the money stock itself, the procedure uses the information provided by the disaggregation of the money stock into financial assets, sources of money supply and holdership. The forecast from a univariate ARIMA model of the money stock is combined with three different forecasts from vector ARIMA models for the components distinguished by the three ways of disaggregation. The combination weights, which differ for each number of months to be forecasted ahead, are determined by regression analysis." .
<http://www.springernature.com/scigraph/things/articles/de7e0e67deac3b7ac6e02fcc1f5d6438> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study presents spatio-temporal analysis of droughts in one of the most drought prone region in India–western Rajasthan and develops drought intensity-area-frequency curves for the region. The meteorological drought conditions are analyzed using 6-month standardized precipitation index (SPI-6) estimated at spatial resolution of 0.5° × 0.5°. Spatio-temporal analysis of SPI-6 indicates increase in frequency of droughts at the central part of the region. The non-parametric Mann–Kendall test for seasonal trend analysis showed increase in number of grids under drought during the study period. Further, bivariate frequency analysis of drought characteristics—intensity and areal extent is carried out using copula methods. For modeling joint dependence between drought variables, three copula families namely Gumbel-Hougaard, Frank and Plackett copulas are evaluated. Based on goodness-of-fit as well as upper tail dependence tests, it is found that the Gumbel-Hougaard copula best represents the drought properties. The copula-based joint distribution is used to compute conditional return periods and drought intensity–area–frequency (I–A–F) curves. The I–A–F curves could be helpful in risk evaluation of droughts in the region." .
<http://www.springernature.com/scigraph/things/articles/b2288a7cfb921b6d5b73442ce41e549b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Water resources management is a complex task and is further compounded by droughts. This study applies a multilayer perceptron network optimized using Levenberg–Marquardt (MLP) training algorithm with a tangent sigmoid activation function to forecast quantitative values of standardized precipitation index (SPI) of drought at five synoptic stations in Iran. The study stations are located in different climatic regions based on De Martonne aridity index. In this study, running series of total precipitation corresponding to 3, 6, 9, 12, and 24 months were used and the corresponding SPIs were calculated: SPI3, SPI6, SPI9, SPI12, and SPI24. The multilayer perceptrons (MLPs) for SPIs with the 1-month lead time forecasting, were tested and validated. Four different input vectors were considered during network development. In the first model, MLP constructed by importing antecedent SPI with 1-, 2-, 3-, and 4-month time lags and antecedent precipitation with 1- and 2-month time lags (MLP1). Addition of antecedent North Atlantic Oscillation or antecedent Southern Oscillation Index with 1-month time lag or both of them to MLP1 led to MLP2, MLP3, and MLP4, respectively. The MLP models were evaluated using the root mean square error (RMSE) and the coefficient of determination (R 2). The results showed that MLP4 had a higher prediction efficiency than the other MLPs. The more satisfactory results of RMSE and R 2 values of MLP4 for 1-month lead time for validation phase were equal to 0.35 and 0.92, respectively. Also, results indicated that MLPs can forecast SPI24 and SPI12 more accurately than the other SPIs." .
<http://www.springernature.com/scigraph/things/articles/52e0d8d75d3d4aa2e655302ecc534679> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This paper examines the use of monetary and fiscal policy in a small country model under floating exchange rates. The government attempts to achieve a target level of economic activity and either an investment spending (output composition) or current account target. However, a choice may have to be made between the latter two objectives because a trade-off exists between them as the monetary-fiscal policy mix changes. It is shown that either monetary or fiscal policy can be assigned to the GNP target, and the second policy to one of the other targets, although the path may be oscillatory." .
<http://www.springernature.com/scigraph/things/articles/e97e7f37236b59759605df2ef4be03c5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We employ a multiple testing technique to identify the countries for which purchasing power parity (PPP) held over the last century. The approach controls the multiplicity problem inherent in simultaneously testing for PPP on several time series, thereby avoiding spurious rejections. It has higher power than traditional multiple testing techniques by exploiting the dependence structure between the countries with a bootstrap approach. Our results show that, plausibly, thus controlling for multiplicity leads to a number of rejections of the null that is intermediate between that of traditional multiple testing techniques and that which results if one tests the null on each single time series at some level α." .
<http://www.springernature.com/scigraph/things/articles/3e2bea4081d967a3f5dd680349c6eafd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Long memory in foreign exchange markets is examined for the post-Bretton Woods period using Lo's [1991] modified rescaled range (R/S). Conventional R/S techniques are presented for comparison. Unlike conventional techniques, Lo's analysis is robust to short-term dependence and conditional heteroskedasticity. Significant long memory and fractal structure are conclusively demonstrated for all 22 countries studied, indicating that traditional econometric methods are inadequate for analyzing foreign exchange markets. However, short-term dependence and conditional heteroskedasticity are also present, making it difficult to describe the nature of the long memory process or processes in foreign exchange markets. The average nonperiodic cycle ranges from 7 months for Canada and the United Kingdom, to approximately 20 months for Austria, Finland, France, Germany, Ireland, Japan, Malaysia, Netherlands, Sweden, and Switzerland. No support is found for the efficient market hypothesis. Results broadly agree with those provided by less sophisticated, less robust R/S methodologies and suggest the possibility that traditional technical analysis should be able to achieve systematic positive returns." .
<http://www.springernature.com/scigraph/things/articles/1634df1096b3632ce7f838736d16d15d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary MORKMON, De Nederlandsche Bank's new quarterly model of the Dutch economy fits in the last generation of macroeconometric models. Based on an integrated set of national and financial accounts, it combines demand, supply and financial conditions. Distinct features are a detailed financial sector, and endogenous exchange-rate determination. The specification reflects the model-builders inclination to give a great weight to empirical evidence. The model's forecasting performance is quite satisfactory, but not all simulations yield plausible results. In particular the interaction between the real and the financial sector could benefit from further research, for which MORKMON provides an excellent bridgehead." .
<http://www.springernature.com/scigraph/things/articles/99891e39e75f5a4e13e027a0474f018f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Quantifying the impact of scientific research is almost always controversial, and there is a need for a uniform method that can be applied across all fields. Increasingly, however, the quantification has been summed up in the impact factor of the journal in which the work is published, which is known to show differences between fields. Here the h-index, a way to summarize an individual's highly cited work, was calculated for journals over a twenty year time span and compared to the size of the journal in four fields, Agriculture, Condensed Matter Physics, Genetics and Heredity and Mathematical Physics. There is a linear log-log relationship between the h-index and the size of the journal: the larger the journal, the more likely it is to have a high h-index. The four fields cannot be separated from each other suggesting that this relationship applies to all fields. A strike rate index (SRI) based on the log relationship of the h-index and the size of the journal shows a similar distribution in the four fields, with similar thresholds for quality, allowing journals across diverse fields to be compared to each other. The SRI explains more than four times the variation in citation counts compared to the impact factor." .
<http://www.springernature.com/scigraph/things/articles/cb6c33fd875928c407e61f19123f1dff> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study investigates the environmental Kuznets curve (EKC) hypothesis by employing the ecological footprint (EF) as an indicator of environmental degradation in Qatar over the 1980–2011 period. The results of the Autoregressive Distributed Lag (ARDL) estimation with structural breaks reveal that there is a long run relationship among the selected variables with a significant shift in the cointegration vector in 1996. The comparison of the short and long-run income elasticities indicates that the EKC hypothesis is not valid in Qatar. In particular, the long run effect of income is greater than its short run effect, which provides evidence of a monotonic relationship between EF and real GDP per capita. Moreover, the oil price and trade openness have a positive and negative long run impact on ecological footprint, respectively. We further investigate the robustness of the results by employing the Toda–Yamamoto causality tests and the estimation with regime approach. The outcome of TY shows that income and oil price increase significantly the ecological footprint. Moreover, the results of the estimation with two regimes (1980–1996 and 1997–2011) show that the impact of real GDP on the EF in the second regime is higher than the first regime, which confirm the ARDL estimation results." .
<http://www.springernature.com/scigraph/things/articles/414226b171b6d676527acb817fbd0aa5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary We discuss a robust approach for predicting a weakly stationary discrete time series whose spectral density f is not exactly known. We assume that we know that f∈ $$\\mathfrak{D}$$ ), where $$\\mathfrak{D}$$ is a convex set of spectral densities fulfilling some not too stringent conditions. We proof the existence of a “most indeterministic” density f 0 in $$\\mathfrak{D}$$ , and we show that the classical optimal linear predictor for a time series with spectral density f 0 is mini-max-robust in the sense that it minimizes the maximal possible prediction error. We investigate some special models $$\\mathfrak{D}$$ , and, in doing so, we illustrate a generally applicable method for determining the robust predictor. In particular, we discuss model sets $$\\mathfrak{D}$$ which are defined by conditions on a finite part of the autocovariance sequence of the corresponding time series. These examples are of particular interest as the most indeterministic density is an autoregressive one, i.e. the robust predictor is finite. We discuss connections between this type of model set $$\\mathfrak{D}$$ and maximum entropy and generalized maximum entropy spectral estimates." .
<http://www.springernature.com/scigraph/things/articles/11fc12d89fac84301a283c00f5c4e96b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper shows that in a two-good economy with a basic and a luxury good sector inequality is indeed a hindrance to provide sufficient incentive for entrepreneurship to low-wealth economic agents. In contrast to the literature it uses both demand and supply-side explanations for the analysis. An entrepreneurial subsidy policy to encourage entrepreneurship in autarky financed by a lump sum tax on the rich is not very effective in unequal economies since it hardly impacts the welfare. When trade is opened up in the luxury good sector of such an economy the sector might cease to exist. In such a scenario, the rich people being the sole consumers would reap the entire benefits of globalization via low price of the imported luxury good. The paper highlights that the crucial question is: ‘how to globalize’ rather than ‘whether to globalize’ and suggests policy measures to make globalization inclusive." .
<http://www.springernature.com/scigraph/things/articles/d09ba4004a3bc6a65e04cd65d0a63c5a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract For more than three decades now, sociologists, politicians and economists have used a wide range of statistical and econometric techniques to analyse and measure the quality of life of individuals with the aim of obtaining useful instruments for social, political and economic decision making. The aim of this paper is to analyse the advantages and disadvantages of three possible methodologies for obtaining synthetic indicators for the area of welfare and quality of life. These methodologies are Principal Components Analysis, Data Envelopment Analysis and Measure of Distance P2. Furthermore this paper analyses quality of life in the European Union (EU), as a methodological exercise to demonstrate the principles of calculation, implications and differences between the three indicator-construction approaches. This analysis is particularly useful in a scene like the EU, immersed in a deep transformation process and with profound cultural, economic and social inequalities. Therefore, an analysis of the quality of life and well-being of its inhabitants can play a major role in ironing out such differences." .
<http://www.springernature.com/scigraph/things/articles/b660cd772b96ed5d5c4843ae03c40b50> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Intra-European exchange rate variability has significant economic costs. VAR causality tests show that higher short-run variability of exchange rates against other EU currencies was associated with higher unemployment, less employment, and lower investment for most EU member countries. Robustness tests show that this result holds up in the presence of both policy instruments that might have had an impact on exchange rate variability and cyclical variables that might have influenced labor demand. A model that incorporates the “option value of waiting” suggests that even short-term spikes in volatility exert a strong impact on investment and labor markets." .
<http://www.springernature.com/scigraph/things/articles/a9717b0026ab6e0e13c73c5fe1119882> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper examines the determinants of bank robbery in the United States using a rational choice model. Panel data estimation techniques were used to analyze the data for all 50 states and the District of Columbia from 1990 through 2000. A random-effects model emerged as the most appropriate estimating model for costs and benefits of bank robbery. Among the significant determinants of the rate of bank robbery were the unemployment rate and amount of loot. The findings suggest that the rational choice model is a suitable framework for examining bank robbery. However, if we are to draw useful policy conclusions, better data are needed to accurately measure the opportunity costs of bank robbery. (JEL C23, K42)" .
<http://www.springernature.com/scigraph/things/articles/212805207d832dbd3396cdba652e3569> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The lack of any reliable method for assessing the age of individuals collected in the field has often been considered a major obstacle for population studies in aquatic oligochaetes. One possible solution could be the adoption of other variables, such as weight or stage, for the definition of the population structure; this approach would be useful if allowed good predictions about population growth. We measured, under laboratory conditions, the effect of age, size and life stage on survival, growth and fecundity of Limnodrilus hoffmeisteri Claparède. The results are used to establish four matrix population models, based respectively on the classification of the individuals by age, weight and stage and on a mixed classification. Matrix population models make the assumptions that the individuals in a population can be arranged in a number of discrete classes and that time is a discrete variable. In these models, the population is represented by a vector (each element in the vector is the number of individuals in a class) and the demographic coefficients (survival, growth and fecundity) are collected in a square matrix. The estimate of λ, the potential long term population growth rate and its confidence interval were taken from the four models using the jackknife method. The width of the confidence interval is a measure of the effectiveness of the models and thus of the classification of the individuals. The results suggest that weight is inefficient as a criterion for the definition of population structure of L. hoffmeisteri in comparison to age and stage." .
<http://www.springernature.com/scigraph/things/articles/89451a71af1efd1f3c48b6d994a1a82c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We handle two major issues in applying extreme value analysis to financial time series, bias and serial dependence, jointly. This is achieved by studying bias correction methods when observations exhibit weak serial dependence, in the sense that they come from β $\\beta$-mixing series. For estimating the extreme value index, we propose an asymptotically unbiased estimator and prove its asymptotic normality under the β $\\beta$-mixing condition. The bias correction procedure and the dependence structure have a joint impact on the asymptotic variance of the estimator. Then we construct an asymptotically unbiased estimator of high quantiles. We apply the new method to estimate the value-at-risk of the daily return on the Dow Jones Industrial Average index." .
<http://www.springernature.com/scigraph/things/articles/0a3da11303e43f2651772de4dab05eab> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Trickle-down has been addressed, so far, using income-based measures of inequality and poverty. However concerns over the inequality in access to other dimensions important for quality of life remains. I revisit trickle-down using the Alkire and Foster (J Public Econ 95(7–8), 2011) class of measures to estimate multidimensional poverty in India. Using NSS data estimates are presented for the 16 major states and are compared to income-based measures. Adding dimensions in poverty measurement results in the reversal of several income-based conclusions about poverty across regions. The paper also finds that contrary to income-based findings, Muslims are less poor than Hindus under the multidimensional criteria." .
<http://www.springernature.com/scigraph/things/articles/a707912a0856ed9f85f9f2fe757cf0a0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This paper re-examines the relationships between short term capital flows and monetary policy, in the light of a new theoretical approach of the forward exchange market. They contend that the traditional forward exchange market theory is a misleading one as it fails to give all the importance it deserves to the distinction between covered and uncovered exchange transactions and to the actual role of the ‘arbitrageurs.’ As a consequence of this analysis, they demonstrate that the problem of monetary management in an open economy must be dealt with in a way different from what has been usual, and they conclude that monetary policy, central banks' intervention on the foreign exchange market and direct controls on capital movements can still have some efficiency in the struggle against inflation, either of the ‘domestic’ or the ‘imported’ type." .
<http://www.springernature.com/scigraph/things/articles/55dc9822e28cdab2a26e0a1eeaacf7b3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article uncovers dynamic properties of the von Neumann–Morgenstern solution in weak tournaments and majoritarian games. We propose a new procedure for the construction of choice sets from weak tournaments, based on dynamic stability criteria. The idea is to analyze dynamic versions of tournament games. The exploration of a specific class of Markov perfect equilibria in these “dynamic tournament games” yields a new solution concept for weak tournaments—the A-stable set. The alternatives in an A-stable set constitute persistent, long-run policy outcomes in the corresponding dynamic tournament games. We find that, in any weak tournament, the class of A-stable sets coincides with that of von Neumann–Morgenstern stable sets." .
<http://www.springernature.com/scigraph/things/articles/6068bbee9233a5c264607352aef948ca> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Does redistribution increase inequality? Is inequality harmful for growth? Both questions have recently been addressed in a number of single-tax models. In this paper, I examine the relationship between policy, growth and inequality when income and inherited wealth can be taxed at different rates. In the model, parents accumulate human capital and a return-bearing, storable good in order to increase the quality of their children. Inequality arises because the learning ability of children is stochastic. Redistributive labor income taxation has a negative impact on short- and long-run growth while taxation of inherited stocks increases growth. Effects of both taxes on income inequality are ambiguous. A switch from income to inheritance taxation may increase average utility of all generations involved. I calculate a structure-induced equilibrium of the political process by means of a stochastic simulation of the model. In the short run initial wealth-inequality can stimulate growth, while initial inequality of the endowment with human capital is harmful for growth." .
<http://www.springernature.com/scigraph/things/articles/a871e43027f3457a0e397eb8285ef87e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Financial derivatives are products whose price is linked with that of an underlying asset. The relationship between these two prices has been studied in depth, and the following conclusions have been reached: (1) the volatility of underlying asset's price decreases after the introduction of derivatives, (2) the price discovery effect improves, (3) the liquidity of the underlying asset's market increases, (4) the bid-ask spread decreases together, and (5) the noise component of prices decreases. Those results are microeconomic and are not coherent with a macroeconomic analysis of derivatives. Derivatives tend to change the effectiveness of monetary policy actions by modifying the instruments that can be used. Derivatives have a monetary nature that has not been yet recognized by central banks and international organizations such as the International Monetary Fund and the Bank for International Settlements. This monetary nature can be evident by testing the relationship between derivatives and the interest rate. The consciousness of the monetary nature of derivatives would impose the quantification of transactions at least by the institutions that hold them, such as banks and other financial operators, and consequently by national authorities." .
<http://www.springernature.com/scigraph/things/articles/a5e6669101de66d37a251961ad536478> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Correlation associations have been detected using Pearson’s r which aims to analyze linear correlation between two variables. It should be noted here that associations between hydro-meteorological variables are usually nonlinear. In this sense, the classical correlation analysis method cannot truly reflect the inherent associations between variables characterized by nonlinear associations. In this case, a new algorithm has been proposed by using the ideas of local correlation, detrended cross-correlation analysis and multifractals, and this novel algorithm is called as the general detrended correlation analysis. The newly-proposed algorithm was evaluated for the validity with numerically-generated time series and the real world hydrological series. The results indicate that the newly-proposed algorithm can well reflect the nonlinear and non stationary associations between two hydrological series when compared to the classical relation detection method such as the Pearson correlation analysis method, and it is particularly the case under the condition that hydrological abrupt changes of the hydrological processes occur where the classical association analysis is not appropriate." .
<http://www.springernature.com/scigraph/things/articles/028b84b45b457f3ab0f6cbf8f7586db0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The dynamics of a community are said to be compensatory if aggregate biomass is less variable over time than the biomass of the individual components of the system. In broad terms, the presence of compensation reflects interactions between components that tend to stabilize the overall community. A common quantitative measure used to detect compensation is the ratio of the temporal variance of total biomass to the sum of the biomass variances of the components, with a ratio less than 1 indicative of compensation. The purpose of this note is to describe a test for compensation when the variance ratio is estimated from biomass time series data. The test involves a bootstrap procedure that accounts for serial correlation in biomass. Failure to account for positive serial correlation can lead to spurious detection of compensation. The test is illustrated using biomass data for fish stocks on Georges Bank." .
<http://www.springernature.com/scigraph/things/articles/2ba680e3cca81f21ac017318b5a5d4a5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Intervention analysis techniques are described for identifying and statistically modelling trends which may be present in water quality time series. At the exploratory data analysis stage, simple graphical and modelling methods can be employed for visually detecting and examining trends in a time series caused by one or more external interventions. For instance, a plot of a robust locally weighted regression smooth through a graph of the observations over time may reveal trends and other interesting statistical properties contained in the time series. In addition, statistical tests, such as different versions of the nonparametric Mann-Kendall test, can be used to detect the presence of trends caused by unknown or known external interventions. To characterize rigorously and estimate trends which may be known in advance or else detected using exploratory data analysis studies, different parametric methods can be utilized at the confirmatory data analysis stage. Specifically, the time series modelling approach to intervention analysis can be employed to estimate the magnitudes of the changes in the mean level of the series due to the interventions. Particular types of regression models can also be used for estimating trends, especially when there are many missing observations. To demonstrate how intervention analysis methods can be effectively used in environmental impact assessment, representative applications to water quality time series are presented." .
<http://www.springernature.com/scigraph/things/articles/d1f4c6b7545fdf8452060266ccd817e3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Nontraded goods account for a major share of GDP in most economies, but have not been incorporated in the welfare analysis of monopolistic-competition models with heterogeneous productivity. This paper extends Helpman, Melitz and Yeaple (American Economic Review 94(1):300–316, 2004) to explore welfare effects in the presence of a nontraded good. We derive new analytical results about how the gains from trade and FDI are determined and affected by key parameters in the case of symmetric countries. The model is calibrated to a country group that includes all major developed countries. The gains from openness (trade and FDI) are found to be substantial (between 3.24 and 6.27 per cent of income) even if nontraded goods represent a major part of the economy. Most of these gains are attributed to trade rather than FDI." .
<http://www.springernature.com/scigraph/things/articles/d14883fdd99d967a5173b24c95d0a382> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Independent Component Analysis (ICA) is a recent and well known technique used to separate mixtures of signals. While in general the researchers put their attention on the type of signals and of mixing, we focus our attention on a quite general class of models which act as sources of the time series, the dynamical systems. In this paper we focus our attention on the general problem to understand the behaviour of ICA methods with respect to the time series deriving from a specific dynamical system, selecting large classes of them, and using ICA to make separation. This study gives some interesting results that are very useful both to highlight some properties related to dynamical systems and to clarify some general aspects of ICA, by using both synthetic and real data. From one hand we study the features of the linear (simple and coupled) and non-linear (single and coupled) dynamical systems, stochastic resonances, chaotic and real dynamical systems. We have to stress that we obtain information about the separation of these systems and substantially how from the entropy of the complete system we can obtain the entropies of the single dynamical systems (so that we also could obtain a more realistic analogic circuit). On the other hand these results show the high capability of the ICA method to recognize the dynamical systems independently from their complexity and in the case of stochastic series ICA perfectly recognizes the different dynamical systems also where the Fourier Transform is irresolute. We also note that in the case of real dynamical systems we showed that ICA permits to recognize the information connected to the sources and to associate to it a phenomenological dynamical system that reproduce it (i.e. Organ Pipe, Stromboli Volcano, Aerosol Index)." .
<http://www.springernature.com/scigraph/things/articles/afa3d247281526a2061f6d9cbff3fe07> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The objective of this article is to provide an analysis of the relationship existing between cereal prices and several variables (population, income, exports, the exchange rate, and speculation), by using a linear regression analysis. Specific emphasis is placed on the speculative dimension. Our results show that speculation has played a crucial role during the period June 2001–December 2009. Exports, in some ways connected to the former variable, occupy second place, in terms of significance. However, their impact on cereal prices is less relevant than that of biofuel production. Population growth acts in the opposite direction due to the change in diets, implying that population increases would tend to affect primarily other agricultural markets. Excessive volatility in food prices is a dramatic question. From a demand point of view, consumers in developing countries and vulnerable income groups in other countries (farmers) have to be protected. More than one policy has to be introduced." .
<http://www.springernature.com/scigraph/things/articles/ceac6441d94f7b2c1d57b002cc885776> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper discusses a methodology able to estimate both the discrete and continuous spectra without any assumption on the shape of spectral densities. The approach to estimate the spectral density is based on a robust smoothing of the periodogram. Bandwidth, a quantity similar to the width of spectral windows traditionally used in spectral analysis, is estimated locally in contrast to intuitively chosen global window lengths. Detection and estimation of frequencies forming discrete spectra are also addressed. The procedure is applied to Central England temperature (CEt), North Atlantic Oscillation (NAO) index and Oxygen Isotope of North Greenland Ice Core Project (δ18O of NGRIP) data. Annual and half annual cycles were detected in CEt data, whilst 118.2- and 41.7-ky cycles were found in δ18O of NGRIP. This latter periodicity is almost as intense as the dominant longer cycle. Several local peaks of spectral densities were recognised in each time series that mostly cover earlier results. However, a few previous findings at low frequencies have not been reinforced by the present method. Identification of modest local peaks or discrete amplitudes at low frequencies is an extremely challenging task as climatic data generally have spectral densities rising to low frequencies." .
<http://www.springernature.com/scigraph/things/articles/ffc0b2c49e54a715964046c822c728a2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper investigates the cyclical behaviour of the wine production in Douro region during the period 1932–2008. In general, wine production is characterised by large fluctuations which are composed of short-term and/or long-term cycles. The aim of this paper is twofold: firstly, we decompose the wine production's variance in order to find the dominating production cycles, i.e we try to explain whether wine production follows more long-term or short-term cycles. In the next step, we try to explain those cycles using a dependent variable, namely the medium spring temperature (Tm_Sp) for the period 1967–2008. We estimated a Time-Varying Autoregressive Model, which could explain 75% of the production that is characterised by 4.8- and 2.5-year cycles. We use the Short Time Fourier Transform to decompose the link between wine production and temperature. When the temperature was incorporated, the R 2 increased and the Akaike criterion value was lower. Hence, Tm_Sp causes a large amount of these cycles and the wine production variation reflects this relationship. In addition to an upward trend, there is a clearly identifiable cycle around the long-term trend in production. We also show how much of the production cycle and what cycle in particular is explained by the Tm_Sp. There is a stable but not constant link between production and the Tm_Sp. In particular, the temperature is responsible for 5.2- and 2.4-year cycles which has been happening since the 1980s. The Tm_Sp can also be used as an indicator for the 4.8- and 2.5-year cycles of production. The developed model suggests that stationarity is a questionable assumption, and this means that historical distributions of wine production are going to need dynamic updating." .
<http://www.springernature.com/scigraph/things/articles/14c8d70c645993979cae0b37c8c90a15> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Financial time series forecasting has become a challenge because of its long-memory, thick tails and volatility persistence. Multifractal process has recently been proposed as a new formalism for this problem. An iterative Markov-Switching Multifractal (MSM) model was introduced to the literature. It is able to capture many of the important stylized features of the financial time series, including long-memory in volatility, volatility clustering, and return outliers. The model delivers stronger performance both in- and out-of-sample than GARCH-type models in long-term forecasts. To enhance MSM’s short-term prediction accuracy, this paper proposes a support vector machine (SVM) based MSM approach which exploits MSM model to forecast volatility and SVM to model the innovations. To verify the effectiveness of the proposed approach, two stock indexes in the Chinese A-share market are chosen as the forecasting targets. Comparing with some existing state-of-the-art models, the proposed approach gives superior results. It indicates that the proposed model provides a promising alternative to financial short-term volatility prediction." .
<http://www.springernature.com/scigraph/things/articles/dc758a46ee820f961d3743bd1ddfb4e6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper investigates the welfare consequences of international policy cooperation by simultaneously introducing the following three elements in a standard two-country general equilibrium model: (i) general degrees of exchange rate pass-through, (ii) nontradable goods and their sector-specific productivity shocks, and (iii) general weights on goods in Cobb–Douglas consumption indices. There are two channels for possible mutual welfare gains from policy cooperation: First, cooperation can compensate for insufficient changes in the terms of trade when the degree of exchange rate pass-through is intermediate. Second, countries can cooperate in reaction to shocks in the nontradable goods sectors. This second channel is revealed by deriving an analytical condition for welfare gains under full pass-through and this condition is characterized by the weights in the consumption indices and the variances of sector-specific productivity shocks. Numerical evaluation demonstrates that when the two countries are symmetric and equal weights on consumption goods are assumed, welfare gains from cooperation increase as symmetric pass-through elasticity increases, which implies that the second channel dominates the first, whose effect on welfare gains is nonmonotonic in pass-through elasticity." .
<http://www.springernature.com/scigraph/things/articles/8440128ed3588a86dbb73bba645d9b5b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Central bank credit has expanded dramatically in some of the Euro Area member countries since the beginning of the financial crisis. This paper makes two contributions to understand this stylized fact. First, we discuss a simple model of monetary policy that includes (i) a credit channel and (ii) a common pool problem in a monetary union. We illustrate that the interaction of the two elements leads to an inflation bias that is independent of the standard time-inconsistency bias. Secondly, we present an institutional analysis that is consistent with the view of fragmented monetary policy and empirical evidence that illustrates the heterogeneity of central bank credit expansion." .
<http://www.springernature.com/scigraph/things/articles/ee632974f0d66f104ea06664c93d3606> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper deals with the problem of parameter significance estimation, and its application to currency exchange rate prediction. The basic problem is that over the years, practitioners in the field of financial engineering have developed dozens of technical and fundamental indicators on the basis of which they try to predict financial time series. The practitioners are now faced with the problem of finding out which combinations of those indicators are most significant or relevant, and how their significance changes over time. The authors propose a novel neural architecture calledSupNet for estimating the significance of various parameters. The methodology is based on the principle of penalizing those features that are the largest contributors to the error term. Two algorithms based on this principle are proposed. This approach is different from related methodologies, which are based on the principle of removing parameters with the least significance. The proposed methodology is demonstrated on the next day returns of the DM-US currency exchange rate, and promising results are obtained." .
<http://www.springernature.com/scigraph/things/articles/ac8aac69c6715a43efd9c60d94211118> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract North African countries (NACs) are particularly concerned with climate change because of their geographical position (close to deserts) and their economic dependence on agriculture. We aim to provide additional insight into the impact of climate on agriculture for NACs, through the example of Tunisia. We first use disaggregated data, both at the geographical level (for 24 regions in Tunisia) and at the product level (cereals, olives, citrus fruit, tomatoes, potatoes and palm trees). Second, through spatial panel data analysis, we explore both the time and spatial dimensions of the data. This makes it possible to consider spatial interactions in agricultural production and the role of climate in these spatial spillover effects. Finally, the model not only includes direct climate variables, such as temperature and precipitation, but also indirect climate-related variables such as the stock of water in dams and groundwater. Results show that Tunisian agriculture is strongly dependent on the direct effects of temperature and precipitation for all the products considered at the regional level. The presence of dams and groundwater generally has a positive effect on agricultural production for irrigated crops with interesting spillover effects with neighboring regions. However, this impact is still considerably lessened in the case of detrimental climate conditions (indirect effect). These results raise the question of the sustainability of the growth in agricultural production in Tunisia in the case of significant climate change." .
<http://www.springernature.com/scigraph/things/articles/bd1b1e16ea9e4503831a2f4d58692a41> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Accurate estimation of an underlying function and its derivatives is one of the central problems in statistics. Parametric forms are often proposed based on the expert opinion or prior knowledge of the underlying function. However, these strict parametric assumptions may result in biased estimates when they are not completely accurate. Meanwhile, nonparametric smoothing methods, which do not impose any parametric form, are quite flexible. We propose a parametric penalized spline smoothing method, which has the same flexibility as the nonparametric smoothing methods. It also uses the prior knowledge of the underlying function by defining an additional penalty term using the distance of the fitted function to the assumed parametric function. Our simulation studies show that the parametric penalized spline smoothing method can obtain more accurate estimates of the function and its derivatives than the penalized spline smoothing method. The parametric penalized spline smoothing method is also demonstrated by estimating the human height function and its derivatives from the real data." .
<http://www.springernature.com/scigraph/things/articles/c355409daabe0d658d842b16a64fed79> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study examines the interaction of bank risk and non-interest income (trading and non-trading) controlling for the executive incentive compensation effect. We do not find executive stock option compensation (ESO) directly impacts bank risk. On the contrary, bank non-interest income, both trading and non-trading revenue components, positively and significantly affects bank risk. This result is robust to the difference-in-difference regressions, bank fixed effect, and the exclusion of too-big-to-fail banks. In a simultaneous equations setting, non-interest income activities affect bank risk of all types, while ESO does not. Moreover, idiosyncratic risk has a positive effect on bank non-interest income activities, but systematic risk has no effect. This result suggests that executives of banks with high idiosyncratic risk have more incentive to expand into the territory of non-interest income activities. Since high-risk banks pose more concern to investors and regulators, we further examine bank risk by means of quantile regressions which dissect the behavior of banks at the tail risk distribution. The findings point out that banks’ decision to diversify into non-traditional business lines is associated with risks in high-risk banks. The impact of non-interest income/trading revenues on bank risk increases in risk, and often the largest impact is spotted for banks with extreme risks. This implies that the leverage effect of non-interest income/trading activities is larger in high-risk banks." .
<http://www.springernature.com/scigraph/things/articles/ba21d038b4ca3668774ea475a9119ee1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We study a novel pricing operator for complete, local martingale models. The new pricing operator guarantees put-call parity to hold for model prices and the value of a forward contract to match the buy-and-hold strategy, even if the underlying follows strict local martingale dynamics. More precisely, we discuss a change of numéraire (change of currency) technique when the underlying is only a local martingale, modelling for example an exchange rate. The new pricing operator assigns prices to contingent claims according to the minimal cost for superreplication strategies that succeed with probability one for both currencies as numéraire. Within this context, we interpret the lack of the martingale property of an exchange rate as a reflection of the possibility that the numéraire currency may devalue completely against the asset currency (hyperinflation)." .
<http://www.springernature.com/scigraph/things/articles/a143d0bbef0f2d5037e83988a65ede0c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Social security policies often focus on replacement rates, which indicate retirement income or social security benefits in relation to preretirement income. The higher replacement rate among the pensioners would ensure that the ageing society would have sufficient income to lead a normal life after retirement. This study examined factors that influencing the income replacement rate of Malaysian Employee Provident Fund (EPF) retirees. The analysis was based on a nationwide survey conducted in 2013–2014 among EPF retiree. A logit model was used to evaluate the likelihood of selected socio-demographic and economic factors contributing to income of the retirees. The results indicated that around 62 % of elderly has lower retirement income compared to their preretirement income and it makes them more vulnerable to unpredictable events and financial conditions. The study suggested that the income replacement rate of elderly could be strengthened by investing in ageing workforce, raising retirement age, enhancing educational achievements of low income groups and restructuring employment. These may in turn increase the availability of skilled workers, enhancing the national productivity, increase the income security of retirees, reduce poverty, and develop economic growth of the country." .
<http://www.springernature.com/scigraph/things/articles/e7a6b6c047b3fc6b82bbc967185b10e0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper introduces a new approach in solving the ICA problem using a method that fits in the contrast and minimize paradigm, mostly found in the ICA literature. In our case, the contrast is a L 2 norm dependence measure, which constitutes an alternative to the usual criteria, based on mutual information. We propose a non parametric evaluation of the L 2 contrast, using a wavelet projection estimator. The mean square error of the procedure is bounded under Besov assumptions. Finally, we provide a set of simulations to show how the method performs in practice." .
<http://www.springernature.com/scigraph/things/articles/e632f3896d6cf308400e635ecc882be4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. The existence of stylized facts suggests that there might be `universal' mechanism which drives price evolution on financial markets in general. Based on empirical estimates of 10 major indices, we propose a stylized model of endogenous price formation on an aggregate level whose key issue is that price evolution is driven by the `market's' expectations about future growth rates of investment. The model is a multiplicative random process with a stochastic, state-dependent growth rate which establishes a negative feedback component in the price dynamics which admits some far reaching formal analysis. Generated return trails exhibit statistical properties such as 'volatility clustering', multi scaling, and a non-Gaussian distribution which is in quantitative in agreement with stylized facts from empirical asset returns. Additionally non-equilibrium entropies are also considered. These results suggests that the structure of the model mimicks a mechanism which is essential in driving price dynamics of financial markets in general." .
<http://www.springernature.com/scigraph/things/articles/5fe797ca39689b9e1901d5c5e0dd87db> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary In this paper the absolute and relative versions of purchasing power parity (ppp) are tested using annual data (over the period 1973–1985) for 5 countries. In contrast to much of the literature on ppp, evidence in favour of the ppp hypothesis is reported, particularly when a wholesale price index is used. A novel feature of the approach is the use of a pooled cross section-time series analysis." .
<http://www.springernature.com/scigraph/things/articles/7a12d25d746a0b03bbf2189d523d0cdb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The application of Engel’s Curve in a single-product perspective may dramatically change the role of quality in affecting the dynamics of economic performance. This paper introduces a specification of preferences that regards quality as luxury, and quantity as necessary. The analysis is carried out by using a framework similar to Grossman’s and Helpman ’s (1991), while quality is defined as in Stokey (1988). The resulting consumer’s demand crucially depends on quality. Quality is potentially able to prevent the process, implied by neoclassical models, that leads the value of consumption goods to decline over time. By doing so, quality also affects the consumption bundle shares and the variety-specific consumption growth rates, thus influencing all dynamic quantitative variables of the economy." .
<http://www.springernature.com/scigraph/things/articles/b76582b493e721f02540193971f5cc44> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The financial crisis of 2007-2009 revealed that the corporate complexity of most of the Global Systemically Important Banks (G-SIBs) presented a formidable obstacle to any plausible orderly resolution of these institutions. This paper documents the extent of this complexity making use of an historical time series, developed by the authors, that shows the evolution of the number of majority-owned subsidiaries of G-SIBs over time. After a very significant increase in complexity before the crisis and until 2011, this trend may be reversing, possibly in response to regulatory and market pressures on banks since then. Nonetheless the reduction in complexity has been uneven across institutions and may not persist. The econometric analysis of this new set of panel data produces two key results with relevant policy implications: first, the relationship found in previous studies between the number of subsidiaries and bank size loses significance when time effects are introduced; second, large mergers and acquisitions are a key driver of complexity and their effect remains significant even when time effects are considered." .
<http://www.springernature.com/scigraph/things/articles/e9c63a61459a98accd1fa820378a47cb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study compares time series and machine learning models for inflation forecasting. Empirical evidence from the USA between 1984 and 2014 suggests that out of sixteen conditions (four different inflation indicators and four different horizons), machine learning models provide more accurate forecasting results in seven conditions and the time series models are better in nine conditions. Moreover, multivariate models give better results in fourteen conditions, and univariate models are better only in two conditions. This study shows that machine learning model prevails against time series models for the core personal consumption expenditure (core-PCE) inflation forecasting, and the time series model (ARDL) is better for the core consumer price (core-CPI) index inflation forecasting in all horizons." .
<http://www.springernature.com/scigraph/things/articles/09cb4cd2b96a802c6a8eea8336268c9c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Sharp estimates are derived for the convergence rate of Fourier series in terms of Bessel functions of the first kind for some classes of functions characterized by a generalized modulus of continuity. The Kolmogorov N-width of these classes of functions are also estimated." .
<http://www.springernature.com/scigraph/things/articles/e61d83580b2e77e8571871f5d338fd9f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In developing countries contingent valuation (CV) has become an important tool for estimating willingness to pay (WTP). So far, however, the CV studies usually have not assessed the validity of the WTP estimates mainly due to ambiguities in the criteria for scope sensitivity analysis. In this article we clarify the criteria from theoretical and empirical aspects. The main debate on scope sensitivity analysis targets the proportionality theory: One group supports strong proportionality, and the other group supports weak proportionality. We highlight the shortcomings of strong proportionality and support weak proportionality. We set up the criteria for statistical significance and plausible responsiveness between the WTP and its explanatory variables. We conducted scope sensitivity of our case study from rural Pakistan to show its applicability in developing countries and to test the validity of our WTP estimates. Statistical analysis, based on the maintained hypothesis, reveals that the magnitude of the benefits and per capita income are significant variables that influence the WTP. The Kruskall-Wallis test reconfirmed the significance of the size of the benefits. Plausible responsiveness is evident from the influence of the household characteristics over the WTP. Finally, we concluded that CV can provide valid results in developing countries if the survey is conducted according to the mainstream guidelines. Further empirical testing is required to support the criterion of plausible responsiveness." .
<http://www.springernature.com/scigraph/things/articles/7c8675ebea40b4ffe51183eee0e5c18b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This report proposes an alternative approach for measurement uncertainty estimation avoiding the two main limitations of the control charting approach in a context were certified reference materials are unavailable. The procedures under study estimated the mass fraction of total alkaloids as nicotine and Kjeldahl total nitrogen in powdered samples of air-cured leaves of Cuban cigar tobacco. The intermediate precision estimated from results of different analysts was evaluated in parallel at three levels of mass fraction trough a spiking experiment using test portions of a one composite non-certified reference material per procedure and a balanced fully nested design. The systematic effect component was estimated in the same mass fraction levels but using a different set of samples covering a wide range of the typical routine test materials. An iterative re-weighted least squares linear regression analysis was performed between the results obtained through the assessed procedure with those attained from a reference one which analyses the same measurand. The estimation was then carried out using a proposed mathematic expression derived from the application of the uncertainty propagation law to the equation for bias estimation for every reference concentration. The uncertainty associated with bias estimation was furthermore evaluated over the whole mass fraction range considered in the procedure comparison study. The interpretation of the evaluated parameters is discussed regarding the specifics analytical characteristics of each procedure." .
<http://www.springernature.com/scigraph/things/articles/9cfd62885cf13556332a91e7d5c6dad3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Seasonal autoregressive integrated moving average (SARIMA) models form one of the most popular and widely used seasonal time series models over the past three decades. However, in several researches it has been argued that they have two basic limitations that detract from their popularity for seasonal time series forecasting tasks. SARIMA models assume that future values of a time series have a linear relationship with current and past values as well as with white noise; therefore, approximations by SARIMA models may not be adequate for complex nonlinear problems. In addition, SARIMA models require a large amount of historical data to produce desired results. However, in real situations, due to uncertainty resulting from the integral environment and rapid development of new technology, future situations must be forecasted using small data sets over a short span of time. Using hybrid models or combining several models has become a common practice to overcome the limitations of single models and improve forecasting accuracy. In this paper, a new hybrid model, which combines the seasonal autoregressive integrated moving average (SARIMA) and computational intelligence techniques such as artificial neural networks and fuzzy models for seasonal time series forecasting is proposed. In the proposed model, these two techniques are applied to simultaneously overcome the linear and data limitations of SARIMA models and yield more accurate results. Empirical results of forecasting two well-known seasonal time series data sets indicate that the proposed model exhibits effectively improved forecasting accuracy, so that it can be used as an appropriate seasonal time series model." .
<http://www.springernature.com/scigraph/things/articles/664b2612537b90fb9ae71f9cc72d30f3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The internal structure of a complex system can manifest itself with correlations among its components. In global business, the interactions between different markets cause collective lead–lag behavior having special statistical properties which reflect the underlying dynamics. In this work, a cybernetic system of combining the vector autoregression (VAR) and genetic algorithm (GA) with neural network (NN) is proposed to take advantage of the lead–lag dynamics, to make the NN forecasting process more transparent and to improve the NN’s prediction capability. Two business case studies are carried out to demonstrate the advantages of our proposed system. The first one is the tourism demand forecasting for the Hong Kong market. Another business case study is the modeling and forecasting of Asian Pacific stock markets. The multivariable time series data is investigated with the VAR analysis, and then the NN is fed with the relevant variables determined by the VAR analysis for forecasting. Lastly, GA is used to cope with the time-dependent nature of the co-relationships among the variables. Experimental results show that our system is more robust and makes more accurate prediction than the benchmark NN. The contribution of this paper lies in the novel application of the forecasting modules and the high degree of transparency of the forecasting process." .
<http://www.springernature.com/scigraph/things/articles/4560b4e4a9216539cdee635d4f5624fd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Space–time series can be partitioned into space–time smooth and space–time rough, which represent different scale characteristics. However, most existing methods for space–time series prediction directly address space–time series as a whole and do not consider the interaction between space–time smooth and space–time rough in the process of prediction. This will possibly affect the accuracy of space–time series prediction, because the interaction between these two components (i.e., space–time smooth and space–time rough) may cause one of them as dominant component, thus weakening the behavior of the other. Therefore, a divide-and-conquer method for space–time prediction is proposed in this paper. First, the observational fine-grained data are decomposed into two components: coarse-grained data and the residual terms of fine-grained data. These two components are then modeled, respectively. Finally, the predicted values of the fine-grained data are obtained by integrating the predicted values of the coarse-grained data with the residual terms. The experimental results of two groups of different space–time series demonstrated the effectiveness of the divide-and-conquer method." .
<http://www.springernature.com/scigraph/things/articles/78abedb6be79682025ae38836c23ce77> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This paper examines the cyclical relationship between exports and output in the U.K. using structural time-series modelling. The time series on exports and output over the period 1885–1993 are decomposed, and the cyclical components are extracted. Causality testing as applied to the cyclical components reveals the absence of causality from exports to output except in the post-1945 period. The results of causality testing are confirmed by the results of estimating a structural time-series model in which exports appear as an explanatory state variable. Three different explanations are suggested for the change in this relationship during the most recent period." .
<http://www.springernature.com/scigraph/things/articles/c220fb7628b79d1335b94c0437f47cf3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We present measurements of triple gauge boson coupling parameters using data recorded by the OPAL detector at LEP2, at a centre-of-mass energy of 172 GeV. A total of 120 W-pair candidates has been selected in the ${\\rm q \\bar q q \\bar q}$, ${\\rm q\\bar q} \\ell \\bar\\nu_\\ell$ and $\\ell \\bar \\nu_\\ell \\bar\\ell^\\prime \\nu_{\\ell^\\prime }$ decay channels, for an integrated luminosity of 10.4 pb $^{-1}$. We use these data to determine several different anomalous coupling parameters using the measured cross-section and the distributions of kinematic variables. We measure $\\alpha_{B\\phi} = 0.35^{+1.29}_{-1.07} \\pm 0.38$, $\\alpha_{W\\phi} = 0.00^{+0.30}_{-0.28} \\pm 0.11$, $\\alpha_W = 0.18^{+0.49}_{-0.47} \\pm 0.23$, $\\Delta g^{\\rm z}_1 = -0.03^{+0.40}_{-0.37} \\pm 0.14$, $\\Delta\\kappa_\\gamma ^{(HISZ)} = 0.03^{+0.55}_{-0.51} \\pm 0.20$, and $\\Delta \\kappa = 0.33^{+0.49}_{-0.46} \\pm 0.21$. Combining the $\\alpha_{W\\phi}$ result with our previous result obtained from the 161 GeV data sample we measure $\\alpha_{W\\phi} = -0.08^{+0.28}_{-0.25} \\pm 0.10$. All of these measurements are consistent with the Standard Model." .
<http://www.springernature.com/scigraph/things/articles/1a5d80afb6df0efb83437fa4e85ff7bd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Since the 1990s many emerging countries have adopted a fixed exchange-rate peg vis-à-vis a reserve currency in order to cope with economic imbalances such as buoyant inflation, high unemployment or staggering economic growth. However, after a period of economic stabilisation and prosperity, overheating effects showed up in several countries that were often coupled with difficulties in the banking and/or the real estate sector. Sticking with a fixed peg, the likelihood of a currency crisis increased. The case of Argentina shows that even with a currency board it is difficult to restore confidence if a crisis has already been developing for several years. This article presents an economic analysis of the Argentina crisis." .
<http://www.springernature.com/scigraph/things/articles/9fa9103d3c5e054e30ffbb5fc24b1e86> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper is an attempt to improve on the approximation. First author citations (Cf)≈Total citations (Ct) of an author's publications without the work of making the complete citation count under the author and all co-author names. Using the bibliographies of all faculty from each of four large departments: Physics, Chemistry, Materials Sciences, and Biosciences, in the same university, both first author and complete citation counts were made, care being taken to avoid the most common errors in such counts. It is shown that the function Cf·T/F (where T and F are the total number of papers and F those with subject author's name first) correlates strongly (>90%) with Ct. We find also that Ct correlates strongly with T. The data also may be used as one more line of evidence to obtain normalizing ratios for possible comparisons of productivityacross different disciplinary universes. A very tentative ratio from different studies would be 8 (Chem.)=4 (Physics)=2.5 (Mat. Sci.)=2 (Mathematics)=4.5 (Biophysics-Biochemistry)." .
<http://www.springernature.com/scigraph/things/articles/c7d2a9fdc6a0eade210a2468b1a53d7c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper analyzes the performance of Dutch drinking water utilities before and after the introduction of sunshine regulation, which involves publication of the performance of utilities but no formal price regulation. By decomposing profit change into its economic drivers, our results suggest that, in the Dutch political and institutional context, sunshine regulation was effective in improving the productivity of publicly organised services. Nevertheless, while sunshine regulation did bring about a moderate reduction in water prices, sustained and substantial economic profits suggest that it may not have the potential to fully align output prices with economic costs in the long run. In methodological terms, the DEA based profit decomposition is extended to robust and conditional non-parametric efficiency measures, so as to account better for both uncertainty and differences in operating environment between utilities." .
<http://www.springernature.com/scigraph/things/articles/f8be93e9ff21c4805764e0c15b225a9a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We consider the joint effect of competition and deposit insurance on risk taking by banks when bank risk is unobservable to depositors. It turns out that the magnitude of risk taking depends on the structure and side of the market in which competition takes place. If the bank is a monopoly or banks are competing only in the loan market, deposit insurance has no effect on risk taking. Banks in this situation tend to take risk, although extreme risk taking is avoided. In contrast, introducing deposit insurance increases risk taking if banks are competing for deposits. Then, deposit rates become excessively high, thereby forcing banks to take extreme risks." .
<http://www.springernature.com/scigraph/things/articles/9e4769ca0d31638f2fc8b924a696d6ac> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper studies the impact of transparency in the mortgage market on the underlying real estate market. We show that geographic transparency in the secondary mortgage market, which implies geographic risk based pricing in the primary market, can limit risk-sharing and make house prices more volatile. Ex ante, regions prefer opaque markets to enable insurance opportunities. We discuss the implications for risk based pricing and house price volatility more generally. In addition, we investigate the specific conditions under which competitive lenders would optimally choose to provide opaque lending, thus reducing volatility in the real estate market. We show that in general the opaque competitive equilibrium is not stable, and lenders have incentive to switch to transparent lending if one of the geographic regions has experienced a negative income shock. We propose market and regulatory mechanisms that make the opaque competitive equilibrium stable and insurance opportunities possible." .
<http://www.springernature.com/scigraph/things/articles/1259076df3b68347937171ff6619ac99> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We apply Bayesian model averaging and a frequentistic model space analysis to assess the pricing determinants of credit default swaps (CDSs). Our study focuses on the complete model space of plausible models and thus supports ultimate robustness. Using a large dataset of CDS contracts we find that CDS price dynamics can be mainly explained by factors describing firms’ sensitivity to extreme market movements. More precisely, our results suggest that dynamic copula based measures of tail dependence incorporate most essential pricing information, making other potential determinants such as Merton-type factors or linear variables measuring the systematic market evolution negligible." .
<http://www.springernature.com/scigraph/things/articles/05c270acb5ddc4e52104650434da46fc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary Some hydrologic, climatologic and artificially generated time series are analyzed for periodic components using a nonharmonic (NH) method of spectral estimation. The NH spectra are compared with those obtained by using the traditional Blackman and Tukey (BT) and Fast Fourier Transform (FFT) methods and with the relatively recent Maximum Entropy (ME) and Autoregressive Moving Average (ARMA) methods. The NH method appears to be promising." .
<http://www.springernature.com/scigraph/things/articles/b09c21ca57242f360dee54b8ee93bddd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we develop and estimate a dynamic stochastic, general-equilibrium New Keynesian model with partial dollarization. Bayesian techniques and Peruvian data are used to evaluate two forms of dollarization: currency substitution (CS) and price dollarization (PD). The empirical results are as follow: first, it is noted that the two forms of partial dollarization are important in explaining the significance of the Peruvian data. Second, models with both forms of dollarization dominate models without dollarization. Third, a counterfactual exercise shows that by eliminating both forms of partial dollarization, the response of both output and consumption to a monetary policy shock doubles, making the interest rate channel of monetary policy more effective. Fourth, based on the variance decomposition of the preferred model (with CS and PD), it is found that demand type shocks explain almost all the fluctuation in CPI inflation, the monetary shock being the most important (39%). Remarkably, foreign disturbances account for 34% of the output fluctuations." .
<http://www.springernature.com/scigraph/things/articles/f35142c9e7f2416099a01e7ad6ced291> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper describes the development of an empirical deterministic two-factor response surface model for the Woodruff lime-requirement buffer (WRF). The model may be used to produce variable-rate lime requirement maps, or to predict lime requirements in real-time. Hence it may be suitable as a component of a decision support system (DSS) for the site-specific management of acid soil. The models' predictions were compared to those of a one-factor response surface, and those of a linear regression. The models tested were validated against soil-CaCO3 incubations using a statistical jackknifing procedure for error and bias estimations. The Akaike Information Criterion (AIC) was used to ascertain the best model in terms of goodness of fit and parsimony. The two-factor response surface model produced the best lime requirement estimates, followed by the single-factor model, then the conventional linear regression. The advantages of the response surface models are their improved prediction accuracy, and their flexibility in the choice of any target pH (from pH 5.5 to 7) without the need for excessive calibrations. The uncertainty of the model was assessed using data from an agricultural field in Kelso, New South Wales, Australia. Block kriged maps of soil pH measured in 0.01 M CaCl2 (pHCaCl2), WRF buffer pH (pHbuffer) and lime requirements to a target pH of 7 were produced, to compare their spatial distributions. Finally the economic and agronomic benefits of site-specific liming were considered." .
<http://www.springernature.com/scigraph/things/articles/09104a664fd29fc1cbf8a55ef6fbc41d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract High frequency financial data modelling has become one of the important research areas in the field of financial econometrics. However, the possible structural break in volatile financial time series often trigger inconsistency issue in volatility estimation. In this study, we propose a structural break heavy-tailed heterogeneous autoregressive (HAR) volatility econometric model with the enhancement of jump-robust estimators. The breakpoints in the volatility are captured by dummy variables after the detection by Bai–Perron sequential multi breakpoints procedure. In order to further deal with possible abrupt jump in the volatility, the jump-robust volatility estimators are composed by using the nearest neighbor truncation approach, namely the minimum and median realized volatility. Under the structural break improvements in both the models and volatility estimators, the empirical findings show that the modified HAR model provides the best performing in-sample and out-of-sample forecast evaluations as compared with the standard HAR models. Accurate volatility forecasts have direct influential to the application of risk management and investment portfolio analysis." .
<http://www.springernature.com/scigraph/things/articles/f97684124a4b8d0c2d7613b8f339f556> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper introduces and discusses a complex econometric model of non-life technical provisions based on the Czech non-life insurance market data. Selected economic-actuarial relations among given insurance variables are described by means of the dynamic linear system of simultaneous equations used in econometrics. In particular, the provision for outstanding claims, the provision for unearned premium, the other (marginal) technical provisions, the acquisition and administrative expenses, the benefit expenses, and their mutual interactions are studied in detail. The suggested simultaneous equations model is estimated, statistically verified, and interpreted with special regard to the actuarial point of view. The proposed modelling scheme can be further employed for prognosing the considered non-life technical provisions. Particularly, such forecasts can be taken into account by non-life insurance companies in their internal calculations (e.g. for financial planning purposes, for testing the sufficiency of non-life technical provisions, or for liability adequacy tests LAT) or by an insurance regulator or supervisory authority (e.g. for performing stress tests). Alternatively, this approach might motivate development of internal models applicable in the Solvency II framework. Both deterministic and randomly generated scenarios are analysed which can deliver relevant outputs for formulating crucial recommendations and conclusions." .
<http://www.springernature.com/scigraph/things/articles/b5b629e96927ffa56ad25d40bcb5a104> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract An improved neural network of time series predicting is presented in this paper. We introduce a random data-time effective radial basis function neural network in determination of the output weights, the center vectors and the widths in the hidden layer of the network. In the training modeling, we consider that the historical data on the financial market is key to the investors’ decision-making for their investing positions, and the impact of historical data depends closely on the time. We develop a random data-time effective function to describe this impact strength, and a weight is given to each of the historical data, where a drift function and a random Brownian volatility function are applied to express the behavior of the time strength. Further, this neural network is applied to the prediction of financial price series of crude oil, SSE, N225 and DAX. The empirical experiments show that the proposed neural network results in better performance in financial time series forecasting and is advantageous in increasing the forecasting precision." .
<http://www.springernature.com/scigraph/things/articles/4497c438be29a2bf00857bc6f5431619> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A major application of rescaled adjusted range analysis (R–S analysis) is to the study of price fluctuations in financial markets. There, the value of the Hurst constant, H, in a time series may be interpreted as an indicator of the irregularity of the price of a commodity, currency or similar quantity. Interval estimation and hypothesis testing for H are central to comparative quantitative analysis. In this paper we propose a new bootstrap, or Monte Carlo, approach to such problems. Traditional bootstrap methods in this context are based on fitting a process chosen from a wide but relatively conventional range of discrete time series models, including autoregressions, moving averages, autoregressive moving averages and many more. By way of contrast we suggest simulation using a single type of continuous-time process, with its fractal dimension. We provide theoretical justification for this method, and explore its numerical properties and statistical performance by application to real data on commodity prices and exchange rates." .
<http://www.springernature.com/scigraph/things/articles/4dc4dc255f0607621aab7fa82d452abc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper examines whether the clarity of central bank communication about inflation varies with the economic environment. Using readability statistics and content analysis, we study the clarity of communication on the inflation outlook by seven central banks across three continents during the recent decade. We uncover significant and persistent differences in clarity over time and across countries. However, identifying determinants of clarity that are robustly relevant across our sample of central banks proves elusive. Overall, our findings suggest that a single model for clarity of central bank communication is not appropriate. Rather, when studying clarity of communication, country-specific and institution-specific factors are highly relevant." .
<http://www.springernature.com/scigraph/things/articles/b42bd613f5be6a7efbcd72bf3b2cd376> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract: For foreign currency exchange rates, multi-affine analysis can put quantitatively into evidence the differences between correlated (daily closing market) values and random walks in time dependent data. The H(q) spectrum is presented and discussed here for the USD/DEM and JPY/USD exchange rates. The time-evolution of these ratios is found to be multi-affine. The $$h(\\gamma )$$ -curve describing the hierarchy of exponents is numerically obtained. Our findings suggest that the modelling of exchange rate time-evolution from day to day is possible within the framework of modern statistical physics and related to models of turbulence in the physics of fluids. Finally, we argue that there is a multiplicity of information levels in the foreign exchange market such that the “efficient market theory” is a crude oversimplification indeed." .
<http://www.springernature.com/scigraph/things/articles/df81f75641dca85cf6ea7baeff00c743> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The modeling of financial price fluctuations is always a hot research aspect that many researchers are concerned about. A financial price model based on two-dimensional continuum percolation system, which is one of the most important statistical physics systems, is introduced in this work. In the model, the fluctuations of stock price changes are assumed to be attributed to the market information interactions among the traders, and the percolation cluster is taken to represent the traders holding the same investment attitude. Then, multifractal detrended fluctuation analysis method is adopted to study the multifractal behaviors of simulation data with different parameter sets. Finally, the recurrence plot and recurrence quantification analysis techniques are applied to investigate the complex determinism dynamics hidden in the simulated stock returns from the price model, as well as in their different intrinsic mode functions (IMFs) decomposed from the empirical mode decomposition method. Abundant and distinctive recurrence behaviors can be observed among returns and IMFs time series. In the meanwhile, the corresponding behaviors of the Chinese Shanghai Composite Index is studied for comparison." .
<http://www.springernature.com/scigraph/things/articles/3ac648e4413ae8e5655bf04e2a9e139b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We consider consumption taxes in a model of endogenous Cournot versus Bertrand competition. It is argued that when the choice of unit versus ad valorem taxes affects longer-term decisions beyond the customary price or quantity decisions, the mix of the two taxes co-determines market conduct. This gives ad valorem taxes an anti-competitive effect that harms ad valorem taxes’ efficiency in comparison with unit taxes. We show that a mix of the taxes—or a unit tax alone if we compare one or the other of the taxes—is sometimes welfare superior on account of consumer-price and tax revenue effects. A practical implication of our findings is that pass-through rates are only sometimes useful guides for policy. In fact, we show when the proper response to demand for higher revenue is a higher unit tax rate and a lower ad valorem tax rate." .
<http://www.springernature.com/scigraph/things/articles/45fc5d62462de21e5c0adb311ccc2283> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Credit risk has been one of the most active areas of recent financial research. It is driven by advances in portfolio risk measurement and management techniques, growth in credit derivatives trading, the Basel II implementation, and regulatory concerns stemming from the commercial credit crunch that initially took place in 2001 and 2002 in the USA. Within this broader literature, a growing body of research analyzes the meaning, role, and influence of credit ratings that quantify credit risk. This paper examines the two-way links between credit risk measurement and the macroeconomic conditions, interpreted through phases of business cycles. We propose a methodology applied on bank internal rating data, which estimates ratings migration probabilities while integrating the state of the economy. We first discuss the issue of whether credit risk is low or high in different economic scenarios. In order to evaluate this prospect, we examine each year in four quarters that represent different scenarios throughout the year. We then review how macroeconomic considerations are incorporated into credit risk models and the risk measurement approach that underlies Basel II and Basel III." .
<http://www.springernature.com/scigraph/things/articles/46fc1d07ad737e7965b29925e30a1dc7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary It is shown that the relative error of the bootstrap quantile variance estimator is of precise order n -1/4, when n denotes sample size. Likewise, the error of the bootstrap sparsity function estimator is of precise order n -1/4. Therefore as point estimators these estimators converge more slowly than the Bloch-Gastwirth estimator and kernel estimators, which typically have smaller error of order at most n -2/5." .
<http://www.springernature.com/scigraph/things/articles/aef06c49f13c3f2cfedd6d61b115c5cd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A partially varying-coefficient model is one of the useful modelling tools. In this model, some coefficients of a linear model are kept to be constant whilst the others are allowed to vary with another factor. However, rarely can the analysts know a priori which coefficients can be assumed to be constant and which ones are varying with the given factor. Therefore, the identification problem of the constant coefficients should be solved before the partially varying-coefficient model is used to analyze a real-world data set. In this article, a simple test method is proposed to achieve this task, in which the test statistic is constructed as the sample variance of the estimates of each coefficient function in a well-known varying-coefficient model. Moreover two procedures, called F-approximation and three-moment χ 2 approximation, are employed to derive the p-value of the test. Furthermore, some simulations are conducted to examine the performance of the test and the results are satisfactory." .
<http://www.springernature.com/scigraph/things/articles/175d8e66144be2f9fa1ec6a0b0fe440e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article links parameterized model mortality schedules with time series methods to develop forecasts of U.S. mortality to the year 2000. The use of model mortality schedules permits a relatively concise representation of the history of mortality by age and sex from 1900 to 1985, and the use of modern time series methods to extend this history forward to the end of this century allows for a flexible modeling of trend and the accommodation of changes in long-run mortality patterns. This pilot study demonstrates that the proposed procedure produces medium-range forecasts of mortality that meet the standard tests of accuracy in forecast evaluation and that are sensible when evaluated against the comparable forecasts produced by the Social Security Administration." .
<http://www.springernature.com/scigraph/things/articles/ffe97748a0c502eb72a822ce5223f5f6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article investigates whether the German Dominance Hypothesis is valid within the context of nominal short-term interest rates. The approach taken to address this hypothesis is based on the notion that German interest rates should convey valuable information to other countries' rates or that there exist significant multidirectional volatility spillovers from the Bundesbank to other nations' central banks. These transfers can be analyzed within a multivariate framework of an Exponential GARCH model capable of capturing the potential asymmetries of the volatility spillover mechanism. The results, basically, do not support the idea of a German predominance within the system, in a strict sense, since Germany's rates are also affected, for the most part, by actions from its partners." .
<http://www.springernature.com/scigraph/things/articles/39a0c33989cd14ec9bfc081fc5881419> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study investigates the meteorological variation in revealed preference travel data. The main objective of this study is to investigate the impact of weather conditions on daily activity participation (trip motives) and daily modal choices in the Netherlands. To this end, data from the Dutch National Travel Household Survey of 2008 were matched to hourly weather data provided by the Royal Dutch Meteorological Institute and were complemented with thermal indices to indicate the level of thermal comfort and additional variables to indicate the seasonality of the weather conditions. Two multinomial logit–generalised estimation equations (MNL-GEE) models were constructed, one to assess the impact of weather conditions on trip motives and one to assess the effect of weather conditions on modal choice. The modelling results indicate that, depending on the travel attribute of concern, other factors might play a role. Nonetheless, the thermal component, as well as the aesthetical component and the physical component of weather play a significant role. Moreover, the parameter estimates indicate significant differences in the impact of weather conditions when different time scales are considered (e.g. daily versus hourly based). The fact that snow does not play any role at all was unexpected. This finding can be explained by the relatively low occurrence of this weather type in the study area. It is important to consider the effects of weather in travel demand modelling frameworks because this will help to achieve higher accuracy and more realistic traffic forecasts. These will in turn allow policy makers to make better long-term and short-term decisions to achieve various political goals, such as progress towards a sustainable transportation system. Further research in this respect should emphasise the role of weather conditions and activity-scheduling attributes." .
<http://www.springernature.com/scigraph/things/articles/429f0fd0a5bcfe86f46604f9852edac9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We analyse the issue of central bank accountability with the aid of a simple monetary policy game with uncertainty about the agent's inflation stabilisation preferences. We find that there may be an important economic role for accountability in addition to its political function of making the central bank answerable to voters through its accountability to the executive. The model suggests that for countries with relatively little central bank independence, or perhaps a poor inflationary track record, significant reductions in inflation can be achieved by lowering monetary policy uncertainty. These reductions are much smaller for inflation-averse central banks, when monetary policy uncertainty is reduced by the same absolute amount. Thus, the effectiveness of accountability – as a means of lowering both inflation and inflation uncertainty – is higher the lower the degree of central bank conservativeness." .
<http://www.springernature.com/scigraph/things/articles/f4a2609a077623b54e05264c4a004e2f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract  As an extension of our previous paper which gave forward and backward error estimates, we perform a running error analysis of the multivariate Horner scheme. This leads to a modified algorithm which computes the value of the polynomial together with an error estimate." .
<http://www.springernature.com/scigraph/things/articles/d16e27d6e745935b92fed69f3975724d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We investigate the presence and temporal evolution of short- and intermediate-term periodicities in the daily data of sunspot numbers and coronal index for the time span from May 1996 to December 2008, which covers the entire Solar Cycle 23. The daily sunspot number data have been analyzed for the full disk, and for northern and southern hemispheres of the Sun. Using the wavelet power spectrum technique, we find a number of quasi-periodic oscillations in all the data sets. We also find a prominent period of 22 to 35 days in the high-frequency range, and detect the Rieger period of 150 to 160 days in both data sets during different phases of Cycle 23. We also detect ∼1.3 year oscillation in both sunspot and coronal index time series. In addition, we find a number of other short and mid-term periods. We discuss possible explanations of the observed periodicities in the light of previous results and existing numerical models." .
<http://www.springernature.com/scigraph/things/articles/9add9ae54f10cc2e29c3bf478aa75a20> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study is an investigation of fuzzy logistic regression model for crisp input and fuzzy output data. The response variable is non-precise and is measured by linguistic terms. Especially this research develops least absolute deviations (LAD) method for modeling and compares the results with the least squares estimation (LSE) method. For these, two estimation methods, min–max method and fitting method, are provided in this research. This study presents new goodness-of-fit indices which are called measure of performance based on fuzzy distance $$(M_p)$$ (Mp) and index of sensitivity $$(I_S)$$ (IS) . The study gives two numerical examples in real clinical studies about systematic lupus erythematosus and the other one in the field of nutrition to explain the proposed methods. In addition, we investigate the sensitivity of two estimation methods in the case of outliers by a numerical example." .
<http://www.springernature.com/scigraph/things/articles/0e6ae984aaba1b357ab9735ed366ff85> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Forecasting of sea-state characteristics has a great importance in coastal and ocean engineering studies. Therefore, the purpose of this study was to investigate performances of Adaptive-Network-Based Fuzzy Inference System (ANFIS) and several parametric methods in the Black Sea. For this purpose, different fuzzy models with different input combinations were developed for two different wind data sources (TSMS and ECMWF) at two offshore buoy stations. It also aimed to apply several approaches to event-based data sets for wave predictions. Generally, in literature the tendency is to use time series data for wave predictions. In this kind of prediction approach, lagged time series data are taken as inputs and current or future variables are taken as output. In this study, event-based data for each independent storm were extracted from time series data. Simultaneous or concurrent data of wind speed, blowing duration, fetch length and wave characteristics were detected for each single storm. These event data were then used to set up models. The hindcast results were validated with significant wave height and mean wave period data recorded in Hopa and Sinop buoy stations. The performance of developed fuzzy models were also compared with that of four different parametric methods (Wilson, SPM, Jonswap, and CEM methods) applied for two wind data sources at both buoy stations. Finally, it was determined that in the prediction of both wave parameters (H s and T z) the ANFIS models (R = 0.66, squared correlation coefficient, and MAE = 0.37 m, mean absolute error, for the best model in prediction of H s) were more accurate than the parametric methods (R = 0.63 and MAE = 0.75 m for the best model in prediction of H s)." .
<http://www.springernature.com/scigraph/things/articles/db92364d7393702e640111bcd1e72a8a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A novel two-stage approach is presented for improving the estimates of both the kinematic state and the unknown external forces in rigid-link multibody systems with negligible joint clearance. The approach is said to be a two-stage one because the estimation process is carried out by two observers running simultaneously and only partially coupled in order to reduce model uncertainties. Nonlinear Kalman filters are employed at both stages. In the first stage, a kinematic observer estimates an augmented system state (i.e., positions, velocities and accelerations) by employing the kinematic constraint equations and some measurements of kinematic quantities as inputs and outputs. Therefore, it is unbiased by external forces and uncertainties on any dynamic parameters. In the second stage, a force observer estimates the external forces by employing dynamic models. The input of the force observer is the kinematic state, while the correction is performed through some direct or indirect measurements of the known forces. Numerical assessment of the theory developed is provided through a slider–crank mechanism. The results achieved through the proposed approach are compared with those yielded by traditional unknown input observers based on a single-stage dynamic estimation. An extensive statistical analysis is carried out at varying levels of measurement noise. Two different strategies are followed in the synthesis of the non-linear Kalman filters. The comparison clearly shows the advantages and the effectiveness of the new two-stage approach." .
<http://www.springernature.com/scigraph/things/articles/4049afcb25caf51adda4d2786463a59e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The programForecast conducts a session to obtain forecasts from subjects for successive values of an evolving chaotic time series. The user of Forecast can control the session by selecting a number of options for the time series, including both the type (Hénon, or logistic) and degree of chaos. Forecast was created in Turbo Pascal and has been run on a 386 AT with a mouse and on a PS/2 with either a mouse or a touch-sensitive screen. Single sessions conducted by Forecast have collected 600 forecasts at a rate of one per 2 sec from adults and, without alteration, 180 forecasts from young (3–5 years) children. Compared with three procedures using other display modes or response modes, Forecast collected about three times the number of forecasts in sessions that were only about a third to one half as long." .
<http://www.springernature.com/scigraph/things/articles/63853a896b032e7a6f48bec7ef5a912b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract.   Mutual information is a generalised measure of dependence between any two variables. It can be used to quantify non-linear as well as linear dependence between any two variables. This makes mutual information an attractive alternative to the use of the correlation coefficient, which can only quantify the linear dependence pattern. Mutual information is especially suited for application to hydrological problems, because the dependence between any two hydrologic variables is seldom linear in nature. Calculation of the mutual information score involves estimation of the marginal and joint probability density functions of the two variables. This paper uses nonparametric kernel density estimation methods to estimate the probability density functions. Accurate estimation of the mutual information score using kernel methods requires selection of appropriate smoothing parameters (bandwidths) for use with the kernels. The aim of this paper is to obtain a practical method for bandwidth selection for calculation of the mutual information score. In this paper, the lag-one dependence structures of several autocorrelated time series are analysed using mutual information (note that this produces the lag-one auto-MI score, the analog of the lag-one autocorrelation). Empirical trials are used to select appropriate bandwidths for a range of underlying autoregressive and autoregressive-moving average models with normal or near-normal parent distributions. Expressions for reasonable bandwidth choices under these conditions are proposed." .
<http://www.springernature.com/scigraph/things/articles/cbd64cc3a2a7522786999c8cdf8429b0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A central limit theorem for the realized volatility estimator of the integrated volatility based on a specific random sampling scheme is proved, where prices are sampled with every ‘continued price change’ in bid or ask quotation data. The estimator is shown to be robust to market microstructure noise induced by price discreteness and bid–ask spreads. More general sampling schemes also are treated in case that the price process is a diffusion." .
<http://www.springernature.com/scigraph/things/articles/57a3dbdaeb2eea8b4676cebab8115c23> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Poverty is commonly defined as a lack of economic resources that has negative social consequences, but surprisingly little is known about the importance of economic hardship for social outcomes. This article offers an empirical investigation into this issue. We apply panel data methods on longitudinal data from the Swedish Level-of-Living Survey 2000 and 2010 (n = 3089) to study whether poverty affects four social outcomes—close social relations (social support), other social relations (friends and relatives), political participation, and activity in organizations. We also compare these effects across five different poverty indicators. Our main conclusion is that poverty in general has negative effects on social life. It has more harmful effects for relations with friends and relatives than for social support; and more for political participation than organizational activity. The poverty indicator that shows the greatest impact is material deprivation (lack of cash margin), while the most prevalent poverty indicators—absolute income poverty, and especially relative income poverty—appear to have the least effect on social outcomes." .
<http://www.springernature.com/scigraph/things/articles/906eb0bd4894c27f47ae253ff3a50c43> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper aims to contribute further research on the conceptualization of individual financial satisfaction as a particular domain of satisfaction with life as a whole. Based on the 2003 Survey on Living Conditions and Poverty for Andalucía (Spain) and using a self-reported measure of welfare, ordered probit models are used to analyze the extent to which individual financial satisfaction can be solely explained by income in absolute terms, or alternatively, by taking into account the importance of relative income in its two dimensions: (1) personal aspirations as individual’s adaptation to previous and future income levels (intra-individual comparisons), and (2) social comparisons as individual’s concern for her peer’s income (inter-personal dependency)." .
<http://www.springernature.com/scigraph/things/articles/6a64c1a9f83ea270a6d48163c1e85306> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract An investigation is performed as to the extent J and Q calculated for successively stationary crack positions can be used to characterize the state at a growing crack in a corresponding geometry. FE models of single-edge notch bend and double-edge cracked panel specimens are used to cover a variation of constraint levels. The stress and strain fields are compared between different specimens at equal J-values and Q-values, respectively. A remeshing technique is used to enhance the efficiency of the analysis. The commercial FE-code ABAQUS is used and substantial crack growth is achieved with less computer time and better accuracy than in conventional FE analysis." .
<http://www.springernature.com/scigraph/things/articles/4cde6d4c15221eb6e3582d4c1c047fd8> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The aim of this paper is to analyse the economic efficiency of members of protected designations of origin (PDO). For the first time we analyse the value of PDO labels from the point of view of economic efficiency. The central hypothesis is that a PDO has a positive impact on the economic efficiency of its member companies and that this is because a PDO label is a collective reputation indicator that foments efficient investment in quality in terms of member returns. The methodology applied to test this hypothesis is based on data envelopment analysis to estimate economic efficiency, and econometric models to explain company efficiency through both the PDO label, as an indicator of collective reputation, and the characteristics of the company. The results obtained in the experience goods of wine and cheese in Spain show that PDO labels have a positive impact on economic efficiency. Additionally, the age and size of the company have a positive effect while the wage level of the company has a different influence on efficiency depending on the sector considered. Overall, the results reveal the importance of PDOs in industries in which the signal of reputation is not only reliant on the individual brands." .
<http://www.springernature.com/scigraph/things/articles/f9300baba889b0e92e3746aea9c3e1f2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper we estimate equilibrium exchange rates for 23 OECD countries and four less mature economies in a panel data setting. Our empirical analysis demonstrates significant links between the trade balance and net foreign assets, and between real exchange rates and the trade balance, rather than between real exchange rates and net foreign asset, as predicted by the model of Lane and Milessi-Ferretti (2002). Our study indicates that, in terms of the association between real exchange rates and trade balance, there is heterogeneity between the emerging market economies and the OECD countries. Finally, we construct various measures of exchange rate misalignment for all the exchange rates included in our panels." .
<http://www.springernature.com/scigraph/things/articles/58b397988d3f9b9b285a95aa5fb89405> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This paper deals with minimum distance (MD) estimators and minimum penalized distance (MPD) estimators which are based on the L p distance. Rates of strong consistency of MPD density estimators are established within the family of density functions which have a bounded m-th derivative. For the case p=2, it is also proved that the MPD density estimator achieves the optimum rate of decrease of the mean integrated square error and the L 1 error. Estimation of derivatives of the density is considered as well. In a class parametrized by entire functions, it is proved that the rate of convergence of the MD density estimator (and its derivatives) to the unknown density (its derivatives) is of order $$1{\\text{/}}\\sqrt n$$ in expected L 1 and L 2 distances. In the same class of distributions, MD estimators of unknown density and its derivatives are proved to achieve an extraordinary rate (log log n/n)1/2 of strong consistency." .
<http://www.springernature.com/scigraph/things/articles/ce792713f9eb3f3c84fc3d00149d2f9f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The purpose of this paper is to derive conditions for the optimality of a limit cycle in a dynamic economic system and to interpret them economically. A fairly general two-state continuous-time nonlinear optimal control problem is considered. It turns out that for this class of models three different economic mechanisms can be identified as the possible source of limit cycles. One relates to an intertemporal substitution effect expressed in terms of complementarity over time, the second one is a dominating cross effect between the state variables of the system (i.e., the capital stocks in our model), and the third one is positive growth at the equilibrium." .
<http://www.springernature.com/scigraph/things/articles/d217bd4ef369cc9d96cccada56056fcf> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Photosynthetically active radiation (PAR) is an important input parameter for most crop models. Unfortunately, a worldwide routine PAR measurement network has not been established, nor does one exist in China. In this study, the relationship between PAR and broadband solar radiation (R s) was investigated. Based on this analysis, three empirical models were developed for estimating PAR. These three models include parameters based on in situ measured R s and parameters obtained from R s. Model A uses only R s, whereas model B uses R s and the clearness index (K s, the ratio of R s to the extraterrestrial irradiance flux), and model C uses attenuation factors under clear skies (ρclear) and K s. Evaluating these estimation models revealed a strong correlation with low relative error between the observed and modeled PAR in Northeast China. The slope a and intercept b of the linear regression between the observed PAR and the modeled PAR are approximately 1 and 0, respectively. The relative error between the observed PAR and the modeled PAR is less than 10.7 %. Model C provides satisfactory estimates of the PAR values for locations where the model is developed. However, model B is more convenient for modeling PAR than model C because K s can be more easily determined than the transmissivity of PAR under clear sky conditions." .
<http://www.springernature.com/scigraph/things/articles/10e2e57a811372375876dde46cbdfbbb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A method of calibrating scanners based on multiresponse regression models which connect the color parameters of color images of a calibrated light target with the results of the scanning of this target is proposed. A procedure and the results of an analysis of the covariance matrices of the errors of observation of the color parameters for different types of scanners are presented. Estimates of the prediction capability of the proposed calibration method are given and comparative results of its use are presented." .
<http://www.springernature.com/scigraph/things/articles/3104b1582cf4ba77db34569447ce814a> <http://www.springernature.com/scigraph/ontologies/core/abstract> " This paper develops a two-good, small-country, general-equilibrium trade model with endogenous labor supply, where trade is restricted by a tariff or an import quota. Within this framework, it is shown that, contrary to Anam (1989), under an import quota domestic and world prices may vary in the same direction. This is due to the possibly positive employment effects of terms of trade shocks. In such a case, compared to fixed labor supply, variable labor supply is likely to make the domestic prices less sensitive to foreign price volatility." .
<http://www.springernature.com/scigraph/things/articles/9c7f306febbe67df356bd542d89c6b5d> <http://www.springernature.com/scigraph/ontologies/core/abstract> " This paper introduces product variety into the Balassa-Samuelson model in order to extend the model of real exchange rate determination. With product differentiation, real exchange rates depend not only on the relative price of nontradables to tradables but also on relative prices among tradables. This paper identifies a new factor that determines the extent of variety, termed Infrastructural Technology, and that affects real exchange rates not through the relative price of nontradables but through relative prices among tradables. This paper also conducts empirical tests, and the results of these tests support the model." .
<http://www.springernature.com/scigraph/things/articles/ff843b6a0b246516e997ae2929818008> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper estimates annual data on educational attainment for 3,076 mainland U.S. counties 1991–2005. Being estimated without resorting to ancillary information, this data is suited particular well for use in panel regression analyses. Several plausibility checks indicate that the data is fairly reliable and yields plausible parameter estimates in regressions." .
<http://www.springernature.com/scigraph/things/articles/27b7501fc05bf60ebce5a8fba037bc5e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper presents an attempt to use macrodynamic social indicators in a time series analysis of three crime categories-homicide; property and; robbery offenses in Israel. Earlier findings such as the relationship between homicide and unemployment, and density of population and property offenses are confirmed by the analysis. The models that are constructed are used later for forecasting and yield a satisfactory performance of at least two of the crime models." .
<http://www.springernature.com/scigraph/things/articles/d480e8f446f4a50ee8eafa262b5b47b0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper studies the emissions of SO2 and COD in China using fine-scale, countylevel data. Using a widely used spatial autocorrelation index, Moran’s I statistics, we first estimate the spatial autocorrelations of SO2 and COD emissions. Distinct patterns of spatial concentration are identified. To investigate the driving forces of emissions, we then use spatial econometric models, including a spatial error model (SEM) and a spatial lag model (SLM), to evaluate the effects of variables that reflect level of economic development, population density, and industrial structure. Our results show that these explanatory variables are highly correlated with the level of SO2 and COD emissions, though their impacts on SO2 and COD vary. Compared to ordinary least square regression, the advantages of SLM and SEM are demonstrated as they effectively reveal the existence and significance of spatial dependence. The SEM, in particular, is chosen over the SLM as the role of spatial correlation is stronger in the error model than in the lag model. Based on the research results, we present some preliminary policy recommendations, especially for those high–high cluster regions that face significant environmental degradation and challenge." .
<http://www.springernature.com/scigraph/things/articles/e551961c1680f91e6661e6419139b42d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract I study a model of growth and income distribution in which workers and firms bargain à la Nash (Econometrica 18(2):155–162, 1950) over wages and productivity gains, taking into account the trade-offs faced by firms in choosing factor-augmenting technologies. The aggregate environment resulting from self-interested, objective function-maximizing decision rules on wages, productivity gains, savings and investment, is described by a two-dimensional dynamical system in the employment rate and output/capital ratio. The economy converges cyclically to a long-run equilibrium involving a Harrod-neutral profile of technical change, a constant rate of employment of labor, and constant input shares. The type of oscillations predicted by the model is qualitatively consistent with the available data on the United States (1963–2003), replicates the dynamics found in earlier models of growth cycles such as Goodwin (A growth cycle, in C.H. Feinstein (ed). Socialism, Capitalism and Economic Growth. Cambridge University Press, Cambridge 1967. Cambridge University Press, Cambridge, 1967); Shah and Desai (Econ J 91:1006–1010, 1981); van der Ploeg (J Macroecon 9:1–12, 1987); Flaschel (J Econ: Zeitschrift für Nationalökonomie 44:63–69, 1984) and Sportelli (J Econ: Zeitschrift für Nationalökonomie 61(1):35–64, 1995), and can be verified numerically in simulations. Institutional change, as captured by variations in workers’ bargaining power, has a positive effect on the long-run rate of growth of output per worker but a negative effect on long-run employment. Economic policy can also affect the growth and distribution pattern through changes in the unemployment compensation, which also have a positive long-run impact on labor productivity growth but a negative long-run impact on employment. In both cases, employment can overshoot its new equilibrium value along the transitional dynamics." .
<http://www.springernature.com/scigraph/things/articles/63a164023a2f326b2ba787fe4b28ce27> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper we present a new approach for solving the pricing equations (PDEs) of European call options for very general stochastic volatility models, including the Stein and Stein, the Hull and White, and the Heston models as particular cases. The main idea is to express the price in terms of a power series of the correlation parameter between the processes driving the dynamics of the price and of the volatility. The expansion is done around correlation zero and each term is identified via a probabilistic expression. It is shown that the power series converges with positive radius under some regularity conditions. Besides, we propose (as in Alós in Finance Stoch. 10:353–365, 2006) a further approximation to make the terms of the series easily computable and we estimate the error we commit. Finally we apply our methodology to some well-known financial models." .
<http://www.springernature.com/scigraph/things/articles/b59c713a5c1234c191a688d07c90eced> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We compare the welfare of different combinations of monetary and currency policies in an open-economy macroeconomic model that incorporates two important features of many small open economies: a high level of vertical international trade and a high degree of exchange rate pass-through. In this environment, a small economy prefers a fixed exchange rate regime over a flexible regime, while the larger economy prefers a flexible exchange rate regime. There are two main causes underlying our results. First, in the presence of sticky prices, relative prices adjust through changes in the exchange rate. Multiple stages of production and trade make it more difficult for one exchange rate to balance the whole economy by adjusting several relative prices simultaneously throughout the vertical chain of production and trade. More specifically, there is a tradeoff between delivering an efficient relative price between home and foreign final goods and delivering an efficient relative price between home and foreign intermediate goods. Second, because the small economy faces a high degree of exchange rate pass-through under a flexible regime, it suffers from a lack of efficient relative prices in vertical trade. The larger economy, however, does not face this problem because its level of exchange rate pass-through is low." .
<http://www.springernature.com/scigraph/things/articles/ee7fe100b73152f8b56135d3bbcc172d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Plans for an early adoption of the euro by some new EU members hang on political will and a set of nominal criteria. The focus, however, should be on the available adjustment mechanisms supporting a permanently fixed exchange rate. Efficient financial markets could provide stabilisation (following a shock), substituting the weakened array of traditional policy instruments. In order to assess the availability of such alternative, this paper presents a particular empirical analysis of efficiency in the foreign exchange markets of three recently acceded countries. The results suggest that some caution is needed in the transition towards full monetary integration, as the level of financial efficiency already attained may be insufficient to ensure an adequate source of stabilisation in economies affected by specific disturbances." .
<http://www.springernature.com/scigraph/things/articles/7a5409c9e9981ddd5d1cbfe3e819bf27> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Short term electric load forecasting with a neural network based on fuzzy rules is presented. In this network, fuzzy membership functions are represented using combinations of two sigmoid functions. A new scheme for augmenting the rule base is proposed. The network employs outdoor temperature forecast as one of the input quantities. The influence of imprecision in this quantity is investigated. The model is shown to be capable of also making reasonable forecasts in exceptional weekdays. Forecasting simulations were made with three different time series of electric load. In addition, the neuro-fuzzy method was tested at two electricity works, where it was used to produce forecasts with 1–24 hour lead times. The results of these one month real world tests are represented. Comparative forecasts were also made with the conventional Holt-Winters exponential smoothing method. The main result of the study is that the neuro-fuzzy method requires stationarity from the time series with respect to training data in order to give clearly better forecasts than the Holt-Winters method." .
<http://www.springernature.com/scigraph/things/articles/6fd814730e83bd0391654be73f3c1d24> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Although the non-Gaussian nature of many hydrologic time series is well recognized and their nonlinearity is suspected, neither property is well tested. This situation has existed partly because of a lack of appropriate tests. Recently Hinich (1982) has developed a test to test the linearity of time series which is based on the bispectral characteristics of the series. This test is used in this study to investigate the linearity and non-Gaussian characteristics of annual and daily rainfall and runoff series. The annual series may be modeled by linear models with Gaussian inputs. The daily data, on the other hand, often demonstrate nonlinear characteristics and are non-Gaussian as well." .
<http://www.springernature.com/scigraph/things/articles/76f1f2c313c5dcb9b50c8284ef27e4f5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper suggests using a proportional hazard model to predict personal income, for the purpose of imputing missing income data in household travel surveys. The model has a hazard function that comprises two multiplicative components: (1) a non-parametric baseline hazard function that is dependent only on the income level and (2) a function that is dependent only on the other personal attributes of the survey respondents (excluding income). To estimate and validate the model, data is drawn from a travel characteristics survey conducted in Hong Kong in year 2001. The model is found to have a much higher accuracy when compared with a conventional ordered probit model based on the assumption that the logarithm of income is normally distributed." .
<http://www.springernature.com/scigraph/things/articles/4f8a1dfc9fb0f10a64cba6bcc28f4a9a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Fungal basidiospores andCladosporium spores are the two most numerous spore types in the air of Dublin and its surroundings. They are known to have allergenic components, and the aim of the study described here is to develop a predictive model for these spores. A very simple model, which combines an estimated diurnal rhythm with a simple, one-parameter time series model, provided golld short-term forecasts. The one-step prediction error variance was reduced by 88% forCladosporium spores and by 98% for basidiospores." .
<http://www.springernature.com/scigraph/things/articles/ec58c745f37d263c3d98827b54c1cdf3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract.  A brief review of the state of seasonal forecasting at the end of the twentieth century is given. The physical basis of seasonal predictability is examined, and the implications of this for forecast strategies considered. The range of methods used for seasonal forecasting is described, with its division into empirical and numerical strategies, and methods for creating multi-model forecasts are discussed. Numerical prediction of climate anomalies is a new and emerging field of human endeavour, and some of its particular challenges are highlighted. Finally, the importance of the development of applications of seasonal forecasts is stressed, and the non-trivial nature of this task is noted." .
<http://www.springernature.com/scigraph/things/articles/6abc4e2d5bff12c2af84c78def15cd0a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A new measure of credibility is constructed as a function of the differential between observed inflation and some estimate of the inflation rate that the central bank targets. The target is assumed to be met flexibly. Credibility is calculated for a large group of both advanced and emerging countries from 1980 to 2014. Financial crises reduce central bank credibility and central banks with strong institutional feaures tend to do better when hit by a shock of the magnitude of the 2007-2008 financial crisis. The VIX, adopting an inflation target and central bank transparency, are the most reliable determinants of credibility. Similarly, real economic growth has a significant influence on central bank credibility even in inflation targeting economies." .
<http://www.springernature.com/scigraph/things/articles/81b2c9b63b724692bbeeb996174b4671> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Although currency adjustment is often proposed as a policy tool to reduce current account imbalances, there is no consensus regarding the macroeconomic effects. In this paper we study the macroeconomic aftermath of large exchange rate appreciations. Using a sample of 128 countries over the period 1960–2008, we identify 25 episodes of large nominal and real appreciations shocks. We use narrative identification of exogenous appreciation episodes and study the macroeconomic effects in a dummy-augmented panel autoregressive model. Our results indicate that exchange rate appreciations tend to have strong effects on current account balances. Within 3 years after the appreciation event, the current account balance on average deteriorates by three percentage points of GDP. This effect occurs through a reduction of savings without a meaningful reduction in investment. Real export growth slows down substantially, but the output costs are small and not statistically significant. All these effects appear somewhat more pronounced in developing countries." .
<http://www.springernature.com/scigraph/things/articles/dbe26a56a0a49fe16606fa6cd2b88110> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We present the results of statistical analysis of the empirical floating-car data. Our investigations are based on analyzing the time series of four basic quantities namely velocity, velocity difference, spatial gap and the acceleration associated to some instrumented cars. We obtain the statistical characteristics, including the mean, variance and relative variance of these time series by taking direct time averages. We also try to identify the moving phases of the instrumented vehicle according to the statistical properties of its velocity time series. Moreover, by exploring the two-point joint probabilities, we propose a new approach for modelling vehicular dynamics based on the floating car data." .
<http://www.springernature.com/scigraph/things/articles/9030c143f7bab73a8b00c1950c8e8fbb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study demonstrates that in contrast to prior research findings on short-term stock returns, long-term stock returns are positively correlated with inflation. In addition, within the context of a more complete explanatory model, long-term stock returns are found to be negatively related to changes in long-term interest rates and negatively related to beginning price to earnings ratios. The significance of these variables in explaining almost all the time series variation in long-term stock returns demonstrates that changes in stock values are well explained by theory." .
<http://www.springernature.com/scigraph/things/articles/34da84be26a6f80abf18f2ae6f7f8be1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Using a unique data set on bank distress, this paper provides novel empirical evidence on the determinants of bank soundness in the European Union (EU) as a whole. The estimation results are consistent with the hypothesis that bank risks have converged across EU members, providing empirical support for introduction of a more centralized system of financial regulation in the EU. We show that asset quality and earning profile of banks are important determinants of bank distress next to leverage, suggesting that these should be central in EU-wide financial regulation and supervision. We find that market discipline, both by depositors and by stock market participants, plays a role in the EU, supporting the notion that transparency and dissemination of financial information would contribute to the financial soundness of banks. Our data also point to the presence of contagion effects, relatively higher fragility of concentrated banking sectors, and hazards associated with high ratios of wholesale funding." .
<http://www.springernature.com/scigraph/things/articles/05caeb88efb8b757b00166f89b89c640> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper deals with dynamic adjustment in large economies to changes in the rate of capital income taxation or in the rate of investment tax credit in one country. The framework applied in the paper is a continuous-time, overlapping generations model with two countries. It features population growth and debt non-neutrality. We address impact and steady state effects of capital income tax and investment subsidy changes in the home country on consumption per capita, the capital intensity, and the per capita net foreign asset position in both countries. We also briefly consider individual welfare consequences of these policies." .
<http://www.springernature.com/scigraph/things/articles/68e1fbbf0fbc3043d5f6cc84d0099983> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper analyzes the dynamic impact of discretionary government consumption purchases on private demand. Using a panel of 132 countries from 1960 to 2008, we find that while discretionary changes in government consumption lead to crowding-in effects in the short run, crowding-out effects take over in the medium run. In addition, we also find that both short-term crowding-in and medium-term crowding out effects are amplified once we control for periods of crisis." .
<http://www.springernature.com/scigraph/things/articles/c6668a3dbf2ea1472f13fa6c04909f53> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper we demonstrate that the menu-cost model implies that prices adjust asymmetrically to nominal-demand shocks and that the asymmetry is linked to the elasticity of demand as well as menu costs. These implications are tested using manufacturing and retailing panel data for the OECD countries. The empirical results give some support for the menu-cost model." .
<http://www.springernature.com/scigraph/things/articles/403dc950701414a8a3fb595e760ae953> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper analyses the propagation of the state changes of agents that are induced by external forces applied to a plane. In addition, we propose two models for the behavior of the agents placed on a lattice plane, both of which are affected by local interactions. We first assume that agents are allowed to move to another site to maximise their satisfaction. Second, we utilise a model in which the agents choose activities on each site. The results show that the migration (activity) patterns of agents in both models achieve stability without any external forces. However, when we apply an impulsive external force to the state of the agents, we then observe the propagation of the changes in the agents’ states. Using simulation studies, we show the conditions for the propagation of the state changes of the agents. We also show the propagation of the state changes of the agents allocated in scale-free networks and discuss the estimation of the agents’ decisions in real state changes. Finally, we discuss the estimation of the agents’ decisions in real state temporal changes using economic and social data from Japan and the United States." .
<http://www.springernature.com/scigraph/things/articles/8e9c9ccf2e44be6ace73abf35d0a9b76> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract For the conduct of monetary policy under floating exchange rates it is important to understand the role of the exchange rate in the monetary transmission mechanism (MTM). The timing and the magnitude of the effects of a change in the exchange rate on output and inflation may be quite different from traditional interest rate channels, thereby affecting optimal policy. In this paper we examine the exchange rate channel in the MTM in Germany by estimating an identified VAR model. Two features of the results are highlighted. The effect of a policy shock on the exchange rate accelerates the pass-through of policy into prices and leads to a different response of the various components of GDP. We then show that these qualitative effects can be duplicated in a general equilibrium model for a semi-small open economy with sticky prices and wages that is calibrated to capture the main features of the German economy." .
<http://www.springernature.com/scigraph/things/articles/703fdc1b34ffa08d879f9f87c2fed139> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper focuses on temporal aggregation of the cyclical component model as introduced by Harvey (1989). More specifically, it provides the properties of the aggregate process for any generic period of aggregation. As a consequence, the exact link between aggregate and disaggregate parameters can be easily derived. The cyclical model is important due to its relevance in the analysis of business cycle. Given this, two empirical applications are presented in order to compare the estimated parameters of the quarterly models for German and US gross domestic products with those of the corresponding models aggregated to annual frequency." .
<http://www.springernature.com/scigraph/things/articles/c3b3cc87f2a66a18ac50356f8243b464> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The model presented in this paper describes an economy with endogenous technical change and polluting production techniques. The main question we want to address is whether the adoption of “dirty” production processes might lead to a sustainable unique steady state, or guarantee the emergence of multiple equilibria. The application of the original Bogdanov–Takens theorem allows us to characterize the regions of the parametric space where the model exhibits either a global indeterminate equilibrium or a poverty-environment trap." .
<http://www.springernature.com/scigraph/things/articles/3b064fbd217e3993c44d0f42990d4c2d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract I develop a stylized model of endogenous growth in which the level of financial depth influences an economy’s long-run growth. Financial depth is defined within the model as the ease with which investors can issue equity in the market on new units of capital. I assume that agents differ in the cost of undertaking investment projects and that there is a fixed distribution of such costs across the population. I theoretically identify channels through which financial depth influences growth, both positively and negatively. When considering a specific distribution of costs, I show that the net effect of financial depth on growth is non-monotonic. It depends on the shape of the distribution, as well as the level or stage of financial depth. The results of this paper help to rationalize some findings in the recent empirical literature on the non-monotonic effect of financial depth on long-run growth. The model is even capable of obtaining a negative effect of excessive financial depth on growth, a result that is also found in the empirical literature." .
<http://www.springernature.com/scigraph/things/articles/1fc83df05362f6b8a46e6d2f4a3740bd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Hydrograph recession constants are required in rainfall-runoff models, baseflow augmentation studies, geohydrologic investigations and in regional low-flow studies. The recession portion of a streamflow hydrograph is shown to be either an autoregressive process or an integrated moving average process, depending upon the structure of the assumed model errors. Six different estimators of the baseflow recession constant are derived and tested using thousands of hydrograph recessions available at twenty-three sites in Massachusetts, U.S. When hydrograph recessions are treated as an autoregressive process, unconditional least squares or maximum likelihood estimators of the baseflow recession constant are shown to exhibit significant downward bias due to the short lengths of hydrograph recessions. The precision of estimated of hydrograph recession constants is shown to depend heavily upon assumptions regarding the structure of the model errors. In general, regression procedures for estimating hydrograph recession parameters are generally preferred to the time-series alternatives. An evaluation of the physical significance of estimates of the baseflow recession constant is provided by comparing regional regression models which relate low-flow statistics to three independent variables: drainage area, basin slope and the baseflow recession constant. As anticipated, approximately unbiased estimators of the baseflow recession constant provide significant information regarding the geohydrologic response of watersheds." .
<http://www.springernature.com/scigraph/things/articles/8110c5b2fdd31b198e90279d07bf4446> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The aim of this study was to establish population-based canine clinical chemistry reference values for the Hitachi 912 (Roche Diagnostics GmbH, Germany) with regard to age, sex, breed, housing and intended use. Reference biochemistry values for 22 variables are presented from 308 clinical healthy dogs, 145 females and 163 males, approximately 1 month to 13 years of age and of various breeds. For each variable the data were examined for homogeneity and, when suspected, outliers were excluded using the range test. Non-parametric analysis was used to calculate the conventional central 95% interval. Then the two-sided non-parametric 0.9 confidence interval of each percentile was determined. Finally, the effects of subgrouping were examined using the Kruskal–Wallis test and p <0.05 was considered significant. Significant age influences were found for 20 of the 22 variables, 14 showing clinical relevance. Significant breed effects could be found for 10 of the 22 parameters, including clinically relevant lower total protein concentrations for retrievers, lower lipase activity for sled dogs, lower total bilirubin concentrations for terriers and higher total bilirubin for Molossians. Differences between male and female were present for six of the 22 variables but had no clinical relevance. Housing and intended use influenced some of the values, but these differences were of no clinical significance. We successfully established canine clinical chemistry reference values for the Hitachi 912. The IFCC Recommendations on Reference Values offered a good framework for establishing standardised reference values, and make it possible for several laboratories to share the same values. Our results clearly indicate that subgrouping according to age and breed is necessary to obtain accurate reference values." .
<http://www.springernature.com/scigraph/things/articles/04f084db6ca8d9bcf4f5201ec378a1c4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. This paper suggests a short term interest rate model. It incorporates inflation rate, market variance, market net growth rate and market volatility trend. Empirical evidence from different markets supports the model." .
<http://www.springernature.com/scigraph/things/articles/163f45a0560b8d37010054cb411c56e1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Few studies concerning the nutritional requirements of Deinococcus geothermalis DSM 11300 have been conducted to date. Three defined media compositions have been published for the growth of this strain but they were found to be inadequate to achieve growth without limitation. Furthermore, growth curves, biomass concentration and growth rates were generally not available. Analysis in Principal Components was used in this work to compare and consequently to highlight the main compounds which differ between published chemically defined media. When available, biomass concentration, and/or growth rate were superimposed to the PCA analysis. The formulations of the media were collected from existing literature; media compositions designed for the growth of several strains of Deinococcaceae or Micrococcaceae were included. The results showed that a defined medium adapted from Holland et al. (Appl Microbiol Biotechnol 72:1074–1082, 2006) was the best basal medium and was chosen for further studies. A growth rate of 0.03 h−1 and a final OD600nm of 0.55 were obtained, but the growth was linear. Then, the effects of several medium components on oxygen uptake and biomass production by Deinococcus geothermalis DSM 11300 were studied using a respirometry-based method, to search for the nutritional limitation. The results revealed that the whole yeast extract in the medium with glucose is necessary to obtain a non-limiting growth of Deinococcus geothermalis DSM 11300 at a maximum growth rate of 0.64 h−1 at 45 °C." .
<http://www.springernature.com/scigraph/things/articles/605f583f356164b735af22be27938723> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This paper shows that the traditional specification of the consumption function in Dutch macroeconometric models is unsatisfactory. In the traditional approach the fact that the consumption decision is taken simultaneously with financial decisions has been ignored. If both the consumption function and the asset demand equations are modelled simultaneously, then in the Dutch case financial stocks have influence on private consumption. Also it has been shown that the income concept is important in describing household behaviour. In a current income model short-term financial considerations are important in the consumption decision. In a permanent income model long-term financial considerations influence private consumption." .
<http://www.springernature.com/scigraph/things/articles/8d8da33b9b6893766c355d15868e4e6e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract NAFTA has arguably been the most important and elaborate free-trade agreement in history, providing a blueprint for potential new agreements. So far, the evidence is mixed as to whether NAFTA has been successful in terms of its economic impact. We fit a multivariate stochastic volatility model that directly measures financial information linkages across the three participating countries in a trivariate setting. The model detects significant changes in information linkages across the countries from the pre- to post-NAFTA period with a high degree of reliability. This has implications not only for measuring these linkages but also for hedging and portfolio diversification policies. An MCMC procedure is used to fit the model, and the accuracy and robustness of the method is confirmed by simulations." .
<http://www.springernature.com/scigraph/things/articles/be9370eb069ec13e63824247deed6986> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Inner composition alignment (IOTA) is a recently proposed, permutation-based asymmetric association measure to identify coupling (interrelations) between different subsystems, together with the associated directionality, which is especially designed for very short time series. In this paper, we extended IOTA to investigate the coupling between subsystems for long time series, which is called segmented IOTA (SIOTA). Both global and local degree of couplings can be detected by varying the segment length. SIOTA is then applied to investigate interactions between stock market indices of America and different countries, and obtain many interesting results. Compared to SIOTA, cross-sample entropy is introduced to obtain consistent results. Besides, time-delay SIOTA, modified from SIOTA, is employed to find the best delay time for two time series with missing values." .
<http://www.springernature.com/scigraph/things/articles/7f0fff4e6e10e1f529d37242c75ceb98> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We propose quantile regression (QR) in the Bayesian framework for a class of nonlinear mixed effects models with a known, parametric model form for longitudinal data. Estimation of the regression quantiles is based on a likelihood-based approach using the asymmetric Laplace density. Posterior computations are carried out via Gibbs sampling and the adaptive rejection Metropolis algorithm. To assess the performance of the Bayesian QR estimator, we compare it with the mean regression estimator using real and simulated data. Results show that the Bayesian QR estimator provides a fuller examination of the shape of the conditional distribution of the response variable. Our approach is proposed for parametric nonlinear mixed effects models, and therefore may not be generalized to models without a given model form." .
<http://www.springernature.com/scigraph/things/articles/b333d868daaa673f0f395220d1f620fb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper develops a simple theoretical model of exchange rate determination in a transitional economy. The distinguishing feature of the model is the retention of market failures pertaining to the production and consumption of nontradable goods and, therefore, the likelihood of real exchange rate appreciation. Using this framework, the econometric tests are performed for the Czech Republic, Slovenia, Poland, and Hungary, and appropriate macroeconomic and exchange rate policies are recommended to support further liberalization and development of the foreign exchange market." .
<http://www.springernature.com/scigraph/things/articles/b2945f00679210087ef01f29ea8761e5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The Bank of Canada may be one of the most important determinants of health within the reach of government policy. Throughout its last three governorships, the Bank has pursued a staunchly anti-inflationary policy. Near zero percent inflation has helped to maintain unemployment levels above all but one of Canada's partners in the Group of Seven nations. Although debate continues, the bulk of the published literature supports a strong relationship between unemployment and ill health. Unfortunately, recent Governors have promulgated a mandate for the Bank that ignores its original mandate in the Bank of Canada Act, its influence on unemployment, and the human cost of sickness and premature death associated with unemployment. Federal monetary policy must take into account this human cost. Otherwise the myopic focus on a healthy economy in the short-run will compromise the goal of a healthy country in the long-run." .
<http://www.springernature.com/scigraph/things/articles/b90409cd180bf9a6093287d07edacada> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary A convenient method for the rapid, accurate and simultaneous estimation of lead and sulphur (after oxidising to sulphate level) in the same solution has been proposed. The results obtained are in good agreement with those obtained by classical procedures. The method is useful particularly in the analysis of galena." .
<http://www.springernature.com/scigraph/things/articles/049600968728ac0ed9eebc1bcefd45e4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. Using the CRSP (Center for Research in Security Prices) daily stock return data, we revisit the question of whether or not actual stock market prices exhibit long-range dependence. Our study is based on an empirical investigation reported in Teverovsky, Taqqu and Willinger [33] of the modified rescaled adjusted range or R/S statistic that was proposed by Lo [17] as a test for long-range dependence with good robustness properties under “extra” short-range dependence. Our main conclusion is that because the modified R/S statistic shows a strong preference for accepting the null hypothesis of no long-range dependence, irrespective of whether long-range dependence is present in the data or not, Lo's acceptance of the hypothesis for the CRSP data (i.e., no long-range dependence in stock market prices) is less conclusive than is usually regarded in the econometrics literature. In fact, upon further analysis of the data, we find empirical evidence of long-range dependence in stock price returns, but because the corresponding degree of long-range dependence (measured via the Hurst parameter H) is typically very low (i.e., H-values around 0.60), the evidence is not absolutely conclusive." .
<http://www.springernature.com/scigraph/things/articles/15b65409eff25933087eb258499d145b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Because of many uncertainties, quantitative estimates of agriculturally related economic impacts of greenhouse gas emissions are often given low confidence. A major source of uncertainty is our inability to accurately project future changes in economic activity, emissions, and climate. This paper focuses on two issues. First, to what extent do variable projections of climate generate uncertainty in agriculturally related economic impacts? Second, to what extent do agriculturally related economic impacts of greenhouse gas emissions depend on economic conditions at the time of impacts? Results indicate that uncertainty due to variable projections of climate is fairly large for most of the economic effects evaluated in this analysis. Results also indicate that economic conditions at the time of impact influence the direction and size of as well as the confidence in the economic effects of identical projections of greenhouse gas impacts. The economic variable that behaves most consistently in this analysis is world crop production. Increases in mean global temperature, for example, cause world crop production to decrease on average under both 1990 and improved economic conditions and in both instances the confidence with respect to variable projections of climate is medium (e.g.,67%) or greater. In addition and as expected, CO2 fertilization causesworld crop production to increase on average under 1990 and improved economic conditions. These results suggest that crop production may be a fairly robust indicator of the potential impacts of greenhouse gas emissions.A somewhat unexpected finding is that improved economic conditions are not necessarily a panacea to potential greenhouse-gas-induced damages, particularly at the region level. In fact, in some regions, impacts of climate change or CO2 fertilization that are beneficial undercurrent economic conditions may be detrimental under improved economic conditions (relative to the new economic base). Australia plus New Zealand suffer from this effect in this analysis because under improved economic conditions they are assumed to obtain a relatively large share of income from agricultural exports. When the climate-change and CO2-fertilization scenariosin this analysis are also included, agricultural exports from Australia plus New Zealand decline on average. The resultant declines in agricultural income in Australia plus New Zealand are too large to be completely offset by rising incomes in other sectors. This indicates that regions that rely on agricultural exports for relatively large shares of their income may be vulnerable not only to direct climate-induced agricultural damages, but also to positive impacts induced by greenhouse gas emissions elsewhere." .
<http://www.springernature.com/scigraph/things/articles/41828c7cae4a0b659ebcc5ddb4efd73e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary A description is given of the aims, design, and policy requirements of the EMS, and of the sort of exchange rate instability it is supposed to end. Changes in market exchange rates are attributed to differential inflation rates between countries and real exchange rate movements. Stable exchange rates can be obtained only if monetary policy is, managed so as to produce international differences in inflation rates that exactly compensate for movements in real exchange rates. Past monetary policies were seriously inconsistent with this requirement. And as yet nothing indicates that they will improve in the future. Moreover, real exchange rate changes are neither well-understood nor well-predictable. As a result, the prospects for the EMS to create monetary stability are dim. It will produce neither price nor exchange rate stability. A better alternative is proposed. Countries should combine flexible exchange rates with low, stable, and equalized inflation rates across the EC and dismatle capital and exchange controls." .
<http://www.springernature.com/scigraph/things/articles/ede96d849049d9f887386ca39f2617ea> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Devaluations and fiscal retrenchments coming from developed countries are buffeting less developed countries. Many emerging market countries have adopted inflation targeting as “best practice,” but now they are being advised to enhance their inflation targeting regimes with foreign exchange intervention. Here we use a DSGE model to tell some cautionary tales about this advice. A Taylor rule guides interest rate setting, while foreign exchange interventions are used as a second tool of monetary policy. These interventions are effective in our model since domestic and key currency bonds are imperfect substitutes. We derive optimal (Ramsey) intervention policies in response to foreign devaluations and fiscal retrenchments, and find that they are rather complex. So, we compare the optimal responses to policies that simply smooth real or nominal exchange rate movements. Our results suggest that discretion may be the better part of valor: pure inflation targeting may come closer to the optimal policy than exchange rate smoothing. A secondary result may also be of some interest: foreign exchange interventions have a stronger impact on inflation and output in an inflation targeting regime than do sterilized interventions; the Taylor rule augments the effects of a given intervention." .
<http://www.springernature.com/scigraph/things/articles/82b33ea3577e9607e7c7748275324242> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study provides evidence on market implied future earnings based on the residual income valuation (RIV) framework and compares these earnings with analyst earnings forecasts for accuracy (absolute forecast error) and bias (signed forecast error). Prior research shows that current stock price reflects future earnings and that analyst forecasts are biased. Thus, how price-based imputed forecasts compare with analyst forecasts is interesting. Using different cost of capital estimates, we use the price-earnings relation and impute firms’ future annual earnings from three residual income (RI) models for up to 5 years. Relative to I/B/E/S analyst forecasts, imputed forecasts from the RI models are less or no more biased when cost of capital is low (equal to a risk-free rate or slightly higher). Analysts slightly outperform these RI models in terms of accuracy for immediate future (1 or 2) years in the forecast horizon but the opposite is true for more distant future years when cost of capital is low. A regression analysis shows that, in explaining future earnings changes, analyst forecasts relative to imputed forecasts do not impound a significant amount of earnings information embedded in current price. In additional tests, we impute future long-term earnings growth rates and find that they are more accurate and less biased than I/B/E/S analyst long-term earnings growth forecasts. Together, the results suggest that the RIV framework can be used to impute a firm’s future earnings that are high in accuracy and low in bias, especially for distant future years." .
<http://www.springernature.com/scigraph/things/articles/f612377efe9f00621f101886e1f4047f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The welfare impact of price controls is examined here in an exchange economy where agents may need to queue in order to make a transaction. Time spent in the queue is an endogenously-determined transaction cost, which agents take as given and which adjusts so as to clear markets when prices are prevented from performing this function. When queuing is required, it enters the household’s decision as a fixed cost, rather than increasing in proportion to the amount of good exchanged, as is far more common in the previous literature. Existence of competitive equilibrium is established for this general equilibrium model. Price controls are shown to cause notable inefficiencies, which differ from those of a proportional cost model. Moreover, in certain environments, price controls will unambiguously harm all individuals relative to a Walrasian equilibrium." .
<http://www.springernature.com/scigraph/things/articles/3a044fbcccddece109000e1c15ee946d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Estimates of animal performance often use the maximum of a small number of laboratory trials, a method which has several statistical disadvantages. Sample maxima always underestimate the true maximum performance, and the degree of the bias depends on sample size. Here, we suggest an alternative approach that involves estimating a specific performance quantile (e.g., the 0.90 quantile). We use the information on within-individual variation in performance to obtain a sampling distribution for the residual performance measures; we use this distribution to estimate a desired performance quantile for each individual. We illustrate our approach using simulations and with data on sprint speed in lizards. The quantile method has several advantages over the sample maximum: it reduces or eliminates bias, it uses all of the data from each individual, and its accuracy is independent of sample size. Additionally, we address the estimation of correlations between two different performance measures, such as sample maxima, quantiles, or means. In particular, because of sampling variability, we propose that the correlation of sample means does a better job estimating the correlation of population maxima than the estimator which is the correlation of sample maxima." .
<http://www.springernature.com/scigraph/things/articles/c3f9f7f7e8ce9b045bccad18f9333094> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper considers externalities and investigates which general properties and respectively their magnitudes induce complex behavior like thresholds and indeterminacy (and cycles). The objective is to obtain general mechanisms within a general setting in order to complement the much advanced but model specific literature. It turns out that these arithmetic and simultaneously economic conditions for thresholds or indeterminacy require complementarity and non-moderate dynamic social influence. In other words, complexities can be related (necessary and sufficient) to a familiar static property that social interactions turn the (stationary) demand for the private stock into a Giffen good. Indeterminacy requires in addition ‘low’ subjective discounting and proper interactions between control, stock and externality. These conditions provide an easy way to construct models that allow for the targeted outcome, stability, thresholds or indeterminacy." .
<http://www.springernature.com/scigraph/things/articles/669f2d880be49f6e2cac06aeefd9de1f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper deals with estimation of a production technology where endogeneous choice of input and output variables is explicitly recognized. In particular, we assume that producers maximize return to the outlay (RO). For simplicity and tractability we start with a Cobb–Douglas transformation function with multiple inputs and outputs and show how the first-order conditions of RO maximization can be used to derive an estimating equation which is nothing but a partial input productivity equation. This equation does not suffer from the econometric endogeneity problem although the output and input variables are endogenous. First, we consider the case where producers are fully efficient allocatively but technically inefficient. The model is estimated using a single equation stochastic frontier approach. The model is then extended to allow allocative inefficiency and it is estimated as a system using generalized method of moment. Algebraic expressions are derived to decompose the effect of technical and allocative inefficiencies on RO. We also consider translog specifications that are estimated as (1) a single equation frontier model as well as (2) a system. We use a panel of Norwegian fishing trawlers data to estimate the model. Outputs are different species caught while inputs are labor and vessel size. We also control for number of days of operation, age of the vessel and year effects. Empirical results show that the average rate of RO is reduced by about 20 to 30 % due to technical inefficiency. On the other hand, average allocative efficiency is found to be about 78 %. The average overall efficiency is found to be around 60 %." .
<http://www.springernature.com/scigraph/things/articles/736f0202cd0c60e57fc3ec8c585ac1ed> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract.  The non-linear instantaneous transformation is a method to model and forecast non-Gaussian time series. A restriction of this method is that the marginal distribution of data must be known, or a general distribution form has to be determined. A difficulty of this method is that in practice the distribution of observed data is usually unknown, and it needs to be determined by fitting the data. In this study, a distribution-free plotting position formula is applied to the non-linear instantaneous transformation method. Synthetic time series and observed data are used to illustrate the proposed method, which does not require fitting the marginal distribution of the data to be forecasted." .
<http://www.springernature.com/scigraph/things/articles/799ba17858d7832917ce171ab9e940b5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The existing papers on the economic impact of research output have focussed on either a single country or bloc of selected countries. The aim of this paper is to examine the effect of research output on economic growth in 169 countries for the period, 1996–2013. A system GMM estimate, which provides for endogeneity, unobserved effects and small sample bias, is employed to test the relationship. Within the neoclassical framework, we use varieties of indicators to proxy research performance, and a few sensitivity analyses were also performed. Overall, the results show that research output has positive impact on economic growth, irrespective of whether the sample is for developing or developed countries. The policy implications of the findings are detailed in the body of the paper." .
<http://www.springernature.com/scigraph/things/articles/b471489f5119bdd42ed1549bd8fca9af> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper evaluates the efficiency of water and sewerage companies (WaSCs) by applying the weighted Russell directional distance model. This is a non-radial data envelopment analysis (DEA) model that allowed us to obtain an individual efficiency score for each input and output considered in the assessment. This study provides a pioneering approach to evaluating the efficiency of WaSCs, since previous studies on this topic were based on radial DEA models that only provide a global efficiency score. Moreover, three variables representing the lack of service quality were introduced into the model as undesirable outputs. An empirical application was carried out for the 25 largest Chilean WaSCs for 2013. The results illustrated that around one-third of the WaSCs in Chile are totally efficient. The inefficiency scores for each variable evidenced that one of the main challenges of the water industry in Chile is to reduce the percentage of unbilled water and that this issue is especially marked for medium WaSCs. As part of the second-stage analysis, some differences in performance between private and concessionary WaSCs were found, although the results were inconclusive. Several policy implications to help water companies’ managers and water regulators make informed decisions were drawn from our empirical analysis." .
<http://www.springernature.com/scigraph/things/articles/9c63a94ac233d8ad8ef8349463641732> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Although credit risk is an important factor that financial institutions must cope with, the determinants of bank problem loans have been little studied. Using panel data, we compare the determinants of problem loans of Spanish commercial and savings banks in the period 1985–1997, taking into account both macroeconomic and individual bank level variables. The GDP growth rate, firms, and family indebtedness, rapid past credit or branch expansion, inefficiency, portfolio composition, size, net interest margin, capital ratio, and market power are variables that explain credit risk. However, there are significant differences between commercial and savings banks, which confirm the relevance of the institutional form in the management of credit risk. Our findings raise important bank supervisory policy issues: the use of bank level variables as early warning indicators, the advantages of bank mergers from different regions, and the role of banking competition and ownership in determining credit risk." .
<http://www.springernature.com/scigraph/things/articles/9ef651cc18c0e9aedf3b1aa8507cd4b6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The aim of the paper is to model small scale neighbourhood in a house price model by implementing the newest methodology in spatial econometrics. A common problem when modelling house prices is that in practice it is seldom possible to obtain all the desired variables. Especially variables capturing the small scale neighbourhood conditions are hard to find. If there are important explanatory variables missing from the model, the omitted variables are spatially autocorrelated and they are correlated with the explanatory variables included in the model, it can be shown that a spatial Durbin model is motivated. In the empirical application on new house price data from Helsinki in Finland, we find the motivation for a spatial Durbin model, we estimate the model and interpret the estimates for the summary measures of impacts. By the analysis we show that the model structure makes it possible to model and find small scale neighbourhood effects, when we know that they exist, but we are lacking proper variables to measure them." .
<http://www.springernature.com/scigraph/things/articles/8f6974b6a52b23a6e43c729a6f20cd9c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We examine long-run PPP between Germany, Great Britain, Japan and the United States over the period 1930–1996 using multivariate cointegration techniques. Bilateral PPP between the four countries is examined in one system (as opposed to e.g. series of trivariate systems). In all of the statistical analysis, asymptotic tests are augmented by parametric bootstrap analogues, whereby we reduce, if not eliminate, the size distortion typically present in small-sample studies. The cointegration analysis provides support for the necessary conditions for PPP (i.e. cointegrating relations are found) but not for the sufficient conditions (i.e., the coefficients in the cointegrating relations are far from what PPP predicts). These results are at odds with results from other studies that also analyze long-horizon data sets." .
<http://www.springernature.com/scigraph/things/articles/cdc6c66568ff69aaf79a7f14df47eb08> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The impact of exchange-rate changes on industrial prices seems ambiguous. Incomplete and even “perverse” pass-through has been observed: the import prices in the depreciating country decrease while those in the appreciating country increase. To explain these “counterintuitive” price reactions we consider a situation of international Bertrand competition: two firms, based in different countries, are selling in both countries simultaneously. The profit-maximizing duopolists set the prices for their products in each of the two markets which are segmented on the demand side. We then study the qualitative effect of an exogenous exchange-rate change on the Bertrand-Nash equilibrium. Under the strong assumption of linear demand and cost functions we have “normal” exchange-rate pass-through. However, allowing for more general cost structures in this simple static model enables us to show that the import prices in both countries might move in counterintuitive directions." .
<http://www.springernature.com/scigraph/things/articles/439af69afef127881348ded91d9a0df5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Conclusions A major result following from the analysis of ourstructural model of inflation under flexible exchange rates is that there is no such thing asstructural inflation in the long run. Long-run inflation rather becomes a purely monetary phenomenon if exchange rates are flexible and if on an international level functioning capital markets are postulated. While, in the light of the assumptions made in Part III, this finding is not nearly as paradoxical as it may appear at first sight, it can hardly be overemphasized considering the ongoing theoretical discussion and the empirical research on the Scandinavian approach to inflation and recalling that the Scandinavian model is basically intended to picture equilibrium dynamics. The results concerning equilibrium price and exchange rate dynamics also apply to the equilibriumlevels of prices and the exchange rate, i. e., the equilibrium price level depends exclusively on monetary factors while the equilibrium exchange rate is determined by a purchasing power parity element and the structural productivity gap component. Turning to the results of our analysis of disequilibrium dynamics, the overall picture does not change very much. Here the qualitative pattern of adjustment of both prices and the exchange rate is again completely independent of structural variables, but is exclusively determined by four adjustment coefficients. However, the particular quantitative values assumed by prices and the exchange rate during the adjustment process do indeed reflect the impact of the productivity gap. No conclusions can be derived from our model on the amount of time it takes to return to the neighbourhood of equilibrium once the economy has been subjected to some kind of external shock. A casual examination of post-1973 developments and especially the Swiss experience suggest, however, that in the case of a disturbance as, e. g., in the form of a monetary contraction (relative to the rest of the world), the economy may take so long to return to the neighbourhood of long-run equilibrium that the negative real consequences of the overvaluation of the domestic currency during the adjustment process provide a momentous rationale for short-run stabilization interventions in the foreign exchange market." .
<http://www.springernature.com/scigraph/things/articles/6a4c6c15fbf4eece9d3d0bad9efac2db> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We study the empirical effects of fiscal policy in Denmark since the adoption of a fixed exchange rate policy in 1982. Denmark’s fixed exchange rate implies that the nominal interest rate remains fixed after a fiscal expansion, facilitating a substantial impact of the fiscal stimulus on the real economy. On the other hand, the large degree of openness of the Danish economy means that a sizeable share of the fiscal stimulus will be directed towards imported goods. Our results suggest that the ‘monetary accomodation channel’ dominates the ‘leakage effect’ in the short run. We demonstrate that fiscal stimulus has a rather large impact on economic activity in the very short run, with a government spending multiplier of 1.1 on impact in our preferred specification. We also find that the effects of fiscal stimulus are rather short-lived in Denmark, with the effect on output becoming insignificant after around two years. The fiscal multiplier is above 1 only in the first quarter, and drops to 0.6 one year after the shock. We also find that in the short run, the government spending multiplier is larger than the tax multiplier. Finally, we demonstrate that exogenous shocks to government spending account for less than 10 % of the movements in output over the business cycle in Denmark." .
<http://www.springernature.com/scigraph/things/articles/c8d8c564332439d869883dc98fac7bad> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article presents a proposal to broaden the right to acquire capital with the earnings of capital as a means of promoting sustainable economic recovery and growth. It would open the markets for real and financial capital acquisition more fully and competitively to poor and working people (1) to distribute more broadly the earnings of capital and (2) to profitably employ more capital and labor. Both the recession and the strategies advanced to promote economic recovery may be viewed as responses to the prospect of inadequate present and future earning capacity of both consumers and producers (1) to purchase what can physically be produced and (2) to repay existent and anticipated debt obligations. To increase the prospects of sufficient, sustainable earning capacity, the proposal advanced in this article would extend to all people the same protections and benefits presently provided by government that facilitate market transactions whereby capital is acquired with the earnings of capital primarily for well-capitalized people. Although in theory, all people in a market economy are able to acquire capital with the earnings of capital, reliable empirical data reveal that as a practical matter, the major determinant of the ability of individuals to acquire capital with the earnings of capital is the existing distribution of capital ownership. The theory of “binary” economic growth underlying this proposal holds that the market return on capital is positively related to the distribution of capital acquisition with the earnings of capital. The prospect of a broader distribution of capital acquisition with the earnings of capital carries with it the prospect of more broadly distributed earning capacity in future years, which in turn will provide the market incentives to profitably employ more capital and labor in earlier years. The idea that the broader distribution of capital acquisition with the earnings of capital will promote growth is not found in any of the widely accepted theories and models of economic growth such as those proposed by Schumpeter, Solow, Roemer, and Lucas. By opening to all people the institutions of corporate finance, banking, insurance, government loans and guaranties, and monetary policy (the very institutions presently relied upon by the Federal Government to stimulate the economy) the practical ability to acquire capital with the earnings of capital can be more broadly extended to all people with the result that greatly enhanced prospects for greater and more broadly distributed earning capacity and growth can be reasonably expected and realized by all." .
<http://www.springernature.com/scigraph/things/articles/a4f4d7d6f09eae0eeccf8fb368f092e0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper is intended as a ‘hands-on’ practical discussion of how and why neural networks are used in forecasting and business modelling. The need for forecasting is briefly examined. The theory of the multilayer perceptron neural network is then covered both qualitatively and in mathematical detail, including the methods of back-propagation of error and independent validation. The advantages of the neural net approach to forecasting, namely nonlinear modelling capability, plausible interpolations and extrapolations, robustness to noise, ill-conditioning and insufficient data, and ease of use, are discussed. Finally, some working notes are offered for the practical implementation of neural nets in forecasting, and four real-life examples are given from the pursuits of econometrics, sales forecasting, market modelling, and risk evaluation." .
<http://www.springernature.com/scigraph/things/articles/6dde8db09d58392a95ed080678177a4c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The substitutability of private and public savings has implications for the effectiveness of fiscal policy. Using annual data for the period 1970–2004, this study re-examines long-run relationships between OECD private and public savings rates. However, unlike previous work, panel data unit root and cointegration tests are employed. The results confirm substitutability where strong Ricardian Equivalence is rejected for the entire OECD panel. There is support for weak Ricardian Equivalence with less than perfect substitutability. Indeed, it is argued that existing studies most likely overstate the extent of long-run substitutability particularly with regard to EU countries." .
<http://www.springernature.com/scigraph/things/articles/33ad609bc9823daaed5684543372bdc9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper we investigated the use of attrition weights to cope with non-response when selecting graphical chain models for longitudinal data. We proposed a parametric bootstrap approach to account for the extra variability introduced by the estimation of the weights and compared this with results using standard test procedures." .
<http://www.springernature.com/scigraph/things/articles/44e34f73eb2780a1ab2da5bbf091ccd2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We investigate the behavior of the empirical minimization algorithm using various methods. We first analyze it by comparing the empirical, random, structure and the original one on the class, either in an additive sense, via the uniform law of large numbers, or in a multiplicative sense, using isomorphic coordinate projections. We then show that a direct analysis of the empirical minimization algorithm yields a significantly better bound, and that the estimates we obtain are essentially sharp. The method of proof we use is based on Talagrand's concentration inequality for empirical processes." .
<http://www.springernature.com/scigraph/things/articles/c50d8d9051cd10a117349f4a8ea29f6c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We present a method based on integro-differential equations describing the13C−1H dipolar dephasing behaviour of carbon magnetization which results from monoprotonated carbons, non-protonated carbons as well as rapidly rotating methyl groups. Good agreement with theoretical calculations and experiment is obtained in ammonium tartrate and durene. The frequently applied empirical methods for determination the ratio of protonated and non-protonated carbons are analyzed. The dipolar dephasing time constants of non-protonated carbons vary substantially as a result, of variation in their heteronuclear second moments and thus in structure. Two different methods are performed for determination heteronuclear second moments from dipolar dephasing data." .
<http://www.springernature.com/scigraph/things/articles/e0e438c54d62bc82433062a3b1776fef> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This Tinbergen Lecture begins by reviewing empirical evidence about trends in income inequality in a number of Western countries. There is considerable diversity of experience across countries. The first quarter century after the Second World War was not generally characterised by a steady downward trend in inequality, but by episodes of inequality reduction at different dates. More recently, several OECD countries have seen a rise in inequality, but the rates of increase differed and in around half of the countries shown there was no significant upward trend over the 1980s. The differing experiences, and the episodic nature of changes, have implications for the explanations of inequality considered in Sections 2 and 3 of the Lecture. I begin with the mechanism which Tinbergen described in Chapter 6 of hisIncome Distribution: the race between technological development and education. It is argued that behind the supply and demand model there lie a variety of factors, and that the explanation we give may be important in determining whether what we are observing are wagedifferentials or wageinequality. Moreover, we need to consider non-labour income, and Section 3 examines the determination of state transfers and of capital income. Finally, in Section 4, I consider some of the policy implications, focusing on one particular set of policy proposals in which Jan Tinbergen was interested: the idea of a basic income." .
<http://www.springernature.com/scigraph/things/articles/b60d9e19ffdecd1cd22c2070b3e721d3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A general nonparametric approach to identify similarities in a set of simultaneously observed time series is proposed. The trends are estimated via local polynomial regression and classified according to standard clustering procedures. The equality of the trends is checked using several nonparametric test statistics whose asymptotic distributions are approximated by a bootstrap procedure. Once the estimated trends are removed from the model, the residual series are grouped by means of a nonparametric cluster method specifically designed for time series. Such a method is based on a disparity measure between local linear smoothers of the spectra of the series. The performance of the proposed methodology is illustrated by means of its application to a particular financial data example. The dependence of the observations is a crucial factor in this work and is taken into account throughout the study." .
<http://www.springernature.com/scigraph/things/articles/25b31d6af2a3feb5e888d0435308594c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Our study examines the long-term relationship among per capita gross domestic product (GDP), per capita health expenditures and population growth rate in Turkey during the period 1984–2006, employing the Johansen multivariate cointegration technique. Related previous studies on OECD countries have mostly excluded Turkey—itself an OECD country. The only study on Turkey examines the period 1984–1998. However, after 1998, major events and policy changes that had a substantial impact on income and health expenditures took place in Turkey, including a series of reforms to restructure the health and social security system. In contrast to earlier findings in the literature, we find that the income elasticity of total health expenditures is less than one, which indicates that health care is a necessity in Turkey during the period of analysis. According to our results, a 10% increase in per capita GDP is associated with an 8.7% increase in total per capita health expenditures, controlling for population growth. We find that the income elasticity of public health expenditures is less than one. But, in the case of private health care expenditures, the elasticity is greater than one, meaning that private health care is a luxury good in Turkey." .
<http://www.springernature.com/scigraph/things/articles/260794045cf27b434754d84f34696614> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Market shares for organic products remain modest despite broad professed consumer interest in purchasing organic products. We use counterfactual product introductions in an estimated demand model to systematically explore the links between product assortment and the market share for organic products. The demand estimates on which we base the counterfactuals use 3 years of household panel data on retail coffee purchases in Sweden, combining household’s stated and revealed behavior in a discrete choice model. The predicted market shares of new organic products are highly dependent on which brand that the organic label partners with. Introduction of a new organic product is predicted to increase in-sample organic market share from around 5% up to a maximum of around 8%. The market expansion effect dominates the market stealing effect for almost all entrants. The largest market share gains for organic products are not to be had amongst the keenest organic households, but rather amongst the moderately keen organic households." .
<http://www.springernature.com/scigraph/things/articles/71de3cabd48a3c8c5dbf0e4607d51e8b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract There is growing interest both in the field of neural computing and in the financial world in the possibility of using neural networks to forecast the future changes in prices of stocks, exchange rates, commodities and other financial time series. Since networks have been shown to be capable of modelling the underlying structure of a time series, many attempts have been made at exploiting that capability in order to carry out a technical analysis of such prices. If the efficient markets hypothesis is true, however, there is no underlying structure to be modelled, and the whole endeavour is doomed to failure. This paper investigates the common methods for such an approach, and outlines the major pitfalls and common errors to avoid. The author hopes that by pointing out the possible pitfalls now, we can avoid making claims to the commercial world before we are properly ready to do so." .
<http://www.springernature.com/scigraph/things/articles/1c95f2b06ff1c19bf5dc2959dab63c06> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In order to test the validity of the global wavelet spectrum — a new period analysis method based on wavelet analysis, we carried out some simple experiments. In our experiments we used idealized time series and real Nino 3 sea surface temperature (SST) for testing purposes. First we combined different signals which have the same power but different periods into some new time series. Then we calculated the global wavelet spectra and Fourier power spectra for the testing time series. The testing results revealed that on some occasions the global wavelet spectrum tends to amplify the relative power of longer periods. By making comparisons with the results obtained by the traditional Fourier power spectrum, we demonstrated that on an occasion when the global wavelet spectrum does not work the Fourier power spectrum can be used to achieve the right results. Hence it is recommended that when making period analysis with the global wavelet spectrum one needs to do further tests to confirm their results." .
<http://www.springernature.com/scigraph/things/articles/a9fc20b6aeeedc3d330d9f25221d29bd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A two-sector general equilibrium model with imperfectly competitive labor markets is set up. Noncooperative equilibria with wage setting at the sectoral level are shown to depend on the choice of price-normalization rule even though all agents behave fully rationally. Hence, imposing rationality is not sufficient to deprive the choice of price-normalization rule of its importance. It is argued that the importance of the choice of price-normalization rule may follow from the strategic interaction of agents and not from imperfectness of competition per se, and some examples are provided." .
<http://www.springernature.com/scigraph/things/articles/444347488d7d69ad62a4b502373dcc5d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The amplitude of a solar-activity cycle is found to be well correlated (r = −0.811) with the descending time three cycles earlier, in smoothed monthly-mean sunspot numbers for Cycles 8 – 23. The descending time therefore can be used as one of the indicators to predict the amplitudes. As a result, the amplitudes of Cycles 24 – 25 are estimated to be 114.8 ± 17.4, 111.6 ± 17.4, respectively, where the error bar equals ± standard error." .
<http://www.springernature.com/scigraph/things/articles/ab5ed7f84ec2095302ffe921c3b07124> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article uses longitudinal data from the Panel Study of Income Dynamics to explore how changes in marital status affect the economic status of married women in their middle years. Results demonstrate that when a marriage ends, the economic status of women declines considerably. Components of income change are discussed, with emphasis on the extent to which women can compensate for the loss of a spouse's income through increases in paid labor, by changes in living arrangements, and by the use of public and private transfers." .
<http://www.springernature.com/scigraph/things/articles/7c26df5afcf2f945efac3ab47d13c8e5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Covariance structure modeling plays a key role in the spatial data analysis. Various parametric models have been developed to accommodate the idiosyncratic features of a given dataset. However, the parametric models may impose unjustified restrictions to the covariance structure and the procedure of choosing a specific model is often ad hoc. To avoid the choice of parametric forms, we propose a nonparametric covariance estimator for the spatial data, as well as its extension to the spatio-temporal data based on the class of space-time covariance models developed by Gneiting (J. Am. Stat. Assoc. 97:590–600, 2002). Our estimator is obtained via a nonparametric approximation of completely monotone functions. It is easy to implement and our simulation shows it outperforms the parametric models when there is no clear information on model specification. Two real datasets are analyzed to illustrate our approach and provide further comparison between the nonparametric estimator and parametric models." .
<http://www.springernature.com/scigraph/things/articles/5c67c86c7c6b5e5f8a01dc907f6faa6c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Numerous studies have shown the potential for US manufacturing to cut its energy costs by installing more efficient equipment that offers competitive payback periods, but the realization of this potential is hindered by numerous obstacles. This paper evaluates seven federal policy options aimed at revitalizing US manufacturing by improving its energy economics while also achieving environmental and energy reliability goals. Traditionally, policy analysts have examined the cost-effectiveness of energy policies using deterministic assumptions. When risk factors are introduced, they are typically examined using sensitivity analysis to focus on alternative assumptions about budgets, policy design, energy prices, and other such variables. In this paper, we also explicitly model the stochastic nature of several key risk factors including future energy prices, damages from climate change, and the cost of criteria pollutants. Using these two approaches, each policy is \"stress tested\" to evaluate the likely range of private and social returns on investment. Overall, we conclude that the societal cost-effectiveness of policies is generally more sensitive to alternative assumptions about damages from criteria pollutants and climate change compared with energy prices; however, risks also vary across policies based partly on the technologies they target. Future research needs to examine the macroeconomic consequences of the choice between a lethargic approach to energy waste and modernization in manufacturing versus a vigorous commitment to industrial energy productivity and innovation as characterized by the suite of policies described in this paper." .
<http://www.springernature.com/scigraph/things/articles/78be50e24915cdab58a4693d09b75afb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We estimate tobacco demand in Italy following the rational addiction framework. Two empirical tests are performed. The first uses a pseudo panel of data and follows the approach of Baltagi and Griffin. We obtain evidence of forward-looking behavior but implausible estimates of the discount rate. The second uses a time series of per capita tobacco expenditures. In this case the data support the theory. A simulation is also carried out to assess the effects of future permanent price changes on tobacco demand. The novelty here is that expected future consumption is estimated by ordinary least squares using past and future prices as regressors instead of taking actual consumption as is usually the case in empirical tests of the rational addiction model. Results show that announcements of future price changes may be effective in curbing tobacco demand." .
<http://www.springernature.com/scigraph/things/articles/16de1d22573f7dec8e0cc47b65f90eea> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract With this study, we analyzed two long-term precipitation time series recorded at Alpe Devero and Domodossola (Italian Western Alps) for two periods (1916–2010 and 1872–2010, respectively). The aims of the study were: to create the first precipitation time series covering more than 50 years for Alpe Devero, to extend and update the precipitation time series for Domodossola, to detect changes by means of trend analysis on the precipitation time series. After an accurate analysis of the metadata and the measurements recorded at each station, a trend analysis was performed on both datasets. The results showed a statistically significant decline in winter, summer, and annual precipitation at Alpe Devero and a nonsignificant decrease in seasonal and annual precipitation at Domodossola. Covering more than 90 years, the long-term precipitation time series at Alpe Devero and Domodossola represent unique data sets for this sector of Italian Western Alps. Continuing updating of the data could provide a useful resource for climate change studies in this area and, within a wider perspective, in Alpine regions." .
<http://www.springernature.com/scigraph/things/articles/e144a55b71742fed3c22e85f78809d03> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper presents a unified approach to local likelihood estimation for a broad class of nonparametric models, including e.g. the regression, density, Poisson and binary response model. The method extends the adaptive weights smoothing (AWS) procedure introduced in Polzehl and Spokoiny (2000) in context of image denoising. The main idea of the method is to describe a greatest possible local neighborhood of every design point X i in which the local parametric assumption is justified by the data. The method is especially powerful for model functions having large homogeneous regions and sharp discontinuities. The performance of the proposed procedure is illustrated by numerical examples for density estimation and classification. We also establish some remarkable theoretical nonasymptotic results on properties of the new algorithm. This includes the ``propagation'' property which particularly yields the root-n consistency of the resulting estimate in the homogeneous case. We also state an ``oracle'' result which implies rate optimality of the estimate under usual smoothness conditions and a ``separation'' result which explains the sensitivity of the method to structural changes." .
<http://www.springernature.com/scigraph/things/articles/6c2fe21c6de430240ab64b8d44ed47a1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. The absence of second class currents together with the assumption of the factorization for non-leptonic B decays provide new constraints on CP observables in the decay $B \\rightarrow a_0(980)(\\rightarrow \\eta\\pi)\\pi$. The kinematics of this decay does not allow for interference between the oppositely charged resonances in the Dalitz plot as in $B^0 \\rightarrow \\rho(770)\\pi $. Nonetheless, under the assumption of factorization, the $B \\rightarrow a_0\\pi$ two-body time-dependent isospin analysis leads to a more robust extraction of the angle $\\alpha$ than in the $B \\rightarrow \\rho\\pi$ isospin-pentagon analysis. The absence of second class currents might lead to enhanced direct CP violation and/or allows for a test of some assumptions made in the $\\alpha$ analysis in other decays like $B \\to a_0 \\rho, B \\rightarrow b_1(1235)\\pi, B\\to a_0 a_0$, $B\\to \\eta(\\eta')\\pi\\pi$ and $B\\to b_1 a_0$. The effects from non-factorizable contributions on the determination of $\\alpha$ are estimated by means of a numerical study." .
<http://www.springernature.com/scigraph/things/articles/2f6e054318485a0eae8722c717a04c16> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Monthly Federal Fund interest rate values, set by the Federal Open Market Committee, have been the subject of much speculation prior to the announcement of their new values each period. In this study we use four competing methodologies to model and forecast the behavior of these short term Federal Fund interest rates. These methodologies are: time series, Taylor, econometric and neural network. The time series forecasts use only past values of Federal Funds rates. The celebrated Taylor rule methodology theorizes that the Federal Fund rate values are influenced solely by deviations from a desired level of inflation and from potential output. The econometric and neural network models have inputs used by both the time series and Taylor rule. Using monthly data from 1958 to the end of 2005 we distinguish between sample and out-of-sample sets to train, evaluate, and compare the models’ effectiveness. Our results indicate that the econometric modeling performs better than the other approaches when the data are divided into two sets of pre-Greenspan and Greenspan periods. However, when the data sample is divided into three groups of low, medium and high Federal Funds, the neural network approach does best." .
<http://www.springernature.com/scigraph/things/articles/446149f2d142e6b8f5f28569bd866a07> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper addresses problem of predicting direction and magnitude of movement of currency pairs in the foreign exchange market. The study uses Support Vector Machine with a novel approach for input data and trading strategy. The input data contain technical indicators generated from currency price data (i.e., open, high, low and close prices) and representation of these technical indicators as trend deterministic signals. The input data are also dynamically adapted to each trading day with genetic algorithm. The study incorporates a currency strength-biased trading strategy which selects the best pair to trade from the available set of currencies and is an improvement over the previous work. The accuracy of the prediction models are tested across several different sets of technical indicators and currency pair sets, spanning 5 years of historical data from 2010 to 2015. The experimental results suggest that using trend deterministic technical indicator signals mixed with raw data improves overall performance and dynamically adapting the input data to each trading period results in increased profits. Results also show that using a strength-biased trading strategy among a set of currency pair increases the overall prediction accuracy and profits of the models." .
<http://www.springernature.com/scigraph/things/articles/eb8dae583d77eb7410f2176e1f033d9b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this era of VLSI circuits, testability is truly a very crucial issue. To generate a test set for a given circuit, choice of an algorithm from a number of existing test generation algorithms to apply is bound to vary from circuit to circuit. In this paper, the Genetic Algorithm is used in order to construct an accurate model for some existing test generation algorithms that are being used everywhere in the world. Some objective quantitative measures are used as an effective tool in making such choice. Such measures are so important to the analysis of algorithms that they become one of the subjects of this work." .
<http://www.springernature.com/scigraph/things/articles/dd54379973599dd4fc29fcf1a06bd669> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The paper examines the household asset dynamics in India as well as Indian rural States. The paper contributes to the empirical analysis of poverty trap by investigating the presence of one potential poverty trap to simultaneous poverty trap. The paper uses the India Human Development Survey for the year 1993 and 2005. We use the local polynomial regression with Epanechnikov kernel weights to test the existence of multiple or single equilibrium in asset poverty dynamics. Moreover, we use the partial linear mixed model to test the impact of illiteracy trap and under-nutrition trap on asset dynamics process. Across all the States we find only single dynamic asset equilibrium for rural households. However the nature of the asset dynamics varies from one state to another. We find that, in most of the States, asset accumulation does not take place and welfare dynamics is very poor in rural areas. Further, we find under-nutrition trap uniformly affect the asset accumulation in most of the States. However an illiteracy trap affects the asset level heterogeneously over the income and regional distribution. We find the most deprived States (Bihar, Uttar Pradesh, Orissa and Madhya Pradesh) have the multiple poverty trap compared to richer States. Our result implies that asset dynamics of the household varies in the long term according to the types of traps. Government and policy makers should take pointed policy and programme based on whether the poor are trapped and in what ways." .
<http://www.springernature.com/scigraph/things/articles/28b7e6dedcb27cbd722a9bb71cce55bf> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In statistical analysis, particularly in econometrics, it is usual to consider regression models where the dependent variable is censored (limited). In particular, a censoring scheme to the left of zero is considered here. In this article, an extension of the classical normal censored model is developed by considering independent disturbances with identical Student-t distribution. In the context of maximum likelihood estimation, an expression for the expected information matrix is provided, and an efficient EM-type algorithm for the estimation of the model parameters is developed. In order to know what type of variables affect the income of housewives, the results and methods are applied to a real data set. A brief review on the normal censored regression model or Tobit model is also presented." .
<http://www.springernature.com/scigraph/things/articles/ffba9cc000ac752ed2f22ff566f22a0b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary The use of beef serum as an essential ingredient in a medium for the cultivation of the Noguchi strain ofTreponema pallidum is described. A proportion of 8% v/v of beef serum can replace the addition of 10% of rabbit serum, under the condition that also basal medium itself is optimal for the cultivation of Noguchi strain. With beef serum employed in this manner, quantitatively the same growth as with rabbit serum has been obtained, with the only difference that maximum is reached somewhat later. Growth curves of Noguchi strain in a medium supplement with 8% of beef serum (medium “61BS8”) are presented and also the correlation of turbidimetric and numeric values between which a linear relationship has been established." .
<http://www.springernature.com/scigraph/things/articles/1de41dbc32044ff08f860bf35eba6a55> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Basic statistics of a nonstationary time series are estimated from its single realization. The estimates are represented in the form of a recurrent procedure forming residual time series and smoothing them with the help of effective models of digital data filtering or a locally weighted polynomial regression. The concept of local time weighting and robust weighting of residual series is generalized on the basis of a rational combination of models of distance-weighted least squares and an exponentially weighted regression. The estimation of trends, volatility, and autocorrelation for time series of companies’ sales volumes and the price dynamics of stock assets is simulated, and the results of simulation are presented." .
<http://www.springernature.com/scigraph/things/articles/7ed5baf731938644f937c17a455086f5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A beef strip loins (Musculus longissimus lumborum) freshness determination method utilizing electronic nose (e-nose) was investigated in this paper. Fresh beef strip loins samples were stored at 4°C continuously for 10 days. Total viable count (TVC) index, total volatile basic nitrogen (TVB-N) index, and e-nose responses to beef strip loins samples were measured every day. TVC and TVB-N index rose with the increase of storage time. Principal component analysis (PCA) only partially discriminated beef samples under different storage days. Stochastic resonance (SR) signal-to-noise ratio (SNR) spectrum discriminated all beef samples successfully. Beef strip loins freshness discrimination model was developed using SR SNR maximums (SNRmax) linear fitting regression. The proposed method forecasted beef freshness with high accuracy. It is holds promise in meat freshness determination applications." .
<http://www.springernature.com/scigraph/things/articles/b6821f869ec3e0656c28bdb2d56b2ef5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The quality of analytical results is expressed by their uncertainty, as it is estimated on the basis of an uncertainty budget; little effort is, however, often spent on ascertaining the quality of the uncertainty budget. The uncertainty budget is based on circumstantial or historical data, and therefore it is essential that the applicability of the overall uncertainty budget to actual measurement results be verified on the basis of current experimental data. This should be carried out by replicate analysis of samples taken in accordance with the definition of the measurand, but representing the full range of matrices and concentrations for which the budget is assumed to be valid. In this way the assumptions made in the uncertainty budget can be experimentally verified, both as regards sources of variability that are assumed negligible, and dominant uncertainty components. Agreement between observed and expected variability is tested by means of the T-test, which follows a chi-square distribution with a number of degrees of freedom determined by the number of replicates. Significant deviations between predicted and observed variability may be caused by a variety of effects, and examples will be presented; both underestimation and overestimation may occur, each leading to correcting the influence of uncertainty components according to their influence on the variability of experimental results. Some uncertainty components can be verified only with a very small number of degrees of freedom, because their influence requires samples taken at long intervals, e.g., the acquisition of a new calibrant. It is therefore recommended to include verification of the uncertainty budget in the continuous QA/QC monitoring; this will eventually lead to a test also for such rarely occurring effects." .
<http://www.springernature.com/scigraph/things/articles/4d1668f8ed060975dfdc93774736d6bd> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Central banks in emerging market economies often grapple with understanding the monetary policy response to an inter-sectoral terms of trade shock. To address this, we develop a three sector closed economy NK-DSGE model calibrated to India. Our framework can be generalized to other emerging markets and developing economies. The model is characterized by a manufacturing sector and an agricultural sector. The agricultural sector is disaggregated into a grain and vegetable sector. The government procures grain from the grain market and stores it. We show that the procurement of grain leads to higher inflation, a change in the sectoral terms of trade, and a positive output gap because of a change in the sectoral allocation of labor. We compare the transmission of a single period positive procurement shock with a single period negative productivity shock and discuss the implications of such shocks for monetary policy setting. Our paper contributes to a growing literature on monetary policy in India and other emerging market economies." .
<http://www.springernature.com/scigraph/things/articles/3cbde8490b43a205624864c7d7e2a561> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Based on intraday 5-min high-frequency dataset, this paper empirically analyzes the intraday dynamic relationships between China’s CSI 300 index futures and spot markets with vector autoregression (VAR) and multivariate GARCH (MGARCH) models. By comparing four VAR–MGARCH models (dynamic conditional correlation, constant conditional correlation, diagonal and BEKK), the VAR–DCC–MGARCH model is found to fit the data the best and be preferred over the other models. The results of this model show that although there are bidirectional price causal relationships between the CSI 300 index futures and spot markets, the index futures return shock affects the spot market more severely than the spot return shock affects the futures market, indicating that the index futures market dominates the price discovery process between the two markets. There are bidirectional volatility spillovers effects between the CSI 300 index futures and spot markets, and the spillovers effects from index futures to spot almost equal to that from index spot to futures. The time-varying conditional correlations between the CSI 300 index futures and spot markets change from 0.4787 to 0.9594 across time, showing there is a strong positive correlation and linkage effect between the two markets. These results indicate that after a period of time of development, the price discovery performance of the CSI 300 index futures market has begun to function well, and the impact of the CSI 300 index futures market on its underlying spot market has strengthened." .
<http://www.springernature.com/scigraph/things/articles/88464ee3e37a4a17e2be3f6219922bad> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We incorporate endogenous production into Sah's analysis of alternative schemes for distributing a deficit good. The model is interpreted as applying to a socialist economy suffering from repressed inflation. Sah's results are robust to this generalisation provided production is linear. Also, amending Sah's assumptions, we suppose all individuals own equal shares in the means of production. If production is linear, a low-wage worker (particularly defined) prefers goods to be sold at a free-market price to the alternatives of (equal) nonconvertible rationing or a queuing system. Without linearity, the results are less clear-cut." .
<http://www.springernature.com/scigraph/things/articles/74a800c6985f85c7cf9fa7ea8098b85d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we extend the standard model of private provision of public goods by including consumption externalities to characterize a situation in which economic activities pollute the environment. We consider a case in which there are an industrial country which can afford to invest in the environment and a developing country which cannot. Then, we show that international income transfers in both directions can improve the global environmental quality as well as the welfare of each country. We also show that the results have important implications for policies such as official development assistance or the assignment of tradable emission permits." .
<http://www.springernature.com/scigraph/things/articles/0124d2459d58e3a895ae85151bbe3653> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Economic theory suggests that an economy's openness to international trade reduces the ability of monetary policy to affect output. Using quarterly data from the 1960:1–1993:4 period for a set of eight countries (Australia, Canada, Germany, Italy, Japan, South Africa, the U.K., and the U.S.A.), this article's empirical results support this theoretical prediction: the more open the economy, the smaller the output effects of a given change in the money supply. This finding, robust across all the different specifications and estimation methods examined, has straightforward implications for stabilization policy. Moreover, it suggests that an economy's net benefit from joining a monetary union is increasing with the economy's openness to foreign trade." .
<http://www.springernature.com/scigraph/things/articles/832f5d928ae3abb9bed76ed6f465d8ad> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper studies the behaviour of Dutch banks. We test the adjustment of banks' balance sheets in times of monetary policy changes during the period 1957–1991. As a reaction to a policy change, banks basically have two alternatives to adjust their net money creation: (1) sell securities in public capital markets, and/or issue long-term liabilities, and (2) change domestic loan supply. If banks opt for the latter a lending channel may be relevant, even in a small open economy with a fixed exchange rate and a high degree of international capital mobility. We test for the effectiveness of both indirect and direct instruments of monetary policy. It turns out that in case of changes in the official interest rate, the volume of bank loans is not affected and that banks display a kind of buffer-stock behaviour by diminishing their publicly traded assets. In situations with quantity restrictions on the growth of net money creation, however, the volume of loans is affected significantly when the quantity restriction is withdrawn thereby fulfilling a necessary condition for the bank lending channel to be effective." .
<http://www.springernature.com/scigraph/things/articles/8f1c63fc605668c1810e97e3bd8e6ab2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper examines the optimal fiscal policies in an economy with externalities from government expenditure. We extend Lucas (Oxf Econ Pap 42:293–316, 1990) two-sector endogenous growth model and consider the spillover effects from the public spending on infrastructure and education. We compare the optimal fiscal policies derived from the Ramsey allocation problem with those in the centrally-planned economy. The results of this paper are as follows. First, the optimal share of public spending on infrastructure is smaller than its relative contribution in the production function. Next, the optimal share of public spending on education is smaller than its relative contribution in the accumulation of human capital, and does not affect the tax rate of capital income. Finally, the optimal tax rate of capital income is positive if the externality from public productive spending exists." .
<http://www.springernature.com/scigraph/things/articles/eb9278e68c60b0739ab6736bdd604f4e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The aim of the study was to monitor the system theoretic exogenous variables augmented state space algorithm of Aoki (State space modelling of time series. Springer, Heidelberg, 1987) and the VARMAX algorithm of Spliid (J Am Stat Assoc 78(384):843–849, 1983) within a geno-mathematical framework towards optimal parametric conditions/search intervals. Both algorithms were implemented as an integrated support library for a general computational platform, the Genetic Hybrid Algorithm (GHA), where some key parameters of the algorithms are defined in a search process utilizing a mixed geno-mathematical search technique. The empirical results of our tests using real economic data from the European stock market are encouraging. Specifically, the information criteria used in the VARMAX-search (Vector Autoregressive Moving Average algorithm with Exogenous variables) algorithm tend to favor parsimonious model representations automatically. Furthermore, the state space algorithm captures almost the same dynamics as the complex VARMAX-model estimated in the study. Both algorithms have encouraging in sample properties. When generating k-steps forecasts out-of-sample, k > 1, the state space algorithm seems to deteriorate faster than the VARMAX algorithm, however. The results suggest that more empirical testing is needed, especially in different situations with different degrees of model order and stationarity conditions, in order to provide more evidence on the suitability of the competing methods in particular cases. We demonstrated that the Genetic Hybrid Algorithm can be used as a generic platform for parametric search in vector valued time series modelling. Efficient procedures for optimal grouping of the individual time series processes and recognition of heteroskedasticity may improve the performance of the algorithms further." .
<http://www.springernature.com/scigraph/things/articles/73e16391af0c09d4b3fd8cc21b3e1dac> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper develops a structural, dynamic model of a banking firm to analyze how banks adjust their loan portfolios over time. In the model, banks experience capital shocks, face uncertain future loan demand, and incur costs based on their proximity to regulatory minimum capital requirements and the intensity of regulatory monitoring. Implications of the model then are estimated using panel data on large U.S. commercial banks operating continuously between December 1989 and December 1997. The estimated model is used to simulate the optimal bank response to (1) past and proposed changes in capital requirements, (2) changes in regulatory monitoring intensity, and (3) economic downturns. The simulation results are used to shed light on the decline in loan growth and the rise in bank capital ratios witnessed over a decade ago as well as the possible impact of the current proposed modification to capital requirements." .
<http://www.springernature.com/scigraph/things/articles/7d19cf4a5761797c34a0664ef92bb065> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary The paper analyzes the problem how environmental policy affects sector structure, the allocation of resources, relative price (and comparative advantage) and national income in a two-country case with varying terms of trade. The frame of reference is a two-sector model in which production generates pollutants as a joint product. If a country exports the pollution-intensively produced commodity environmental policy will improve its terms of trade under suitable conditions with respect to demand. Whereas in the political debate the negative effect of environmental policy on the international competiveness of a country is stressed, the terms-of-trade effect gives more leeway to environmental policy. The effects on output, export, imports and the other variables of the system are discussed." .
<http://www.springernature.com/scigraph/things/articles/cc0cd382f92f8e9fd6495905ba5e8578> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract I exploit the potential of latent class models for proposing an innovative framework for financial data analysis. By stressing the latent nature of the most important financial variables, expected return and risk, I am able to introduce a new methodological dimension in the analysis of financial phenomena. In my proposal, (i) I provide innovative measures of expected return and risk, (ii) I suggest a financial data classification consistent with the latent risk-return profile, and (iii) I propose a set of statistical methods for detecting and testing the number of groups of the new data classification. The results lead to an improvement in both risk measurement theory and practice and, if compared to traditional methods, allow for new insights into the analysis of financial data. Finally, I illustrate the potentiality of my proposal by investigating the European stock market and detailing the steps for the appropriate choice of a financial portfolio." .
<http://www.springernature.com/scigraph/things/articles/e1b71695a43d8fceb07280a207188552> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract.  The non-parametric Mann–Whitney (MW) statistic test has been popularly used to assess the significance of a shift in median or mean of hydro-meteorological time series. It has been considered that the test is more suitable for non-normally distributed data and it may be not sensitive to the distribution type of sample data. However, no evidence has been provided to demonstrate these. This study investigates the power of the test in various circumstances by means of Monte Carlo simulation. Simulation results demonstrate that the power of the test is very sensitive to various properties of sample data. The power depends on the pre-assigned significance level, magnitude of a shift, sample size, and its occurrence position within a time series; and it is also strongly affected by the variation, skewness, and distribution type of a time series. The bigger the magnitude of a shift, the more powerful the test is; the larger the sample size, the more powerful the test is; and the bigger the variation within a time series, the less power the test has. The test has the highest power if a shift occurs at the midpoint of a time series. For the samples with different distribution types, the power of the test is dramatically different. The test has the highest power for time series with the extreme value type III (EV3) distribution while it indicates the lowest power for time series with the lognormal distribution." .
<http://www.springernature.com/scigraph/things/articles/3610c0cf2c76b7098f81997cea6eb7d2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We propose a sequential learning policy for ranking and selection problems, where we use a non-parametric procedure for estimating the value of a policy. Our estimation approach aggregates over a set of kernel functions in order to achieve a more consistent estimator. Each element in the kernel estimation set uses a different bandwidth to achieve better aggregation. The final estimate uses a weighting scheme with the inverse mean square errors of the kernel estimators as weights. This weighting scheme is shown to be optimal under independent kernel estimators. For choosing the measurement, we employ the knowledge gradient policy that relies on predictive distributions to calculate the optimal sampling point. Our method allows a setting where the beliefs are expected to be correlated but the correlation structure is unknown beforehand. Moreover, the proposed policy is shown to be asymptotically optimal." .
<http://www.springernature.com/scigraph/things/articles/a3815d9484b58252c1fc67b9182054f6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper develops a Wald statistic for testing the validity of multivariate inequality constraints in linear regression models with spherically symmetric disturbances, and derive the distributions of the test statistic under null and nonnull hypotheses. The power of the test is then discussed. Numerical evaluations are also carried out to examine the power performances of the test for the case in which errors follow a multivariate student-t (Mt) distribution." .
<http://www.springernature.com/scigraph/things/articles/76f54a473335b8afbcb5a004d1023cef> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary To preserve essential characteristics of our economic order it is necessary to reverse the unfavourable trends in unemployment and inflation. This requiresinter alia adequate growth of effective demand, curbing the growth of the public sector, avoiding the passing-on of collective burden and a development of exchange rates which neutralizes external inflationary effects. The restoration of sound economic conditions requires a drastic and extended operation; for that reason a quantitative plan for medium-term macro-economic policy is useful. Medium-term planning can only be successful through a combination of sophisticated economic analysis and down-to-earth management." .
<http://www.springernature.com/scigraph/things/articles/c60605fa612b58e26d85475301d1ac37> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper estimates the backward-looking and forward-looking monetary policy reaction functions of the Central Bank of the Republic of Turkey (CBRT) by considering the post-crisis period from August 2001 to September 2006, with a special emphasis on inflation targeting. Policies which the CBRT applied are analyzed according to the Taylor rule. The empirical results indicate that the CBRT followed the Taylor rule in its interest setting behaviour. In forward-looking models, the response coefficient of inflation and the output gap is greater than that of backward-looking models. The results of forward-looking models reflect, the policies conducted in Turkey. In the post-crisis period, expected inflation has been the main reaction variable for the CBRT. This suggests that monetary policy over the post-crisis period was not accommodating increases in expected inflation. The main conclusion is that ‘Taylor rule’ based monetary policies were effective in inflation targeting in Turkey." .
<http://www.springernature.com/scigraph/things/articles/9c66eb6d757095585bb8069664daa703> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The nonlinear discriminant function, when covariance matrixes of each population are not equal to each other, is discussed on the basis of Bayes’ criterion, and by using the stepwise discriminant method, a method for calculating the nonlinear discriminant function is provided, which is called “stepwise nonlinear discriminant analysis”. In addition, an appropriate discriminant analysis model is selected by testing whether the covariance matrixes of each population are equal, which was proposed by Box. The calculations show that, the discriminant effects of this method are superior not only to linear discriminant analysis, but also to nonlinear discriminant analysis in which the stepwise discriminant algorithm is not used when covariance matrixes of each population are not equal to each other. Satisfactory results have been obtained in applying this method. This is an important improvement on the linear discriminant analysis used in the weather typing prediction at present." .
<http://www.springernature.com/scigraph/things/articles/8d2ad63f6a24dfe1b38a91fa7b559cc9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Numerous studies have looked at the effect of corruption on economic growth and a common finding is that the former adversely affects the latter. Through regression analyses, we use recent data from Transparency International’s Corruption Perception Index (CPI) and the World Bank’s Governance Indicators for the 2000–2012 period to test the direct and indirect effects of corruption on GDP growth rate. Our findings confirm that corruption metes out important costs in terms of lower economic growth when the direct method is considered. However, the indirect method shows that the impact of corruption on growth through the human capital (education) and domestic investment channels is positive, whereas the impact of corruption on growth through the voice and accountability channel is negative and statistically significant. Using these results, we examine the costs of corruption for Vietnam. We show that, had the CPI levels improved by just one unit between 2000 and 2012, then the economy would have grown from an average of 6.73 % during this period to 6.94 %. If corruption levels had fallen one standard deviation (i.e., the CPI increased from 2.6 to 5.0), then Vietnam could have achieved a growth rate of 7.22 %. This illustrates the primary finding that corruption undermines economic performance." .
<http://www.springernature.com/scigraph/things/articles/7369b0b38234cdabf598a2c8ac4fd2fb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper proposes useful guidance on the choice of threshold for binary forecasts. In weather forecast systems, the probabilistic forecast cannot be used directly when estimated too smoothly. In this case, the binary forecast, whether a meteorological event will occur or not, is preferable to the probabilistic forecast. A threshold is needed to generate a binary forecast, and the guidance in this paper encompasses the use of skill scores for the choice of threshold according to the forecast pattern. The forecast pattern consists of distribution modes of estimated probabilities, occurrence rates of observations, and variation modes. This study is performed via Monte-Carlo simulation, with 48 forecast patterns considered. Estimated probabilities are generated by random variate sampling from five distributions separately. Varying the threshold from 0 to 1, binary forecasts are generated by threshold. For the assessment of binary forecast models, a 2 × 2 contingency table is used and four skill scores (Heidke skill score, hit rate, true skill statistic, and threat score) are compared for each forecast pattern. As a result, guidance on the choice of skill score to find the optimal threshold is proposed." .
<http://www.springernature.com/scigraph/things/articles/e7d44fe775dc4308bb39ddb20b967125> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Corruption has been found to have complex effects on firm innovation. Limited theoretical and empirical evidence to date has been rather inconclusive. This study employs econometric estimation techniques to analyze data from small and medium manufacturing enterprises in Vietnam to assess the impact of petty corruption on firm innovation. The empirical results tend to support the “greasing” impact of corruption on innovation. Specifically, informal payments by Vietnamese firms are shown to encourage overall innovation, product improvement, innovation and new innovation. In view of the commonplace business practice of paying small informal fees to speed up transactions in the inefficient public sector in Vietnam, this finding is not entirely unexpected, though troubling." .
<http://www.springernature.com/scigraph/things/articles/523f0d51f9787965fd7c9f72731dbc52> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We develop a method for computing output shadow prices when total cost and input prices are exogenous, using the indirect output distance function of Shephard (1974). We show that indirect distance function shadow price imputations for output prices are the same to a proportional constant as marginal cost imputations. We motivate our results by relating them to the problem of valuing the output of nonprofit institutions, to some measurement issues for noncompetitive industries, and to a problem of imputing sales of the commercial banking industry to consuming sectors of the economy in the national income accounts." .
<http://www.springernature.com/scigraph/things/articles/30bb23f3ec231f0fcc1451ebb3323e31> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Economic integration is examined in a multi-economy Schumpeterian growth model where economies differ in their research environment, and consequently in the productivity of R&D. It is shown that economies with more or less the same productivity of R&D integrate. In equilibrium, there can be many common markets with different growth rates as well as stagnating economies with decreasing relative income. A small economy with low incentives to save can avoid stagnation, if its R&D is so productive that a common market with a positive growth rate can accept it as a member." .
<http://www.springernature.com/scigraph/things/articles/d70ffddc0144bfae2ca573f9cc87190c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary The demand for money has been at the centre of monetary econometrics. The policy debate has focused on the stability issue. To investigate this the present paper presents an overview of 400 estimated demand-for-money equations in the EC countries and G7 member states taken from the literature. The results of this survey suggest, firstly, serious doubts on the stability of the demand for money and, secondly, a remarkable evolution in econometric methodology in an attempt to improve the statistical evidence. Thirdly and important from a policy perspective, the analysis of the reported standard errors of the equations shows that among the large European countries Germany has the most stable money demand." .
<http://www.springernature.com/scigraph/things/articles/90d9c94e8990b990b8ec60e8220d82b6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper adopts a flexible framework to assess both short- and long-run business cycle linkages between the Latin American (LA) bloc and the four largest economies in the world (namely the US, the Euro area, Japan and China) over the period 1980:I–2011:IV. The result indicates that the LA region is largely dependent on external developments, especially in the years after the great recession of 2008 and 2009. The trade channel appears to be the most important source of business cycle co-movement, whilst capital flows are found to have a limited role, especially in the very short run." .
<http://www.springernature.com/scigraph/things/articles/f66e766dea824014fa92e21b640d9a83> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper analyses the relation between money and inflation in Germany in a cost-push/demand-pull model of an open small economy by means of cointegration methods. The full-information-maximum-likelihood method of Johansen as well as structural methods are applied to datasubsets and the full data set. The focus of the paper is on tests for overidentifying restrictions and for weak and strong exogeneity within these data sets. The result of the paper is that the money stock, the price level and gross national product are endogenous whereas the interest rate and the real import price are both weakly and strongly exogenous. By means of the price cointegration relation we illustrate how monetary targeting should react to imported inflation." .
<http://www.springernature.com/scigraph/things/articles/0011878bfaf6bfe6cde3bca5ce1d0960> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This research proposes estimation of mid-terms in a time series for improving the prediction performance of back propagation. In this research, the process of estimating mid-terms is called VTG (virtual term generation) and schemes for doing that are called VTG schemes. This research proposes three VTG schemes: mean method, 2nd Lagrange method, and 1st Taylor method. We adopt only back propagation as prediction model, since the goal of this research is to improve its prediction performance and back propagation is used most popular for regression among supervised neural networks. By implementing the VTG schemes as preprocessing of time series prediction, it will be observed that the prediction performance of back propagation is improved through experiments of Sect. 5." .
<http://www.springernature.com/scigraph/things/articles/bfd878100e50525f13a26f86424af51e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The slowing population growth and consequent aging of the population in Canada and elsewhere have raised questions of the ability of such populations to provide support to their non-working or dependent, particularly their aged, members. Previous discussions have often been focussed on demographic measures of dependency, but more recent research has shown that, in North American society, the per capita costs of providing public programmes to an elderly member are between two and three times higher than those to a younger member of society. However, these measures have made no attempt to take into account changing labour market conditions. This paper develops measures of dependency to incorporate these latter effects. Calculations with Canadian data (1921–2021) show that demographic and economic dependency in Canada are currently at historically low levels. The numerical results also suggest that the effects of the general increases in labour force participation rates, that have characterized the past two decades, have more than offset the effects of the general increases in unemployment rates, and that future increases in participation rates and, perhaps, decreases in unemployment rates could provide a significant alleviation of the impacts of population aging on government expenditures in the years ahead." .
<http://www.springernature.com/scigraph/things/articles/fb8696cc4cd01106b3195042c71a2e04> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract According to the IFCC, to determine the population-based reference interval (RI) of a test, 120 reference individuals are required. However, for some age groups such as newborns and preterm babies, it is difficult to obtain enough reference individuals. In this study, we consider both parametric and nonparametric bootstrap methods for estimating RIs and the associated confidence intervals (CIs) in small sample size groups. We used data from four different tests [glucose, creatinine, blood urea nitrogen (BUN), and triglycerides], each in 120 individuals, to calculate the RIs and the associated CIs using nonparametric and parametric approaches. Also for each test, we selected small groups (m = 20, 30,…, 120) from among the 120 individuals and applied parametric and nonparametric bootstrap methods. The glucose and creatinine data were normally distributed, and the parametric bootstrap method provided more precise RIs (i.e., the associated CIs were narrower). In contrast, the BUN and triglyceride data were not normally distributed, and the nonparametric bootstrap method provided better results. With the bootstrap methods, the RIs and CIs of small groups were similar to those of the 120 subjects required for the nonparametric method, with a slight loss of precision. For original data with normal or close to normal distribution, the parametric bootstrap approach should be used, instead of nonparametric methods. For original data that deviate significantly from a normal distribution, the nonparametric bootstrap should be applied. Using the bootstrap methods, fewer samples are required for computing RIs, with only a slightly increased uncertainty around the end points." .
<http://www.springernature.com/scigraph/things/articles/5254b635409e44380c267cea5df48db6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Hierarchical models are considered for estimating the probability of agreement between two outcomes or endpoints from an environmental toxicity experiment. Emphasis is placed on generalized regression models, under which the prior mean is related to a linear combination of explanatory variables via a monotone function. This function defines the scale over which the systematic effects are modelled as additive. Specific illustration is provided for the logistic link function. The hierarchical model employs a conjugate beta prior that leads to parametric empirical Bayes estimators of the individual agreement parameters. An example from environmental carcinogenesis illustrates the methods, with motivation derived from estimation of the concordance between two species carcinogenicity outcomes. Based on a large database of carcinogenicity studies, the inter-species concordance is seen to be reasonably informative, i.e. in the range 67–84%. Stratification into pertinent potency-related sub-groups via the logistic model is seen to improve concordance estimation: for environmental stimuli at the extremes of the potency spectrum, concordance can reach well above 90%." .
<http://www.springernature.com/scigraph/things/articles/a346aa1304e98fe8d1158c171ca39f78> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The main objective of “time series analysis” is to discover the underlying structure of the time series, and thus, become able to forecast its “future values”. This process makes it possible to predict, control or simulate variables. Most of the time series modelling procedures try to forecast future values from lagged ones. Thus, the selection of the relevant lagged values to be used is a key step. In this paper, a new consensus method for the selection of relevant lagged values of a time series is introduced: feature ranking aggregated selection (FRASel). The main contribution of this feature selection method is the definition of a consensus decision making mechanism based on aggregation and expressed as a simple rule. In FRASel, the selected subset of lagged values is decided by the application of an aggregation criterion to the results of different flavours of feature ranking methods, applied from different approaches. A thorough empirical analysis is carried out to assess the performance of FRASel. The statistical significance of the experimental results is also analysed through the application of non-parametric statistical tests." .
<http://www.springernature.com/scigraph/things/articles/9e5475ad1ac39f252efab7f2134d9365> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The trip end models which have been used in past transportation studies are briefly summarised. Problems associated with the use of zone-based models are outlined and reasons are given to support the development of models at the household rather than zonal level. It is suggested that recent developments which have taken place in household-based models have not been entirely logical. In particular, arguments between regression models and category analysis models have been confused with the use of aggregate (zonal) as against disaggregate (household) data — regression models being associated with the use of zonal data and category analysis models with household data. Misunderstood arguments and false notions regarding sample sizes have directed attention from the regression analysis approach. A detailed comparison of the category analysis and regression analysis methods for developing household-based trip end models is given. Both methods have been applied using data from the Monmouthshire Land Use Transportation Study. The regression results reported are from a very preliminary analysis and contain a number of anomalies, although it is thought that sufficient work has been done to provide an objective evaluation of the two methods. It is recommended that the household regression approach should be further investigated since it has advantages as a modelbuilding procedure and makes better use of sample data. A certain amount of categorisation of household types is necessary and the investigations would attempt to determine the best balance between categorisation and regression fitting. Further development will be restricted if the trend towards minimum sample sizes of about 1000 households is continued. Larger samples should be taken in certain circumstances to pursue development work." .
<http://www.springernature.com/scigraph/things/articles/6b95eeb2875a02b678850a31ac0246a8> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract There is evidence that estimates of long-run impulse responses of structural vector autoregressive (VAR) models based on long-run identifying restrictions may not be very accurate. This finding suggests that using short-run identifying restrictions may be preferable. We compare structural VAR impulse response estimates based on long-run and short-run identifying restrictions and find that long-run identifying restrictions can result in much more precise estimates for the structural impulse responses than restrictions on the impact effects of the shocks." .
<http://www.springernature.com/scigraph/things/articles/dacafc7e4adc6af03200f5f6fe120e20> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This research examines the degree of financial contribution of married women to their overall family income. This phenomenon is analyzed from the point of view of sex-role/human capital orientations. The sex-role position argues that regardless of women's social, economic and education background their financial input to household economy will always be less than fifty percent because women's financial opportunities are impeded by sex-role configurations and expectations. The human capital thesis explains women's apparent inability to contribute more than half of the family income as a function of their lower human capital; that is, education, professionalization and training in the labour market. Individual data pertaining to thirty-year old married women, taken from the 1981 Canadian census, are examined. Generally, we find support for the positions: Women with relatively high human capital assmulation contribute significantly to overall household income, but invariably that contribution is less than 50 percent of total family income. On average, all women contribute 22 percent of their families annual income, while working women provide approximately 33 percent of the total. This analysis demonstrates what appears to be a pervasive phenomenon in industrial nations: married women are generally junior economic partners within the family. The extent of junior partnerships, however, is somewhat conditioned by women's human capital resources." .
<http://www.springernature.com/scigraph/things/articles/ff87474d6bb78e8dfbb7ef90b348642e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We develop a two equation error correction model to investigate determinants of and dynamic interaction between changes in profits and number of firms in retailing. An explicit distinction is made between the effects of actual competition among incumbants, new firms competition and potential competition from firms outside the market. Effects of cost, demand and general income changes on profitability are investigated to gain insight in the role of retailing in the cost, demand and wage inflationary processes. The relative importance of profitability, growth and unemployment as determinants of net entry are studied. The model is tested using a panel data set of 36 Dutch shoptypes covering the 1977–1988 period." .
<http://www.springernature.com/scigraph/things/articles/3246c0026880b9b9e8dc9881e7843138> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We analyze the level and distribution of economic well-being in the United States during the 1980s and 1990s based on the standard measure of money income and a measure in which income from wealth is calculated as the sum of lifetime annuity from nonhome wealth and imputed rental-equivalent for owner-occupied homes. Over the 1982–2000 period, median well-being increases faster when these adjustments are made than when standard money income is used. This adjustment also widens the income gap between African-Americans and whites but increases the relative well-being of the elderly. Adding imputed rent and annuities from household wealth to household income considerably increases measured inequality and the share of income from wealth in inequality. However, both measures show about the same rise in inequality over the period. We also find an increasing share of wage and salary income in our expanded definition of income among the richest 1% over the period but do not find that the “working rich” have largely replaced rentiers at the top of the economic ladder." .
<http://www.springernature.com/scigraph/things/articles/5aebd8be9bf7178cd0627483054af871> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract For Markovian economic models, long-run equilibria are typically identified with the stationary (invariant) distributions generated by the model. In this paper we provide new sufficient conditions for continuity in the map from parameters to these equilibria. Several existing results are shown to be special cases of our theorem." .
<http://www.springernature.com/scigraph/things/articles/7e4a5a67d0e1334e7c893333b98852a1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract  This study is a further development of a dynamic compartment-flow analysis, intended as an analytical tool for the empirical estimation of fine root growth, mortality and decomposition in forest soil. General properties of the dynamic system are utilised to interpret relatively simple measurements of standing biomass, necromass, and decomposition, in order to derive estimates of the process rates. The method is based on the finding that the ratio of fine root necromass to biomass is related to the specific rates of decomposition, mortality, and net growth. If the decomposition rate is measured and the net growth trend is determined from live root measurements, mortality and gross growth can be estimated using these relationships, provided certain regularity requirements are met. These requirements are explicated, such that the estimates can be easily assessed for reliability. To illustrate the use of the method, it was applied to the estimation of specific mortality rates in seven Scots pine stands of different ages and site types. A reanalysis of a previous sequential coring study yielded consistent results. The advantage of this method is that, unlike the standard analysis of sequential cores, it accounts for the possibility of simultaneous growth, mortality and decomposition. It is therefore applicable to situations with no apparent fluctuations or trend in the biomass and necromass levels. No minimum sampling interval is required; hence the method also allows for more extensive or prolonged studies." .
<http://www.springernature.com/scigraph/things/articles/9f35534ce513587e5936a2e201c065d1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Modelling of financial systems has traditionally been done in partial equilibrium. Such models have been very useful in expanding our understanding of the capital markets; nevertheless, many empirical financial anomalies have remained unexplainable. It is possible that this may be due to the partial equilibrium nature of these models. Attempting to model financial markets in a general equilibrium framework still remains analytically intractable. Because of their inductive nature, dynamical systems such as neural networks can bypass the step of theory formulation, and they can infer complex non-linear relationships between input and output variables. Neural networks have now been applied to a number of live systems, and have demonstrated far better performance than conventional approaches. This paper reviews the state-of-the-art in financial modelling using neural networks, and describes typical applications in key areas of forecasting, classification and pattern recognition. The applications cover areas such as asset allocation, foreign exchange, stock ranking and bond trading." .
<http://www.springernature.com/scigraph/things/articles/b1011dc64dc6901f5292ee657a2e4fae> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The degree of banking efficiency is of key importance as this has significant implication on the stability of financial systems and ultimately impacts on an economy. In this paper, we extend the existing literature by measuring the degree of bank efficiency in ten frontier African countries. We also attempt to analyse the determinants of banking efficiency in the sample countries. We employ a bank-level panel data set over the period 2008–2012 to measure banking efficiency in a two-stage procedure. In the first stage, we use the Data Envelopment Analysis technique to estimate technical, pure technical and scale bank efficiency. In the second stage, we use Simar and Wilson (J Econom 136:31–64, 2007) truncated bootstrapping approach to analyse the determinants of banking efficiency. The results of our analysis show that, to a greater extent, banks in the countries studied have efficient banking sectors. The results of truncated regression indicate that bank size is negatively related to banking sector efficiency while the degree of risk is positively related bank efficiency. Overall, the present study provides empirical information that may be used to guide future financial reform policies in the Frontier African countries." .
<http://www.springernature.com/scigraph/things/articles/51e0223481aa863134830f693eff9777> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper explores the relationship between two well-established concepts of measuring individual well-being: the concept of happiness, i.e. self-reported level of satisfaction with income, and relative deprivation, i.e. the gaps between the individual’s income and the incomes of all individuals richer than him. Operationalizing both concepts using micro panel data from the German Socio-Economic Panel, we provide empirical evidence for subjective well-being depending more on relative deprivation than on absolute levels of income. This finding holds after controlling for other influential factors in a multivariate setting." .
<http://www.springernature.com/scigraph/things/articles/365f00a0407004e9cb8de602ae8e51cf> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper investigates the nonparametric analysis of technology under non-convexity. The analysis extends two approaches now commonly used in efficiency and productivity analysis: data envelopment analysis where convexity is imposed; and free disposal hull (FDH) models. We argue that, while the FDH model allows for non-convexity, its representation of non-convexity is too extreme. We propose a new nonparametric model that relies on a neighborhood-based technology assessment which allows for less extreme forms of non-convexity. The distinctive feature of our approach is that it allows for non-convexity to arise in any part of the feasible set. We show how it can be implemented empirically by solving simple linear programming problems. And we illustrate the usefulness of the approach in an empirical application to the analysis of technical and scale efficiency on Korean farms." .
<http://www.springernature.com/scigraph/things/articles/550429681cbdea018699cbe759935fef> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In the decade since its creation in 1999, the European Economic and Monetary Union (EMU) has experienced surprisingly large and persistent inflation differentials across member states causing substantial shifts in relative price levels. At the same time, member countries exhibited distinct non-synchronized output fluctuations, giving rise to a pattern of ‘rotating slumps’ (a term coined by Olivier Blanchard). This paper presents a stylized theoretical model of a monetary union which demonstrates how inflation differentials and relative output movements interact dynamically. A number of implications are derived from the model. In particular, national fiscal policies are shown to have an important role in containing internal macroeconomic disparities in a monetary union. An optimal fiscal policy rule is derived from the model for that purpose." .
<http://www.springernature.com/scigraph/things/articles/d077f039d8a99142c43392875042b320> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper proposes two bootstrap-based tests that can be used to infer whether the individual slopes in a panel regression model are homogenous. The first test is suitable when wanting to infer the null of homogeneity versus the general alternative, while the second is suitable when wanting to infer the units of the panel that can be pooled. Both approaches are shown to be asymptotically valid, a property that is verified in small samples using Monte Carlo simulation." .
<http://www.springernature.com/scigraph/things/articles/cc0e40a48ca72b169179b3686465cedb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract It is known that the occurrence of outliers in linear or non-linear time series models may have adverse effects on the modelling and statistical inference of the data. Consequently, extensive research has been conducted on developing outlier detection procedures so that outliers may be properly managed. However, no work has been done on the problem of outliers in circular time series data. This problem is the focus of this paper. The main objective is to develop novel numerical and graphical procedures for detecting these outliers in circular time series data.A number of circular time series models have been proposed including the circular autoregressive model. We extend the iterative outlier detection procedure which has been successfully used in linear time series models to the circular autoregressive model. The proposed procedure shows a good performance when investigated via simulation for the circular autoregressive model of order one. At the same time, several statistical techniques have been used to detect the change of preferred trend in time series data using SLIME and CUSUM plots. While the methods fail to indicate directly the outliers in circular time series data, we use the ideas employed to develop three novel graphical procedures for identifying the outliers. For illustration, we apply the procedures to a particular set of wind direction data. An agreement between the results of the graphical and iterative detection procedures is observed. These procedures could be very useful in improving the modelling and inferential processes for circular time series data." .
<http://www.springernature.com/scigraph/things/articles/a5c1bf864b7a45d789b26e29093a745d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A small number of studies have sought to establish that research papers with more funding acknowledgements achieve higher impact and have claimed that such a link exists because research supported by more funding bodies undergoes more peer review. In this paper, a test of this link is made using recently available data from the Web of Science, a source of bibliographic data that now includes funding acknowledgements. The analysis uses 3,596 papers from a single year, 2009, and a single journal, the Journal of Biological Chemistry. Analysis of this data using OLS regression and two ranks tests reveals the link between count of funding acknowledgements and high impact papers to be statistically significant, but weak. It is concluded that count of funding acknowledgements should not be considered a reliable indicator of research impact at this level. Relatedly, indicators based on assumptions that may hold true at one level of analysis may not be appropriate at other levels." .
<http://www.springernature.com/scigraph/things/articles/6cbf37326ffbba5c0398d4f8d9630df7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We present a new approach of explaining instantaneous causality in multivariate fMRI time series by a state space model. A given single time series can be divided into two noise-driven processes, a common process shared among multivariate time series and a specific process refining the common process. By assuming that noises are independent, a causality map is drawn using Akaike noise contribution ratio theory. The method is illustrated by an application to fMRI data recorded under visual stimulation." .
<http://www.springernature.com/scigraph/things/articles/37b9ef9c38dce3b461b2655047cd2904> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we estimate the effect of exchange rate moments on foreign direct investment (FDI). Using data from a developing country (specifically Ghana) during the years 1990–2012 and robust regression and bootstrap method, the study finds that FDI increases as a result of the depreciation of the local currency. Secondly, using standard deviation as a measure of volatility, we find positive relationship between exchange rate volatility and FDI. Skewness did not show any significant relationship with FDI, which is straight to the heart of the mean reverting principle of the exchange rate. We find the political atmosphere as one of the main factors of drawing FDI into Ghana. These results are robust in the presence of all the standard control variables having significant coefficients under the various methodologies." .
<http://www.springernature.com/scigraph/things/articles/b2b06d5a03370767edeb62bb961b6c8c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We use time-series analysis to estimate the economic damage caused by the uncovered retail gasoline cartel in the city of Sherbrooke. We calculate both the total overcharge and the deadweight loss using a Marshallian demand curve. We find that total damages for the period spanning from January 2000 to May 2006 can be as high as $16.2 million expressed in 2002 Canadian dollars. We compare the total damages from this price fixing conspiracy in the city of Sherbrooke to the meted punishment for all of the investigated markets and find the latter to be a small fraction of the former. We argue that the current enforcement of the Competition Act’s conspiracy provision is unlikely to deter cartel formation." .
<http://www.springernature.com/scigraph/things/articles/674225378543f3d4fc65fc18008cf0c9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract There are two distinct bivariate extreme value distributions constructed from Gumbel marginals, namely Gumbel mixed (GM) model and Gumbel logistic (GL) model. These two models have completely different structures and their dependence ranges are different. The product-moment correlation coefficient for the former is ρ∈[0,2/3] and the latter is ρ∈[0,1]. It is natural to ask which one is more appropriate for representing the joint probabilistic behavior of two correlated Gumbel-distributed variables. This study compares these two models by numerical experiments. The comparison is based on that: (i) if the two distribution models are identical, then the joint probability and the joint return period computed by the GM model should be the same as those by the GL model; and (ii) if a selected distribution is the true distribution from which sample data are drawn, then the probabilities computed by the theoretical model should provide a good fit to empirical ones. Comparison results indicate that in the range of correlation coefficient ρ∈[0,2/3], both models provide identical joint probabilities and joint return periods, and both indicate a good fit to empirical probabilities; while for ρ∈(2/3,1), only the Gumbel logistic model can be used." .
<http://www.springernature.com/scigraph/things/articles/8eb31b7ae4641e0d61626539560bc91b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The autonomy of a country’s central bank from political authorities has been advocated both as a remedy against the inflationary bias that would otherwise be present in the conduct of the government’s monetary policy and, more recently, on the basis of empirical evidence. However, both theoretical arguments and empirical findings have associated central bank autonomy with the conduct of monetary policy, while often failing to pay attention to those institutional cases where a central bank is in place but is not responsible for the conduct of monetary policy. These cases are particularly relevant for those countries which do not possess their own currency, or where extreme monetary regimes such as dollarization, currency boards, or monetary unions are present. These institutional settings, where a central bank exists, but there is no monetary policy to be conducted, raise the issue of central bank autonomy in a framework where the inflation bias is no longer pertinent. In other words: Is central bank autonomy still a relevant objective when a country does not run its own monetary policy? The present paper addresses this question, discusses dimensions of autonomy and accountability and maintains that central bank autonomy still does matter, particularly if the central bank is responsible for bank supervision and financial regulation." .
<http://www.springernature.com/scigraph/things/articles/821a2ca85d175f330ed9db498e5f8514> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Much attention has been given to the estimation of hedonic regressions given their potential use as a means to adjust consumer and producer price indices for quality changes. However, there has been warranted criticism over the methods used, particularly relating to the econometric specification of the models. Much of the criticism has arisen from the inability of available data to match the requirements of a fully specified model. Using EPOS scanner data for UK television sets we provide reliable hedonic estimates which incorporate several developments. Such data are available for a wide range of product areas and this application illustrates how they might be used. We develop methodology to help surmount problems arising from omitted variables, the coexistence of new and old models, weighting of observations and quality changes common to all models. More specifically we pay particular attention to the neglected area of product markets where pricing is above marginal cost." .
<http://www.springernature.com/scigraph/things/articles/15111cf806151662cf64088d141ceceb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. This paper develops and estimates a structural, latent variable, model for the hidden economy in New Zealand, and a separate currency-demand model. The estimated latent variable model is used to generate an historical time-series index of hidden economic activity, which is calibrated via the information from the currency-demand model. Special attention is paid to data non-stationarity, and to diagnostic testing. Over the period 1968 to 1994, the size of the hidden economy is found to vary between 6.8% and 11.3% of measured GDP. This, in turn, implies that the total tax-gap is of the order of 6.4% to 10.2% of total tax liability in that country. Of course, not all of this foregone revenue would be recoverable, as not all of the activity in the underground economy is responsive to changes in taxation or other policies." .
<http://www.springernature.com/scigraph/things/articles/e043b326770ed4d5387a2c2035dbf9a6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A new approach is considered to processing interlaboratory test data resulting from several different values for the measured quantity. There is a basic method for the simultaneous estimation of the additive and multiplicative components of the total error, which employs covariance analysis. It is shown that if one of the components is not identified reliably, one can transfer to one of the two models in variance analysis." .
<http://www.springernature.com/scigraph/things/articles/7a821446a50895a1f2d0218fd21581b7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper presents an interpolation variance as an alternative to the measure of the reliability of ordinary kriging estimates. Contrary to the traditional kriging variance, the interpolation variance is data-values dependent, variogram dependent, and a measure of local accuracy. Natural phenomena are not homogeneous; therefore, local variability as expressed through data values must be recognized for a correct assessment of uncertainty. The interpolation variance is simply the weighted average of the squared differences between data values and the retained estimate. Ordinary kriging or simple kriging variances are the expected values of interpolation variances; therefore, these traditional homoscedastic estimation variances cannot properly measure local data dispersion. More precisely, the interpolation variance is an estimate of the local conditional variance, when the ordinary kriging weights are interpreted as conditional probabilities associated to the n neighboring data. This interpretation is valid if, and only if, all ordinary kriging weights are positive or constrained to be such. Extensive tests illustrate that the interpolation variance is a useful alternative to the traditional kriging variance." .
<http://www.springernature.com/scigraph/things/articles/efab5018d2335a175cd9c772ff99b27e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper examines the optimal environmental and monetary policy mix in a New Keynesian model embodying pollutant emissions, abatement technology and environmental damage. The optimal response of the economy to productivity shocks is shown to depend crucially on the instruments policy makers have available, the intensity of the distortions they have to address (i.e. imperfect competition, costly price adjustment and negative environmental externality) and the way they interact." .
<http://www.springernature.com/scigraph/things/articles/b200875c4cbf6832aacd31498d8e5f56> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. This paper develops methods for relating the prices of discrete- and continuous-time versions of path-dependent options sensitive to extremal values of the underlying asset, including lookback, barrier, and hindsight options. The relationships take the form of correction terms that can be interpreted as shifting a barrier, a strike, or an extremal price. These correction terms enable us to use closed-form solutions for continuous option prices to approximate their discrete counterparts. We also develop discrete-time discrete-state lattice methods for determining accurate prices of discrete and continuous path-dependent options. In several cases, the lattice methods use correction terms based on the connection between discrete- and continuous-time prices which dramatically improve convergence to the accurate price." .
<http://www.springernature.com/scigraph/things/articles/1ba10564d98f694f7e13d353a9ad9d30> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A dynamical model of optimal economic growth is used for the comparison of catalogs of real econometric data and synthetic growth scenarios. The model is calibrated on a database of the Tokyo Institute of Technology. Special attention is paid to the aggregated data of the Japanese manufacturing industry in the period 1960–92. A description of an algorithm modeling optimal trends in the technological dynamics is given." .
<http://www.springernature.com/scigraph/things/articles/5cc307e2852b6d1cfc71c180831ee80f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A detailed analysis of the inclusive production of the vector mesonsφ,K *+,0(892) $$\\bar K*^0 (892),\\rho ^{ + ,0} ,\\omega $$ and the tensor mesonsK 2*0)(1430) andf 2(1270) inK + p interactions at 250 GeV/c is presented The data are compared with results at lower energies and with various quark-parton models. The production ofρ 0,K *0(892) and $$\\bar K*^0 (892)$$ increases at the same rate as a function ofs, is concentrated in the central region and is not reproduced by the models. Production of the tensor mesonsf 2(1270) andK 2*0(1340) is suppressed relative toρ 0 andK *0(892) by a factor of about 3." .
<http://www.springernature.com/scigraph/things/articles/2414e1fc7859f16a10216c15ffe8538d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary The historical roots of macroeconometric model building go back to the studies of Jan Tinbergen in constructing statistical models of The Netherlands and the United States. His work built on the contributions of J.M. Keynes to macroeconomic theory and Simon Kuznets to the design of accounts to measure national income and product. Wassily Leontief's input-output models helped to extend the effort to many industrial sectors. Other economic theorists and statisticians also made important contributions in the 1930s and 1940s. A breakthrough has been the arrival of the electronic computer. Many seemingly impossible tasks are now quite easy. Among the many approaches to economic forecasting, policy analysis, and cyclical analysis, macroeconometric modeling stands out as the most accurate and insightful. There are many challengers, but none that is demonstrably superior on a replicated basis. The present thrust of model building has extended beyond Professor Tinbergen's original work at the national level. World models of economic interdependence are now operational in many international centers." .
<http://www.springernature.com/scigraph/things/articles/4f36dbf6fca361ceae4da6ee9e38b6a3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Many pattern matching approaches have been applied in financial time series to detect chart patterns and predict price trends. In this paper, we propose an extended hidden semi-Markov model for chart pattern matching (HSMM-CP). In our approach, a hidden semi-Markov model is trained and a Viterbi algorithm is used to detect chart patterns. The proposed approach not only simplifies the traditional way of training an HSMM, but also reduces potential biases in parameter initialisation. We compare the proposed model with current approaches on a set of templates selected from 53 chart patterns. Experiments on a synthetic dataset show that the proposed approach has the highest average accuracy and recall among other pattern matching approaches. Specifically, the HSMM-CP approach achieves highest accuracy for “Triangles, Ascending”, “Head-and-Shoulders Tops”, “Triple Tops” and “Cup with Handle” patterns. Moreover, experiments results show that the HSMM-CP performs significantly better than other approaches in distinguishing patterns with similar shapes such as “Head-and-Shoulders Tops” and “Triple Tops”. Experiments are also conducted on a real dataset comprising the historical prices of several stocks." .
<http://www.springernature.com/scigraph/things/articles/6a905073d6aeace280b0d5a9b953f16c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract An exact maximum likelihood procedure is presented for estimating the parameters of a periodic autogressive-moving average (PARMA) model. To develop an estimator which is both statistically and computationally efficient, the PARMA class of models is written using a state-space representation and a Kalman filtering algorithm is used to estimate the parameters. In order to demonstrate how to fit PARMA models in practice, the most appropriate types of PARMA models are identified for fitting to two average monthly riverflow time series and the new estimator is employed for estimating the model parameters." .
<http://www.springernature.com/scigraph/things/articles/1bee79d23bb28237fe07c8d5ec2b7288> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. This paper presents a new approach to interest rate dynamics. We consider the general family of arbitrage-free positive interest rate models, valid on all time horizons, in the case of a discount bond system driven by a Brownian motion of one or more dimensions. We show that the space of such models admits a canonical mapping to the space of square-integrable Wiener functionals. This is achieved by means of a conditional variance representation for the state price density. The Wiener chaos expansion technique is then used to formulate a systematic analysis of the structure and classification of interest rate models. We show that the specification of a first-chaos model is equivalent to the specification of an admissible initial yield curve. A comprehensive development of the second-chaos interest rate theory is presented in the case of a single Brownian factor, and we show that there is a natural methodology for calibrating the model to at-the-money-forward caplet prices. The factorisable second-chaos models are particularly tractable, and lead to closed-form expressions for options on bonds and for swaptions. In conclusion we outline a general “international” model for interest rates and foreign exchange, for which each currency admits an associated family of discount bonds, and show that the entire system can be generated by a vector of Wiener functionals." .
<http://www.springernature.com/scigraph/things/articles/29aa6cad6400d0ea6dc73ef137945fc6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary Keynesian IS-LM models assume the production of a single homogenous commodity which can either be consumed or added to an immobile capital stock. Elsewhere the short run implications of both fixed and flexible wage versions of this model were found altered when consumer and investment goods are produced in separate industries and sold for different prices. This paper reports the long run implications of such models. It turns out that qualitatively the steady state multipliers for the one and two commodity models are virtually identical." .
<http://www.springernature.com/scigraph/things/articles/54e982933c40a7e1ac9882e811d8f811> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Reconstructing weighted networks from partial information is necessary in many important circumstances, e.g. for a correct estimation of systemic risk. It has been shown that, in order to achieve an accurate reconstruction, it is crucial to reliably replicate the empirical degree sequence, which is however unknown in many realistic situations. More recently, it has been found that the knowledge of the degree sequence can be replaced by the knowledge of the strength sequence, which is typically accessible, complemented by that of the total number of links, thus considerably relaxing the observational requirements. Here we further relax these requirements and devise a procedure valid when even the the total number of links is unavailable. We assume that, apart from the heterogeneity induced by the degree sequence itself, the network is homogeneous, so that its (global) link density can be estimated by sampling subsets of nodes with representative density. We show that the best way of sampling nodes is the random selection scheme, any other procedure being biased towards unrealistically large, or small, link densities. We then introduce our core technique for reconstructing both the topology and the link weights of the unknown network in detail. When tested on real economic and financial data sets, our method achieves a remarkable accuracy and is very robust with respect to the sampled subsets, thus representing a reliable practical tool whenever the available topological information is restricted to small portions of nodes." .
<http://www.springernature.com/scigraph/things/articles/8e3965df370688f002d8251d488f6d82> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The downturn in the world economy following the global banking crisis has left the Chinese economy relatively unscathed. This paper develops a model of the Chinese economy using a DSGE framework with a banking sector to shed light on this episode. It differs from other applications in the use of indirect inference procedure to test the fitted model. The model finds that the main shocks hitting China in the crisis were international and that domestic banking shocks were unimportant. However, directed bank lending and direct government spending was used to supplement monetary policy to aggressively offset shocks to demand. The model finds that government expenditure feedback reduces the frequency of a business cycle crisis but that any feedback effect on investment creates excess capacity and instability in output." .
<http://www.springernature.com/scigraph/things/articles/0d8d6c3951635317e0b603094ad32236> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article studies the connection between political instability and the sustainability of an exchange rate regime. A model based on the credibility of monetary policy shows that political unrest should be correlated with the adoption of flexible exchange rates. That intuition is tested using various measures of political instability on a panel of 125 countries between 1980 and 1994." .
<http://www.springernature.com/scigraph/things/articles/a1273ec18d469ca12cc998d0de87def3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper addresses the problem of joint disaggregating a group of time series when their temporal aggregation values and their contemporaneous aggregation are known and when a number of related series in the desired frequency are available. The focus is on temporal distribution of annual series. This problem was treated before by other authors but they did not solve the problem of spurious steps which usually emerge in this framework. Proposed here is the simplest hypothesis congruent with reality that solves this difficulty. An algorithm is proposed to use these hypotheses in empirical works." .
<http://www.springernature.com/scigraph/things/articles/3849da7a68af2bf247c68d326cf82031> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract PurposeThe main objective of this work is to compare the standard bioequivalence tests based on individual estimates of the area under the curve and the maximal concentration obtained by non-compartmental analysis (NCA) to those based on individual empirical Bayes estimates (EBE) obtained by nonlinear mixed effects models. MethodsWe evaluate by simulation the precision of sample means estimates and the type I error of bioequivalence tests for both approaches. Crossover trials are simulated under H 0 using different numbers of subjects (N) and of samples per subject (n). We simulate concentration-time profiles with different variability settings for the between-subject and within-subject variabilities and for the variance of the residual error. ResultsBioequivalence tests based on NCA show satisfactory properties with low and high variabilities, except when the residual error is high, which leads to a very poor type I error, or when n is small, which leads to biased estimates. Tests based on EBE lead to an increase of the type I error, when the shrinkage is above 20%, which occurs notably when NCA fails. ConclusionsFor small n or data with high residual error, tests based on a global data analysis should be considered instead of those based on individual estimates." .
<http://www.springernature.com/scigraph/things/articles/6090cf65c07364d47b9a5b25ff859544> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Flood frequency analysis is usually based on the fitting of an extreme value distribution to the local streamflow series. However, when the local data series is short, frequency analysis results become unreliable. Regional frequency analysis is a convenient way to reduce the estimation uncertainty. In this work, we propose a regional Bayesian model for short record length sites. This model is less restrictive than the index flood model while preserving the formalism of “homogeneous regions”. The performance of the proposed model is assessed on a set of gauging stations in France. The accuracy of quantile estimates as a function of the degree of homogeneity of the pooling group is also analysed. The results indicate that the regional Bayesian model outperforms the index flood model and local estimators. Furthermore, it seems that working with relatively large and homogeneous regions may lead to more accurate results than working with smaller and highly homogeneous regions." .
<http://www.springernature.com/scigraph/things/articles/dda1a26a16573e580c0dc18147d5f7d4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Conclusions The main conclusion which emerges from the results in Tables 1–3 is the extreme sensitivity of Marlow's results to the countries included in the sample (particularly Japan), to the time period, and to the other variables included in the analysis. This conforms with the OECD's own analysis of these data and subsequent research based on them. It suggests that the underlying relationship being investigated is inherently unstable and that the estimated model leaves a considerable proportion of the variance of the dependent variable unexplained. These aspects of the results are consistent with most of the other empirical work on the relationship between economic growth and the size and growth of government in industrialised economies. It is to be emphasised, however, that the results presented here do not refute the claims that the size and growth of government have not had any detrimental impact on economic performance in general and economic growth in particular. What they do point to is the absence of any simple, aggregative relationships linking government size and growth to the rate of economic growth. If such relationships are to be uncovered, this will require a more detailed and complex investigation of the impact of government which is embedded in a more rigorously formulated structural model of the growth process." .
<http://www.springernature.com/scigraph/things/articles/1a37d021b0692001eb020844f4ef322d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract  The paper proposes a new neuro-genetic hybrid algorithm (NGHA) for coping with ill-conditioned time-series processes. Extensive testing and comparisons to various heteroskedastic models indicate that the neuro-genetic algorithm may be a useful device for modelling complicated time series. NGHA is used to model a factor price series corresponding to the European factor of a representative set of global asset returns. NGHA provides a platform for adapting evolutionary computation to the search for suitable networks for observed time series." .
<http://www.springernature.com/scigraph/things/articles/2112665e0d864293efc60244941f902e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We present a methodology based on Fourier series analysis to compute time series volatility when the data are observations of a semimartingale. The procedure is not based on the Wiener theorem for the quadratic variation, but on the computation of the Fourier coefficients of the process and therefore it relies on the integration of the time series rather than on its differentiation. The method is fully model free and nonparametric. These features make the method well suited for financial market applications, and in particular for the analysis of high frequency time series and for the computation of cross volatilities." .
<http://www.springernature.com/scigraph/things/articles/97014c1e566bba3a10bd3a93ec2d388e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract ObjectivesTo document the association between economic development, income inequality, and health-related public infrastructure, and health outcomes among Chinese adults in midlife and older age. MethodsWe use a series of multi-level regression models with individual-level baseline data from the China Health and Retirement Longitudinal Survey (CHARLS). Provincial-level data are obtained both from official statistics and from CHARLS itself. Multi-level models are estimated with different subjective and objective health outcomes. ResultsEconomic growth is associated with better self-rated health, but also with obesity. Better health infrastructure tends to be negatively associated with health outcomes, indicating the likely presence of reverse causality. No supportive evidence is found for the hypothesis that income inequality leads to worse health outcomes. ConclusionsOur study shows that on top of individual characteristics, provincial variations in economic development, income inequality, and health infrastructure are associated with a range of health outcomes for Chinese midlife and older adults. Economic development in China might also bring adverse health outcomes for this age group; as such specific policy responses need to be developed." .
<http://www.springernature.com/scigraph/things/articles/8d4d19e402b256752c5d8420dc46de63> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A class of demand systems based on simple parametric specification of the indirect utility functions, but allowing for the parsimonious imposition of global regularity, is proposed. Demand systems in this class are completely flexible in rank, that is, can be potentially specified to acquire as large a rank as required in empirical work. They also exhibit a clear and reasonable homothetic asymptotic behaviour, as income approaches infinity. In an empirical application using Australian data, several examples from this class are estimated and compared with some popular alternatives in the literature." .
<http://www.springernature.com/scigraph/things/articles/e06fa4468548fb5f832c0ceb03adaba5> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In seasonal adjustment a time series is considered as a juxtaposition of several components, the trend-cycle, and the seasonal and irregular components. The Bureau of the Census X-11 method, based on moving averages, correction of large errors and trading day adjustments, has long dominated. With the success of ARIMA modelling at the end of the 20th century, methods with better outlier detection and trading day corrections by regression with ARIMA errors have appeared, with the regARIMA module of Census X-12-ARIMA or Bank of Spain TRAMO-SEATS. SEATS consists of extracting the components by an ARIMA-model-based unobserved components approach. This means that models are used for each component such that the sum of the components is compatible with the ARIMA model for the corrected time series. The underlying theory of the SEATS program is studied in many papers but there is no complete and systematic description of its output. Our purpose is to examine SEATS text output and to explain the results in simple words and formulas. This is done on a simple example, a time series with a non-seasonal model so that the computations can be verified step by step. The principles behind SEATS are first described, including the admissible decompositions and the canonical decomposition, and the derivation of the Wiener-Kolmogorov filter. Then the example is introduced: the interest rates of US certificates of deposits. The text output from SEATS is presented in edited form in several tables. Finally, the main results are checked on the example by means of a Microsoft Excel workbook and direct computations. In particular, the forecasts and backcasts are obtained; the admissible and canonical decompositions with two components are discussed; the filters are first derived using autocorrelations of two auxiliary ARMA processes, then applied on the prolonged time series; and the characteristics of the estimates, the revisions and the growth rates are analyzed." .
<http://www.springernature.com/scigraph/things/articles/35d9ded09a4774203e55ad4a51384763> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Forecasting future freight demand at a seaport is important for its planning and development. India has 13 major ports which handle 75% of the total seaport freight. Among the 13 major ports, Mumbai Port, ranked at number three in the country for the year 2013-14, handles about 11% of the total freight at major seaports in India. The focus of this paper is on developing inbound and outbound demand forecasting models for Mumbai Port. The models are developed using additive regression and time series techniques. In regression analysis economic indicators, Gross Domestic Product (GDP) and Crude Oil Production (CRLP) are found to be significant. The multivariate models performed better than the univariate models. The validation of time-series models resulted in error of less than 5%. Both multivariate regression and time-series models are used to forecast freight demand for the years 2014- 15 through 2017-18. The regression models are producing more optimistic forecasts than the time series models. The elasticity analysis suggested that Mumbai’s inbound freight will be growing almost with India’s GDP growth rate, the outbound freight, however, will experience slower growth than that of inbound." .
<http://www.springernature.com/scigraph/things/articles/522ae880df37d7af45379f2249f3b222> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In an economy dominated by labor-intensive processing trade, such as China, real exchange rate appreciation can possibly increase rather than decrease net exports. As the import content of processed exports (a proxy for dependence on processing trade) increases in its continuum, the stable equilibrium for the exchange rate and price level eventually yields to a saddle-point equilibrium. Unless the initial inflation (or deflation) rate is uniquely moderate at a given exchange rate, either the depreciation-inflation spiral or the appreciation-deflation spiral can dominate. Monetary and fiscal policies can help a processing-trade dependent country in structural transition from excessive engagement in processing trade (the saddle-point equilibrium) to a more sustainable and balanced trade structure." .
<http://www.springernature.com/scigraph/things/articles/d35c15e8a66a30bcc827bbb7e884656a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The lithium-ion battery cycle life prediction with particle filter (PF) depends on the physical or empirical model. However, in observation equation based on model, the adaptability and accuracy for individual battery under different operating conditions are not fully considered. Therefore, a novel fusion prognostic framework is proposed, in which the data-driven time series prediction model is adopted as observation equation, and combined to PF algorithm for lithium-ion battery cycle life prediction. Firstly, the nonlinear degradation feature of the lithium-ion battery capacity degradation is analyzed, and then, the nonlinear accelerated degradation factor is extracted to improve prediction ability of linear AR model. So an optimized nonlinear degradation autoregressive (ND–AR) time series model for remaining useful life (RUL) estimation of lithium-ion batteries is introduced. Then, the ND–AR model is used to realize multi-step prediction of the battery capacity degradation states. Finally, to improve the uncertainty representation ability of the standard PF algorithm, the regularized particle filter is applied to design a fusion RUL estimation framework of lithium-ion battery. Experimental results with the lithium-ion battery test data from NASA and CALCE (The Center for Advanced Life Cycle Engineering, the University of Maryland) show that the proposed fusion prognostic approach can effectively predict the battery RUL with more accurate forecasting result and uncertainty representation of probability density distribution (pdf)." .
<http://www.springernature.com/scigraph/things/articles/89f256e618e9c95f8eb0375e2e886b6c> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This paper formulates an optimizing model of a small open economy with a representative (immortal) household, a firm and a government. The asset menu consists of domestic currency, non-traded bonds and traded bonds. There is a risk premium on traded bonds, which leads to deviations from perfect capital mobility and uncovered interest parity. Taxes are lump-sum, so that finance by bonds and by taxation are equivalent. The model allows for current-account and wealth dynamics. The model assumes either purchasing power parity or imperfect substitution between home and foreign goods and either labour market equilibrium, nominal wage rigidity or real wage rigidity. The steady-state effects of a fiscal contraction, a monetary disinflation and an increase in the world interest rate are discussed. The transient effects of these policies are analysed with the aid of a ‘multiple shooting’ algorithm." .
<http://www.springernature.com/scigraph/things/articles/b64e6146058f3f6faeea49d0b3d7d0a1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract XYZ Company spends millions of dollars in the procurement of spare parts and tools every year. The maintenance part plays the role of sustaining the technical readiness of the equipment and vehicles. This research will try to find ways to reduce total inventory cost while maintaining the targeted level of technical readiness. The research consists of two phases of multi-criteria decision making on total inventory cost and technical readiness. First phase is to apply a 2-dimentional material classification technique to the selected data. Thus, a combination of ABC- and 123-analysis is used to simplify the problem by focusing on costly items only. The second phase is to apply a deterministic inventory model to the results of the material classification. A detailed analysis of the technical readiness and total inventory cost is covered for the deterministic inventory model. The objective of this research is to design a new system to balance readiness and the associated total inventory cost by finding the relationship between the desired level of technical readiness and cost. Finally, a comparison between the current inventory system and the proposed one shows around 42% savings in the total inventory cost over a period of 3 years, (Adi in Optimizing total inventory cost and enhancing technical readiness level. Master’s thesis, ESM at AUS, Sharjah, UAE, 2005)." .
<http://www.springernature.com/scigraph/things/articles/44491da1139873dff80456193f79673d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary The economic theory of the “true” cost of living and real income index numbers is described and illustrated geometrically in the logarithmic price-income space. Special attention is paid to the real income index evaluated at the geometric means of the prices in the two periods and to the cost of living index evaluated at the utility level which is associated with these geometric mean prices and geometric mean income. It is shown that this particular pair of index numbers is the only pair which satisfies a certain simple set of axioms. It is also shown how these index numbers can be approximated on the basis of observable price-quantity data. The approximation is accurate up to the second order in price and income log-changes." .
<http://www.springernature.com/scigraph/things/articles/a7b51f4a9a0d63f761971b17703ba477> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper describes the structure of a newly developed econometric, imperfectly competitive, general equilibrium model for the medium term study of energy and environmental problems. The geographical coverage of the model regards twelve European countries as well as the European Union as a whole. Compared to existing quantitative E3 (economy-energy-environment) models, the WARM model is characterized by a few novel and relevant features Firstly, in contrast to multicountry interlinked models, it copes with the international dimension by integrating differences from a common European denominator within a unified and homogeneously designed framework. A panel data estimation approach is used to achieve this objective. Secondly, in contrast to the traditional market-based philosophy of many econometric models, it adopts a perspective focused upon economic agents' decisions. Thirdly, in contrast with the practice of modelling technical progress as an exogenous and deterministic phenomenon, it incorporates an explicit attempt of modelling the sources and effects of endogenous technical change. A Kalman filter latent variable approach is the methodology from which statistical information on the dynamics of technical progress can be obtained. Finally, all markets in the model are imperfectly competitive, including the labour market where the wage bargaining process is explicitly modelled and estimated. This last feature is especially important in view of the European unemployment problem." .
<http://www.springernature.com/scigraph/things/articles/0a5011dba0916204c098a25b0a08a211> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Asymptotic estimates for the error of the Gauss-Jacobi quadrature formula are given for analytic functions. Our estimates for entire and meromorphic functions include those of Chawla and Jain [2]; for functions having branch-point and logarithmic singularities on the real axis we obtain improved estimates which, for the Gauss-Legendre case also, are better than those of Chawla and Jain. Numerical examples are given to illustrate the estimates obtained." .
<http://www.springernature.com/scigraph/things/articles/de3508edc6d42d25a29cc7c9b7cccee9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In German-style private health insurance contracts, aging provisions are used to flatten premium profiles. An individual would like to change insurer if she perceives a low service quality. The first-best optimum is characterized by provision transfers upon insurer changes which are higher for high risks and may be negative for low risks. Should the actual risk status not be verifiable, provision transfers have to be uniform. Efficient transfers will equalize consumption across periods and states if high risks are deterred from switching. Otherwise, the optimum transfer balances the distortion of incentives for high-risk and low-risk individuals." .
<http://www.springernature.com/scigraph/things/articles/7210c53952287edf32a3a4ba8927c39a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In defense of Europe. A crucial, not openly revealed and analyzed aspect of the 2 years crisis affecting the world economy, financial system, labour market, welfare and development is the fact that impact had not been a wave affecting all the main areas and regions in the same way. The emerging countries were not hit as we were supposing, Europe managed quite well the governance of the macroeconomic and financial impact of the earthquake coming from the USA, Russia has shown to be very vulnerable to external negative factors, innovative countries have reached the highest developments of R&D and ranking worldwide. The Great European world region (EU 27 plus almost other 20 neighboring countries) has shown a better capability to operate, via the European Central Bank, in a counter policy against the negative financial cycle policy than expected. FDIs were lagging but M&A were still quite robust. Eastern countries, by the way, showed capabilities to overcome unbalances and worst fall outs of the real economy recession. Social implications were quite severe but even so not as much as predicted in January 2009. The paper intends to demonstrate that Europe is now becoming the main international player and competitor in the 2020 worldwide competition." .
<http://www.springernature.com/scigraph/things/articles/ec765445882d5f2f8109259ad5ca587b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In the transition from a centrally planned to a market-oriented economy, such as in Romania, the domestic financial market plays two important roles. First, the financial market itself must be fundamentally restructured. Second, its efficient functioning is a crucial precondition for economic transformation. In transition economies, however, financial market institutions tend to concentrate their services on urban or larger rural enterprises. So far, small rural enterprises, even those with profitable investment plans, often do not have access to the financial market. This paper briefly characterizes the key issues of agricultural production units and their institutional environment and analyzes the depth and the efficiency of rural finance and its effect on Romania's rural economic transformation. It concludes with policy and institutional recommendations to strengthen rural finance." .
<http://www.springernature.com/scigraph/things/articles/f2f22440032a959383935b4f3b71b7d6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. The statistical distances between countries, calculated for various moving average time windows, are mapped into the ultrametric subdominant space as in classical Minimal Spanning Tree methods. The Moving Average Minimal Length Path (MAMLP) algorithm allows a decoupling of fluctuations with respect to the mass center of the system from the movement of the mass center itself. A Hamiltonian representation given by a factor graph is used and plays the role of cost function. The present analysis pertains to 11 macroeconomic (ME) indicators, namely the GDP (x1), Final Consumption Expenditure (x2), Gross Capital Formation (x3), Net Exports (x4), Consumer Price Index (y1), Rates of Interest of the Central Banks (y2), Labour Force (z1), Unemployment (z2), GDP/hour worked (z3), GDP/capita (w1) and Gini coefficient (w2). The target group of countries is composed of 15 EU countries, data taken between 1995 and 2004. By two different methods (the Bipartite Factor Graph Analysis and the Correlation Matrix Eigensystem Analysis) it is found that the strongly correlated countries with respect to the macroeconomic indicators fluctuations can be partitioned into stable clusters." .
<http://www.springernature.com/scigraph/things/articles/d587e493bfae2bc3542e0ecd8f70ba1f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper overviews the joint strategy of the Bank of Slovenia and of the Government of Slovenian for the policy management in the Exchange Rate Mechanism II (ERM II) and the eventual adoption of the euro. The current prospects of the Slovenian economy are favorable for early entry into ERM II so that the currency union can be acceded as soon as possible. The ERM II-connected risks, in particular an asymmetric credit financed demand boom, require a new policy mix to be set in place. While the monetary policy will focus on the tight management of the nominal exchange rate, the role of inflation restraint and shock absorption will rely on fiscal and income policies." .
<http://www.springernature.com/scigraph/things/articles/fc0e8a6a8a08c0099f5a0aa40622ecc6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The purpose of this paper is to develop an asymmetric game-theoretic static oligopoly model suitable for empirical work on oligopolistic markets. Prevailing models in applied research on oligopolistic industries are mainly of the type conjectural variations, Cournot models, although these models are known to be “logically flawed” from a game-theoretic point of view. As an alternative to these, a Bertrand model with three types of asymmetries is developed: firms can be concurrently asymmetric in cost levels and in the amount of product differentiation, where the impact from product differentiation on a firm's quantity demanded is divided into one relative-price component and one size component. This model is solved for different game-theoretic equilibria solutions. The conduct and performance of individual firms can be analyzed, and welfare effects in terms of consumer-surplus levels are calculated on the firm level. The model contains enough structure for direct use in applied research. A simple method for empirical use of the model is proposed, which minimizes the econometric task: By estimatingn+1 demand elasticities, the asymmetric market-demand structure for then firms will be completely specified." .
<http://www.springernature.com/scigraph/things/articles/a74e0cba7331ffe124ca543cf0632fc1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The change point detection (CPD) problem in a time series is when it is found that the structure of the data being generated has changed at some time and for some reason. We have formulated structural change detection in a time series as an optimal stopping problem using the concept of dynamic programming (DP), and we present the optimal solution and its correctness by numerical calculations. In this article, we present the solution theorem and its proof using reduction to absurdity." .
<http://www.springernature.com/scigraph/things/articles/52c4ce2f000fcc0ff79b667c39512bd6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The objective of the paper is to compare three recursive linear state space models used to forecast river flow. The three models are as follows: (i) Purely deterministic discrete linear cascade model (DLCM); (ii) Purely stochastic autoregressive moving average (ARMAX) time series model; and (iii) Coupled deterministic (DLCM) — stochastic (ARMA) model. Description of DLCM is given shortly. The state space formulation of the ARMAX model enables the recursive estimation of random walk parameters and the forecast of flows by linear Kalman filtering. The correlated error sequence of DLCM is described by an ARMA model. The DLCM and ARMA models are put together in a coupled deterministic-stochastic model. The recursive conditional forecasting of the augmented state vector is performed by the linear Kalman-filter. The conditional output forecast is given by linear projection of thea priori state vector. Numerical investigations on River Danube data lead to the conclusion that the coupled deterministic-stochastic model is the most efficient forecasting model of all the three recursive techniques compared." .
<http://www.springernature.com/scigraph/things/articles/4ea98d072ed610a03a758fc99963b98f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Forecasting financial indicators (indexes/prices) is a complex and a quite difficult issue because they depend on many factors such as political events, financial ratios, and economic variables. Also, the psychological facts or decision-making styles of investors or experts are other major reasons for this difficulty. In this study, a generalized behavioral learning method (GBLM) was employed to forecast financial indicators, which are the indexes/prices of 34 different financial indicators (24 stock indexes, 2 forexes, 3 financial futures, and 5 commodities). The achieved results were compared with the reported results in the literature and the obtained results by artificial neural network, which is widely used and suggested for forecasting financial indicators. These results showed that GBLM can be successfully employed in short-term forecasting financial indicators by detecting hidden market behavior (pattern) from their previous values. Also, the results showed that GBLM has the ability to track the fluctuation and the main trend." .
<http://www.springernature.com/scigraph/things/articles/a6fe0ac3683cf75f05c4d867fdf22e9b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper describes the content and logical structure of an engineering data base, to be constructed from direct technical information, for use with input-output (IO) models of the national economy. These models, which until now have relied almost exclusively on accounting information describing past economic transactions, can now be extended to analyze the future prospects for the U.S. economy and its individual sectors in terms of detailed technical decisions taken at the sites of production. The basic IO data base describes each sector's input in terms of its use of given amounts of goods and services produced in all sectors, per unit of its output. The new data base will distinguish the individual activities carried out within a sector, specify the important technical alternatives for each activity, and describe each alternative in terms of inputs of the required goods and services. The structure of the new data base accommodates the quantification of both production and “overhead” activities and their integration, and its implementation in stages is facilitated by the fact that it is a generalization of the structure of existing IO data bases." .
<http://www.springernature.com/scigraph/things/articles/526623fda594a00f70068b3ba305b838> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Even if questions of how resources aredistributed within and between societies are our main concern, we must continue to grapple with the issue of the causes of economic growth because economic growth and level of development continue to be among the most important causes of inequality, poverty, unemployment, and the quality of life. This paper’s dependent variable is the economic growth rate of 55 less developed countries (LDCs) during two time periods—1970–78 and 1965–84. The causal model consists of control variables—level of development and domestic investment in 1965—and a variety of independent variables drawn from major sociological theories of economic growth published during the last three decades. Multiple regression analysis shows that, net of the effects of the two control variables, the variables that have the strongest effect on economic growth rates are: (1) direct foreign investment, which has a negative effect; (2) the proportion of the population in military service; and (3) the primary school enrollment ratio, both of which have positive effects of economic, growth. On the other hand, variables drawn from some theories receive no empirical suport. The mass media of communications, ethno-linguistic heterogeneity, democracy and human rights, income inequality, and state-centric theory’s key variable—state strength—all fail to show any significant impact on economic growth rates when the control variables and the significant independent variables are held constant. The theoretical implications of these findings are discussed." .
<http://www.springernature.com/scigraph/things/articles/f4d2896d51116eab0f571d00df2221cc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We propose a two-stage probit model (TPM) to predict recovery rates. By the ordinal nature of the three categories of recovery rates: total loss, total recovery, and lying between the two extremes, we first use the ordered probit model to predict the category that a given debt belongs to among the three ones. Then, for the debt that is classified as lying between the two extremes, we use the probit transformation regression to predict its recovery rate. We use real data sets to support TPM. Our empirical results show that macroeconomic-, debt-, firm-, and industry-specific variables are all important in determining recovery rates. Using an expanding rolling window approach, our empirical results confirm that TPM has better and more robust out-of-sample performance than its alternatives, in the sense of yielding more accurate predicted recovery rates." .
<http://www.springernature.com/scigraph/things/articles/2ecc47e16f69914679b40169a6c48da0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article explores the policy and wealth consequences of alternative institutional arrangements through which fiscal policy interacts with monetary policy in a monetary union such as the EMU. The central issue of the article is the design of the appropriate monetary and fiscal institutions through a comparison of alternative arrangements to distribute power over monetary and fiscal authorities between the central authority of the union and the individual members of the union and evaluating their performance. The main results of this article reveal that delegation of the fiscal policy to a council of country representatives and the monetary policy to a council of governors is the appropriate institutional design to reduce inflation bias and better stabilize regional, idiosyncratic supply and demand shocks in a monetary union." .
<http://www.springernature.com/scigraph/things/articles/80eb851c5de6ae3d433bd999edd1d6fe> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Inflation targeting countries generally define the inflation objective in terms of the consumer price index. Studies in the academic literature, however, reach conflicting conclusions concerning which measure of inflation a central bank should target in a small open economy. This paper examines the properties of domestic, CPI, and real-exchange-rate-adjusted (REX) inflation targeting. In one class of open economy New Keynesian models there is an isomorphism between optimal policy in an open versus closed economy. In the type of model we consider, where the real exchange rate appears in the Phillips curve, this isomorphism breaks down; openness matters. REX inflation targeting restores the isomorphism but this may not be desirable. Instead, under domestic and CPI inflation targeting the exchange rate channel can be exploited to enhance the effects of monetary policy. Our results indicate that CPI inflation targeting delivers price stability across the three inflation objectives and will be desirable to a central bank with a high aversion to inflation instability. CPI inflation targeting also does a better job of stabilizing the real exchange rate and interest rate which is an advantage from the standpoint of financial stability. REX inflation targeting does well in achieving output stability and has an advantage if demand shocks are predominant. In general, the choice of the inflation objective affects the trade-offs between policy goals and thus policy choices and outcomes." .
<http://www.springernature.com/scigraph/things/articles/2414851a830d86369b808fcacff4f182> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The Kodaikanal sunspot data set covering the interval 1906–1987 is analyzed for differential rotation of sunspots of different sizes. As is known, smaller sunspots rotate faster than larger sunspots, and this result is verified in the analysis of this data set. These results agree well with the Mount Wilson sunspot results published earlier. The activity cycle dependence of sunspot rotation is studied. An increase in this rate at the minimum phase is seen, which has been reported earlier. It is demonstrated that this cycle variation is seen for sunspots in all size categories, which suggests that it is not a relative increase in the number of the faster-rotating small sunspots that causes the cycle dependence. These results are discussed as they may relate to subsurface dynamic properties of the Sun." .
<http://www.springernature.com/scigraph/things/articles/05c21faa2b8b5cfc41b95d68fc3779ed> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Uncertain finance has shown great significance in managing financial cases such as stock prices and currency options. Early researchers have put up some currency models to describe the foreign exchange rate. This paper proposes a mean-reverting currency model to describe the foreign change rate in the long term, and derives its European and American option pricing formulas. Besides, it gives some numerical examples to illustrate the formulas." .
<http://www.springernature.com/scigraph/things/articles/13c3cd29957d4a153bccebd21387efba> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, the empirical likelihood inferences for varying-coefficient semiparametric mixed-effects errors-in-variables models with longitudinal data are investigated. We construct the empirical log-likelihood ratio function for the fixed-effects parameters and the mean parameters of random-effects. The empirical log-likelihood ratio at the true parameters is proven to be asymptotically $$\\chi ^2_{q+r}$$ χq+r2 , where $$q$$ q and $$r$$ r are dimensions of the fixed and random effects respectively, and the corresponding confidence regions for them are then constructed. We also obtain the maximum empirical likelihood estimator of the parameters of interest, and prove it is the asymptotically normal under some suitable conditions. A simulation study and a real data application are undertaken to assess the finite sample performance of the proposed method." .
<http://www.springernature.com/scigraph/things/articles/6a66743896b5a8c2a1297c09766f8884> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The methods used in our two survey papers on real business cycles (King,Plosser and Rebelo, 1988a,b) are detailed in this document. Our presentationof the basic neoclassical model of growth and business cycles is broken intothree parts. First, we describe the model and its steady state, discussing:the structure of the environment including government policy rules; the natureof optimal individual decisions and the dynamic competitive equilibrium;technical restrictions to insure steady state growth; comparable restrictionson preferences and policy rules; stationary levels and ratios in the steadystate; and the nature of a transformed economy. Second, we detail methods forstudying near steady-state dynamics, considering: the linear approximationapproach; the rational expectations solution algorithm; the nature ofalternative solutions; and the special case of the fixed labor model. Third,we discuss the computation of simulations, moments and impulse responses.The objective of this appendix is to provide a detailed analysis of aneoclassical economy that is sufficiently flexible to permit: (a) exogenoussteady state growth; (b) distorting tax rules of various sorts; and (c) timevarying government spending. Although we do not focus on all of these issuesin the present discussion, other investigations in progress will utilize thisframework. The appendix is divided into three main parts. Part A describes theartificial economy under study and analyses its steady state, Part B developsmethods to study approximate dynamics around the steady state, and Part Cderives a set of formulas for generating population moments. This technicalappendix is designed to serve two functions. First, it develops thetheoretical material in Sections 2 and 3 of the main text in more depths.Second, it serves as a detailed guide to PC-MATLAB programs for computingdynamic equilibria, written by King and Rebelo in the Spring of 1987. Notationin programs and the technical appendix has been detailed as closely asfeasible." .
<http://www.springernature.com/scigraph/things/articles/bcabdfbec089a05369038a0450d713b4> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Parametric models are commonly used in frequency analysis of extreme hydrological events. To estimate extreme quantiles associated to high return periods, these models are not always appropriate. Therefore, estimators based on extreme value theory (EVT) are proposed in the literature. The Weissman estimator is one of the popular EVT-based semi-parametric estimators of extreme quantiles. In the present paper we propose a new family of EVT-based semi-parametric estimators of extreme quantiles. To built this new family of estimators, the basic idea consists in assigning the weights to the k observations being used. Numerical experiments on simulated data are performed and a case study is presented. Results show that the proposed estimators are smooth, stable, less sensitive, and less biased than Weissman estimator." .
<http://www.springernature.com/scigraph/things/articles/7c9f371fc9cef1c6781d4195094ebe45> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper attempts to explain shopping center choice behavior in the Peoria area using Attribute Salience, Determinant Attribute Analysis and Factor Analysis. Thirteen shopping center selection attributes were developed by interviewing about 3000 Peoria shoppers and a review of the relevant literature. Attribute Salience and the Determinant Attribute Analysis indicated almost the same attributes to be relatively important and determinant: availability of parking, quality of merchandise, variety of merchandise, distance from home and atmosphere of shopping area. The factor analysis model in all 4 cases extracted a merchandise-atmosphere index and a convenience index, indicating that the basic assumptions of the traditional gravitational models which use shopping center square footage and distance as proxy variables for utility and disutility should be reconsidered." .
<http://www.springernature.com/scigraph/things/articles/bdd4ff19d66595de261ee823bc995efe> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. This research note investigates the relationship between output and unemployment in Greece at a regional level through the implementation of Okuns’s law. Current practice is primarily restricted to the national level, and thus ignores the regional dimension of this relationship. To this end, we apply modern unit root test and cointegration techniques based on panel data settings. Using panel data is necessary because typical spans of economic time series are short, so the entire panel must be exploited in order to draw sharper inferences. The empirical results reveal that Okun’s law can be confirmed for six out of the 13 regions we examine." .
<http://www.springernature.com/scigraph/things/articles/e3a31c0629fdcb435815d87401c20978> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The Monetary Conditions Index is a composite index of interest and exchange rates frequently used by (central) banks, the IMF, and the OECD. This paper considers the benefits and weaknesses of the MCI in the light of large macroeconometric models. It follows that the impact of the exchange rate on GDP relative to the impact of the short-term interest rate is substantially lower under a monetary union. For most countries, including a long-term interest rate in the MCI only affects the level of the MCI and not its turning points." .
<http://www.springernature.com/scigraph/things/articles/8306375e98a81450fe1dfce3b6e70978> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In geostatistics, the approximation of the spatial dependence structure of a process, through the estimation of the variogram or the covariogram of the variable under consideration, is an important issue. In this work, under a general spatial model, including a mean or trend function, and without assuming any parametric model for this function and for the dependence structure of the process, a general nonparametric estimator of the variogram is proposed. The new approach consists in applying an iterative algorithm, using the residuals obtained from a nonparametric local linear estimation of the trend function, jointly with a correction of the bias due to the use of these residuals. A simulation study checks the validity of the presented approaches in practice. The broad applicability of the procedures is demonstrated on a real data set." .
<http://www.springernature.com/scigraph/things/articles/4676c1d7c1c54e97ea17a3d634082041> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The present study quantifies the importance of price risk and irreversibility for investment in a corn stover-based cellulosic biofuel plant. Using a real-option model, we recover prices of gasoline that would trigger entry into the market and compare it to breakeven price. Our analysis shows that the price premium (above breakeven) required by investors to enter the market due to risk is substantial. Managerial flexibility (embedded in the option of mothballing and reactivating the plant) does not sensibly reduce the entry premium. Results also show that price volatility may greatly reduce plants’ responsiveness to gasoline prices and decrease supply elasticity. In combination, results suggest that (1) policies supporting second-generation biofuels may have fell short of their targets because of their failure to alleviate price uncertainty and (2) the use of price-based instruments such as reverse auctions, either in isolation or in combination with mandates, may be warranted." .
<http://www.springernature.com/scigraph/things/articles/9cb7d1cdfd4f19de897bcbce20ed5fd2> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Summary This econometric model is on an annual basis and has been estimated for the period 1953–1969 using the two-stages least-squares method. All behavioral equations are based on a partial adjustment mechanism. The behavior of the public is expressed by the demand for currency, demand deposits and time-and-savings deposits. The behavior of the banking system is described by a required reserves identity and by the demand for excess reserves, borrowed reserves and net foreign assets. The main instruments of monetary policy under the direct control of the central bank are explicitly included in the analysis. Some impact multipliers and elasticities are shown." .
<http://www.springernature.com/scigraph/things/articles/6bb16f9fb89e3b0a673bb809a95e5b56> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The annual temperatures recorded for the last two centuries in fifteen european stations around the Alps are analyzed. They show a global warming whose growth rate is not however constant in time. An analysis based on linear Arima models does not provide accurate results. Thus, we propose threshold nonlinear nonstationary models based on several regimes both in time and in levels. Such models fit all series satisfactorily, allow a closer description of the temperature changes evolution, and help to discover the essential differences in the behavior of the different stations." .
<http://www.springernature.com/scigraph/things/articles/7dcc856b54f0611bbe8f327ea3b2c8dc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This article attempts to investigate the issue of asymmetries in the transmission of shocks to input prices and exchange rate onto the wholesale and retail price of gasoline respectively. For this purpose, we utilise the error-correction methodology in the Greek gasoline market. The sample consists of monthly data covering the period of January 1988 to June 2006. We also try to analyse by using impulse response functions the effect of competition on the dynamic adjustment of gasoline price to which has been paid scant attention in the past. The results favour the common perception that retail gasoline prices respond asymmetrically to cost increases and decreases both in the long and the short-run. At the wholesale segment, there is a symmetric response of the spot prices of gasoline towards the adjustment to the short-run responses of the exchange rate. Lastly, after the deregulation, wholesale prices of gasoline tend to gradually restore equilibrium triggered by a price shock compared to the regulated period." .
<http://www.springernature.com/scigraph/things/articles/79cb89272c70e987dcbca76cf8e6a127> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We examine the effect of nutrient prices and other socio-economic and health factors on the Body Mass Index (BMI) of Canadians using the Canadian Community Health Survey (CCHS). The CCHS data does not include information on nutrition intake, and so the price of fat, carbohydrates and protein are included to capture the effects of diet on BMI. The results indicate that changes in nutrient prices in the model have statistically significant impacts on BMI and the direction of the impacts corresponds to hypotheses from the nutrition literature. However, all estimates are inelastic so that the effect of fat taxes or thin subsidies is small. The results also indicate that education is negatively related and income is positively related to BMI." .
<http://www.springernature.com/scigraph/things/articles/a4e84843690440b20376986d5617beec> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper examines the transmission of the 2008 US financial crisis to four Latin American stock markets using daily stock returns from 2006 to 2010, analyzing before, during and after the 2008 financial crisis. The empirical evidence presents a financial contagion by showing persistently higher and more volatile pair-wise conditional correlations during the crisis period. This indicates there are structural changes in mean and volatility of the correlation coefficients due to the 2008 financial crisis in Latin American markets. The results here could be useful in international portfolio diversification decision-making in Latin American region. In addition, the predicting the volatility in different markets could be a useful input for reducing financial instability in crisis episodes to policy makers." .
<http://www.springernature.com/scigraph/things/articles/99fde2f7b01f251824f6803ae8979420> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The Gini concentration coefficient is considered to be the best synthetic inequality measure and is widely used in economic research. In this paper, we present its decomposition by factor components with an application to income distributions in Poland. Income inequality measures proposed by Gini, Zenga and Bonferroni are calculated for different socio-economic groups based on their exclusive or primary source of maintenance. For theoretical income distribution, the Dagum type-I model was used. The basis for the calculations was the individual data coming from the Household Budgets Survey conducted quarterly by the Polish Central Statistical Office. Using the decomposition of inequality by source, we were able to examine how changes in particular income components affected overall inequality." .
<http://www.springernature.com/scigraph/things/articles/1a5a6ad964fa07b835df2c49008ab8cc> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Value at Risk (VaR) is a basic and very useful tool in measuring market risks. Numerous VaR models have been proposed in literature. Therefore, it is of great interest to evaluate the efficiency of these models, and to select the most appropriate one. In this paper, we shall propose to use the empirical likelihood approach to evaluate these models. Simulation results and real life examples show that the empirical likelihood method is more powerful and more robust than some of the asymptotic method available in literature." .
<http://www.springernature.com/scigraph/things/articles/80efc76fe6e6d44f36cdfd6dce0243c0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper asks whether educational mismatches can account for the positive association between education and wage inequality found in the data. We use two different data sources, the European Community Household Panel and the Portuguese Labour Force Survey, and consider several types of mismatch, including overqualification, underqualification and skills mismatch. We test our hypothesis using two different measurement methods, the ‘statistical’ and the ‘subjective’ approach. The results are robust to the different choices and unambiguously show that the positive effect of education on wage inequality is not due to the prevalence of educational mismatches in the labour market." .
<http://www.springernature.com/scigraph/things/articles/34ce4350649942632408fb8cfee95213> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, we formulate the problem of early classification of time series data, which is important in some time-sensitive applications such as health informatics. We introduce a novel concept of MPL (minimum prediction length) and develop ECTS (early classification on time series), an effective 1-nearest neighbor classification method. ECTS makes early predictions and at the same time retains the accuracy comparable with that of a 1NN classifier using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classification is effective." .
<http://www.springernature.com/scigraph/things/articles/1fd287ea78a42fe4d5cc7b3288461793> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study evaluates 10-year US government bond yield forecasts and three-month US Treasury bill rate forecasts for the period between October 1989 and December 2004. In total, 136 forecast time series with approximately 13,800 forecast data were scrutinized, making this the most extensive analysis of interest rate forecasts to date. Not one of the forecast time series proved to be unbiased. In the majority of cases, information from the past was not efficiently integrated into the forecasts. The sign accuracy is significantly better than random walk forecasts in only a very few of the forecast time series. The modified Diebold–Mariano test for forecast encompassing reveals that the information content of most of the forecast time series is lower than that of the naïve forecasts, the simple ARIMA models, the implicit forward rates, or average interest rate expectations. The forecasting process is dominated by the present and past market situation." .
<http://www.springernature.com/scigraph/things/articles/adddffa91598cf8afad2d93b0ca43d43> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper analyzes wage elasticities using a panel dataset of 2800 large Belgian firms over the period 1987–1994. We explore various functional forms and find that the short-run wage elasticity varies between −0.37 and −0.65, while the long-run elasticity is robustly estimated to be larger than 1 in absolute value. These results are striking for they are much higher than those reported in previous studies using macroeconomic time-series data. This suggests that labour costs are more important in determining the demand for labour than initially was believed." .
<http://www.springernature.com/scigraph/things/articles/3ccee3d0096243e060a47db540924b44> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In several fields of Geophysics, such as Hydrology, Meteorology or Oceanography, it is often useful to generate random fields, displaying the same variabilitity as the observed variables. Usually, these synthetic data are used as forcing fields into numerical models, to test the sensitivity of their outputs to the variability of the inputs. Examples can be found in subsurface or surface Hydrology and in Meteorology with General Circulation Models (GCM). Different techniques have already been proposed, often based on the spectral representation of the random process, with, usually, assumptions of stationarity. This paper suggests that Empirical Orthogonal Function (EOF) analysis, which leads to the decomposition of the covariance kernel on the set of its eigen-functions, is a possible answer to this problem. The convergence and accuracy of the method are shown to depend mainly on the number of EOFs retained in the expansion of the covariance kemel. This result is confirmed by a comparison with the turning band method and a matrix technique. Furthermore, a synthetic example of non-homogencous fields shows the interest of EOF analysis in the direct simulation of such fields." .
<http://www.springernature.com/scigraph/things/articles/ffbed3812ca3733111a20af3942bf2e1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract A method is suggested for the estimation of autonomous and induced effects of cost factors on the rate of inflation. It involves calculating total effects from a national income accounts identity and estimating autonomous effects from a price equation and induced effects as the difference between total and autonomous effects. The significance of induced effects may be tested. Applying the above method to Greek data we find that induced effects are significant in the cases of unit labour costs and the other factors captured by the constant term of the price equation." .
<http://www.springernature.com/scigraph/things/articles/ad1b0eed3df238e84f29ece7aa740716> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The size of the Fed’s balance sheet has almost quadrupled since 2007, and the composition of the balance sheet has changed in important ways, with regard to both assets and liabilities. This short paper asseses the implications for how monetary policy works, and the entailed risks. The size of the balance sheet and its composition may not matter economically, but there are significant political risks. The political risk-taking may make monetary policy choices more difficult than they would otherwise be." .
<http://www.springernature.com/scigraph/things/articles/957e5e0467df138ef1f761b0196b6fdf> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract: The concept of symbolic dynamics, entropy and complexity measures has been widely utilized for the analysis of measured time series. However, little attention as been devoted to investigate the effects of choosing different partitions to obtain the coarse-grained symbolic sequences. Because the theoretical concepts of generating partitions mostly fail in the case of empirical data, one commonly introduces a homogeneous partition which ensures roughly equidistributed symbols. We will show that such a choice may lead to spurious results for the estimated entropy and will not fully reveal the randomness of the sequence." .
<http://www.springernature.com/scigraph/things/articles/169595e12c132910b7180448c4a40aed> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Since 2002, the Croatian social health insurance system has undergone substantial reforms, initiated for the most part with the aim of addressing the perpetual financial deficits of the state health insurance fund. While the reforms focussed heavily on increasing the inflow of private funds into the health care system, underlying inefficiencies contributing significantly to poor financial performance have been largely ignored. Furthermore, contrary to demographic trends and developments in social health insurance schemes in other countries, funding health care became even more dependent on its main collection mechanism—payroll tax—and consequently on the employment ratio and wage level. Little effort has been made to diversify the revenue base or to increase the efficiency of revenue collection. Like other countries, Croatia is facing difficulties in adjusting its ‘Bismarck’ system to its changing demographic and socioeconomic context. Instead of targetting a comprehensive effort at improving revenue collection and limitating unnecessary expenditure and system inefficiencies, simplified approaches to balance the budget have been implemented at a high price to users and with limited effect. As a result, the Croatian health insurance system now offers a lower level of financial protection, while still facing the problem of spending more than can be collected through the current mix of revenue collection mechanisms. The authors suggest that, in order to meet the sustainability requirement of the health financing system, measures affecting both revenue and expenditure should be considered and implemented. On the revenue collection side, the Croatian government must make further efforts to improve collection from the informally employed to broaden the base of contributing members; equally important is the diversification of revenue sources by increasing transfers from general taxation revenues. On the expenditure side, exploring inefficiencies of the delivery system can be delayed no longer, and the introduction of effective cost-control mechanisms and financial discipline would seem to be unavoidable." .
<http://www.springernature.com/scigraph/things/articles/e9a23fde8d3981822559e2b70fe6c3fa> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper discusses the possible causal relationships and empirical associations between globalization and growth, growth and poverty reduction, and, finally, globalization and poverty reduction. We argue that globalization can contribute much to poverty reduction both directly and by accelerating growth. Second, the contributions of redistributive policies are very likely to be less than the contribution of greater access to markets, more competitive insurance and financial markets, and improved institutions to poverty reduction. The potential effect of greater international integration on poverty reduction, however, is limited by domestic policy failures in developing countries and also by continued protectionism, particularly in developed countries." .
<http://www.springernature.com/scigraph/things/articles/63ed3f0fdaabac5f57bef39dc2bd4258> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract We discuss the scientific contribution of Battaglia and Protopapas’ paper concerning the debate on global warming supported by an extensive analysis of temperature time series in the Alpine region. In the work, Authors use several exploratory and modelling tools for assessing and discriminating the presence of different patterns in the data. We add some general and specific considerations mainly devoted to the modelling stage of their analysis." .
<http://www.springernature.com/scigraph/things/articles/715e0350118f0936e1dc0f87936fc565> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This research aims at examining the application of support vector machines (SVMs) to the task of forecasting the weekly change in the Madrid IBEX-35 stock index. The data cover the period between 10/18/1990 and 10/29/2010. A trading simulation is implemented so that statistical efficiency is complemented by measures of economic performance. The inputs retained are traditional technical trading rules commonly used in the analysis of equity markets such as the Relative Strength Index (RSI) and the Moving Average Convergence Divergence (MACD) decision rules. The SVMs with given values of the RSI and MACD indicators are used in order to determine the best situations to buy or sell the market. The two outputs of the SVM are both the direction of the market and the probability attached to each forecast market move. The best result that it has been achieved is a hit ratio of 100% using the SVM classifier under some chosen risk-aversion parameters. However, these results are obtained analyzing recent periods rather than using all the dataset information." .
<http://www.springernature.com/scigraph/things/articles/09b867cbc182ddaf198a5a377029a9c6> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Firms in durable good product markets face incentives to intertemporally price discriminate, by setting high initial prices to sell to consumers with the highest willingness to pay, and cutting prices thereafter to appeal to those with lower willingness to pay. A critical determinant of the profitability of such pricing policies is the extent to which consumers anticipate future price declines, and delay purchases. I develop a framework to investigate empirically the optimal pricing over time of a firm selling a durable-good product to such strategic consumers. Prices in the model are equilibrium outcomes of a game played between forward-looking consumers who strategically delay purchases to avail of lower prices in the future, and a forward-looking firm that takes this consumer behavior into account in formulating its optimal pricing policy. The model outlines first, a dynamic model of demand incorporating forward-looking consumer behavior, and second, an algorithm to compute the optimal dynamic sequence of prices given these demand estimates. The model is solved using numerical dynamic programming techniques. I present an empirical application to the market for video-games in the US. The results indicate that consumer forward-looking behavior has a significant effect on optimal pricing of games in the industry. Simulations reveal that the profit losses of ignoring forward-looking behavior by consumers are large and economically significant, and suggest that market research that provides information regarding the extent of discounting by consumers is valuable to video-game firms." .
<http://www.springernature.com/scigraph/things/articles/de97a79c5f77d4b71cef6c563791b096> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In the present study, the short-term periodicities in the daily data of the sunspot numbers and areas are investigated separately for the full disk, northern, and southern hemispheres during Solar Cycle 23 for a time interval from 1 January 2003 to 30 November 2007 corresponding to the descending and minimum phase of the cycle. The wavelet power spectrum technique exhibited a number of quasi-periodic oscillations in all the datasets. In the high frequency range, we find a prominent period of 22 – 35 days in both sunspot indicators. Other quasi-periods in the range of 40 – 60, 70 – 90, 110 – 130, 140 – 160, and 220 – 240 days are detected in the sunspot number time series in different hemispheres at different time intervals. In the sunspot area data, quasi-periods in the range of 50 – 80, 90 – 110, 115 – 130, 140 – 155, 160 – 190, and about 230 days were noted in different hemispheres within the time period of analysis. The present investigation shows that the well-known “Rieger periodicity” of 150 – 160 days reappears during the descending phase of Solar Cycle 23, but this is prominent mainly in the southern part of the Sun. Possible explanations of these observed periodicities are delivered on the basis of earlier results detected in photospheric magnetic field time series (Knaack, Stenflo, and Berdyugina in Astron. Astrophys. 438, 1067, 2005) and solar r-mode oscillations." .
<http://www.springernature.com/scigraph/things/articles/ef128804cdbe47d0cf7dbc7e763ce44b> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper presents the integration of principal component analysis (PCA) and adaptive network-based fuzzy inference system (ANFIS) to assess the impact of bad loans on technical efficiency of banks. Bad loans or non-performing loans (NPLs) include past due loans, bankrupt and quasi-bankrupt assets and doubtful assets. Bad loans are considered as a bad output for calculation of the technical efficiency through PCA. ANFIS is used to model the relationship between bad loans and technical efficiency. ANFIS modeling is used to capture the nonlinearity and fuzziness existed in the modeling environment. In the ANFIS model, technical efficiency is considered as the output which is modeled with respect to bad loans, profit and costs. The results of the proposed model are illustrated through a case study in Iranian governmental banks. It is evidenced that the effects of bad loans on technical efficiency of banks are not linear but a nonlinear negative impact." .
<http://www.springernature.com/scigraph/things/articles/f1267940f54aaca0210ec4abe73650b8> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Omitted variables and measurement errors in explanatory variables frequently occur in hedonic price models. Ignoring these problems leads to biased estimators. In this paper, we develop a constrained autoregression–structural equation model (ASEM) to handle both types of problems. Standard panel data models to handle omitted variables bias are based on the assumption that the omitted variables are time-invariant. ASEM allows handling of both time-varying and time-invariant omitted variables by constrained autoregression. In the case of measurement error, standard approaches require additional external information which is usually difficult to obtain. ASEM exploits the fact that panel data are repeatedly measured which allows decomposing the variance of a variable into the true variance and the variance due to measurement error. We apply ASEM to estimate a hedonic housing model for urban Indonesia. To get insight into the consequences of measurement error and omitted variables, we compare the ASEM estimates with the outcomes of (1) a standard SEM, which does not account for omitted variables, (2) a constrained autoregression model, which does not account for measurement error, and (3) a fixed effects hedonic model, which ignores measurement error and time-varying omitted variables. The differences between the ASEM estimates and the outcomes of the three alternative approaches are substantial." .
<http://www.springernature.com/scigraph/things/articles/204672ae88aed23f994af268a9382fff> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract The reversibility of sequential economic choices concerning production and consumption is addressed. A geometric approach to substitution effects and output/income effects is set forth in terms of vector fields on bundle space. By means of suitable fixing relations the 0-homogeneity of such problems can be circumvented, so as to define global parametrizations of effects, for which Lie brackets measure the departure from commutativity. A couple of propositions are established, assessing the benchmark relevance of homothetic models. Application to Farrell decompositions, as tailored by Bogetoft et al. (Eur J Oper Res 168:450–462, 2006), results in complete agreement with the results found by such Authors. The theoretical relevance of the approach is thoroughly discussed." .
<http://www.springernature.com/scigraph/things/articles/d86f2089e076a6fea788a1b05fe3ffeb> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Due to the nonlinear feature of a ozone process, regression based models such as the autoregressive models with an exogenous vector process (ARX) suffer from persistent diurnal behaviors in residuals that cause systematic over-predictions and under-predictions and fail to make accurate multi-step forecasts. In this article we present a simple class of the functional coefficient ARX (FARX) model which allows the regression coefficients to vary as a function of another variable. As a special case of the FARX model, we investigate the threshold ARX (TARX) model of Tong [Lecture notes in Statistics, Springer-Verlag, Berlin, 1983; Nonlinear time series: a dynamics system approach, Oxford University Press, Oxford, 1990] which separates the ARX model in terms of a variable called the threshold variable. In this study we use time of day as the threshold variable. The TARX model can be used directly for ozone forecasts; however, investigation of the estimated coefficients over the threshold regimes suggests polynomial coefficient functions in the FARX model. This provides a parsimonious model without deteriorating the forecast performance and successfully captures the diurnal nonstationarity in ozone data. A general linear F-test is used to test varying coefficients and the portmanteau tests, based on the autocorrelation and partial autocorrelation of fitted residuals, are used to test error autocorrelations. The proposed models were applied to a 2 year dataset of hourly ozone concentrations obtained in downtown Cincinnati, OH, USA. For the exogenous processes, outdoor temperature, wind speed, and wind direction were used. The results showed that both TARX and FARX models substantially improve one-day-ahead forecasts and remove the diurnal pattern in residuals for the cases considered." .
<http://www.springernature.com/scigraph/things/articles/767193fd825f9f1f3a952ce14c6c1e4a> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper, the effect of the system parameters on the flutter of a curved skin panel forced by a supersonic/hypersonic unsteady flow is numerically investigated. The aeroelastic model investigated includes the third-order piston theory aerodynamics for modeling the flow-induced forces and the Von Kármán non-linear strain-displacement relation in conjunction with the Kirchhoff plate hypothesis for the panel structural modeling. Structural non-linearities are considered and are due to the non-linear coupling between out-of-plane bending and in-plane stretching. The effects of thermal degradation and Kelvin’s model of structural damping independent on time and temperature are also considered. The aero-thermo-elastic governing equations are developed from the geometrically imperfect non-linear theory of infinitely long two-dimensional curved panels. Computational analysis and discussion of the finding along with pertinent conclusions are presented." .
<http://www.springernature.com/scigraph/things/articles/cdd96aadc1d703829b19f6198a25584e> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Spatial and temporal precipitation variability in Chhattisgarh State in India was examined by using monthly precipitation data for 102 years (1901–2002) from 16 stations. The homogeneity of precipitation data was evaluated by the double-mass curve approach and the presence of serial correlation by lag-1 autocorrelation coefficient. Linear regression analysis, the conventional Mann–Kendall (MK) test, and Spearman’s rho were employed to identify trends and Sen’s slope to estimate the slope of trend line. The coefficient of variation (CV) was used to analyze precipitation variability. Spatial interpolation was done by a Kriging process using ArcGIS 9.3. Results of both parametric and non-parametric tests and trend tests showed that at 5 % significance level, annual precipitation exhibited a decreasing trend at all stations except Bilaspur and Dantewada. For both annual and monsoon precipitation, Sen’s test showed a decreasing trend for all stations, except Bilaspur and Dantewada. The highest percentage of variability was observed in winter precipitation (88.75 %) and minimum percentage variability in annual series (14.01 %) over the 102-year periods." .
<http://www.springernature.com/scigraph/things/articles/3514b43b41151ee4c89a7deb8ba175a9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. Two different chaotic time series analysis methods – the correlation dimension and nonlinear forecasting – are introduced and then used to process the interspike intervals (ISI) of the action potential trains propagated along a single nerve fiber of the anesthetized rat. From the results, the conclusion is drawn that compared with the correlation dimension, nonlinear forecasting is more efficient and robust for chaotic ISI time series analysis in a noisy environment. Moreover, the evolution of the correlation coefficient curves calculated from nonlinear forecasting can qualitatively give a better reflection of the unpredictability of the system's future behavior and is in good agreement with the values of the largest Lyapunov exponent that quantitatively measures the degree of chaos." .
<http://www.springernature.com/scigraph/things/articles/681f0a39f2f2c6d559b311a1105c3127> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Are Islamic banks inherently more stable than conventional banks? We address this question by applying a survival analysis based on the Cox proportional hazard model to a comprehensive sample of 421 banks in 20 Middle and Far Eastern countries from 1995 to 2010. By comparing the failure risk for both bank types, we find that Islamic banks have a significantly lower risk of failure than that of their conventional peers. This lower risk is based both unconditionally and conditionally on bank-specific (microeconomic) variables as well as macroeconomic and market structure variables. Our findings indicate that the design and implementation of early warning systems for bank failure should recognize the distinct risk profiles of the two bank types." .
<http://www.springernature.com/scigraph/things/articles/a4d99547e5dd51d6564b44652ae57007> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Numerous definitions of droughts which are based on different climatological time series have been in use. In this paper, the development of drought indicators by using different time series is described. These drought indicators were developed for use by the Department of Natural Resources in the State of Indiana, U.S.A. The second part of the study deals with an analysis of the consistency of results obtained by using different time series, in order to select two or three of the commonly available series for drought analysis. Past drought data are used to test the performance of the drought indicators. As a result of this study, three month precipitation, monthly river flow and the Palmer Hydrologic Drought Index series are recommended for operational use." .
<http://www.springernature.com/scigraph/things/articles/54e6d52559a68c5dfdeed02f678e24d1> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. We investigate high frequency price dynamics in foreign exchange market using data from Reuters information system (the dataset has been provided to us by Olsen and Associates). In our analysis we show that a naïve approach to the definition of price (for example using the spot mid price) may lead to wrong conclusions on price behavior as for example the presence of short term correlations for returns. For this purpose we introduce an algorithm which only uses the non arbitrage principle to estimate real prices from the spot ones. The new definition leads to returns which are not affected by spurious correlations. Furthermore, any apparent information (defined by using Shannon entropy) contained in the data disappears." .
<http://www.springernature.com/scigraph/things/articles/c349b99148f75ecd763fdf4ac3a7b79f> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract With contemporary data collection capacity, data sets containing large numbers of different multivariate time series relating to a common entity (e.g., fMRI, financial stocks) are becoming more prevalent. One pervasive question is whether or not there are patterns or groups of series within the larger data set (e.g., disease patterns in brain scans, mining stocks may be internally similar but themselves may be distinct from banking stocks). There is a relatively large body of literature centered on clustering methods for univariate and multivariate time series, though most do not utilize the time dependencies inherent to time series. This paper develops an exploratory data methodology which in addition to the time dependencies, utilizes the dependency information between S series themselves as well as the dependency information between p variables within the series simultaneously while still retaining the distinctiveness of the two types of variables. This is achieved by combining the principles of both canonical correlation analysis and principal component analysis for time series to obtain a new type of covariance/correlation matrix for a principal component analysis to produce a so-called “principal component time series”. The results are illustrated on two data sets." .
<http://www.springernature.com/scigraph/things/articles/d40cd56f24f24081935d3c977a1d05b9> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper estimates a forward-looking reaction function with time-varying parameters to examine changes in the Brazilian monetary policy under the inflation-targeting regime. As the monetary policy rule has endogenous regressors, the conventional Kalman filter cannot be applied. Thus, the two-step procedure proposed by Kim and Nelson (J Monet Econ 53:1949–1966, 2006) is used for consistent estimation of the hyper-parameters of the model. The results indicate that the reaction function parameters of the Central Bank of Brazil are time-varying and that the regressors of that function are endogenous. Besides, we observed that: (i) the monetary policy interest rate (Selic rate) responses to current inflation and the inflationary expectations present considerable changes and have diminished with the passing of time; (ii) since mid-2010, policy rule has violated the Taylor principle; (iii) the implicit target for the Selic interest rate has shown a decline over time; and (iv) the degree of interest rate smoothing has shown a relative stability. Finally, the policy instrument response to the output gap presents an increasing trend over the 2010–2011 period." .
<http://www.springernature.com/scigraph/things/articles/421889aa80614fa5d755bc14186c62f0> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This paper studies monetary policy committee transparency (MPCT) based on a new index that measures central bankers’ educational and professional backgrounds as disclosed through central bank websites. Based on a novel cross-sectional data set covering 75 central banks, we investigate the determinants of MPCT as well as its economic consequences. We find that past inflation, institutional indicators, and monetary policy strategy are important determinants of MPCT. MPCT has a robust and significantly negative impact on inflation variability and inflation expectations, even after controlling for important macroeconomic variables and institutional transparency, as well as instrumenting MPCT in various ways. MPCT can be both a complement to and a substitute for institutional transparency." .
<http://www.springernature.com/scigraph/things/articles/765cec2ad9dd6fc59731a6ebecc43706> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract This study examines the dynamic relationships between product and international diversification, keiretsu financing, and economic performance of the listed firms in Japan’s textile industry. Panel data analysis shows that the performance effects of those strategic factors are contingent on macroeconomic environments, rather than showing consistent relationships. The potentially positive or negative effects of particular diversification strategies and keiretsu financing are neutralized in the munificent environments, as exogenous macroeconomic factors overwhelm endogenous decision-making by the management. In the scarce setting, by contrast, it is those strategic factors that influence financial outcomes. Keiretsu financing moderates the relationship between international diversification strategy and profitability positively only during times of economic scarcity." .
<http://www.springernature.com/scigraph/things/articles/78e1da4b46aba1ea0140cd7ab45f5af3> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Much of the current interest in pollen time series analysis is motivated by the possibility that pollen series arise from low-dimensional chaotic systems. If this is the case, short-range prediction using nonlinear modeling is justified and would produce high-quality forecasts that could be useful in providing pollen alerts to allergy sufferers. To date, contradictory reports about the characterization of the dynamics of pollen series can be found in the literature. Pollen series have been alternatively described as featuring and not featuring deterministic chaotic behavior. We showed that the choice of test for detection of deterministic chaos in pollen series is difficult because pollen series exhibit $$1/f^{\\alpha }$$ power spectra. This is a characteristic that is also produced by colored noise series, which mimic deterministic chaos in most tests. We proposed to apply the Ikeguchi–Aihara test to properly detect the presence of deterministic chaos in pollen series. We examined the dynamics of cedar (Cryptomeria japonica) hourly pollen series by means of the Ikeguchi–Aihara test and concluded that these pollen series cannot be described as low-dimensional deterministic chaos. Therefore, the application of low-dimensional chaotic deterministic models to the prediction of short-range pollen concentration will not result in high-accuracy pollen forecasts even though these models may provide useful forecasts for certain applications. We believe that our conclusion can be generalized to pollen series from other wind-pollinated plant species, as wind speed, the forcing parameter of the pollen emission and transport, is best described as a nondeterministic series that originates in the high dimensionality of the atmosphere." .
<http://www.springernature.com/scigraph/things/articles/1fcc9627761d91dc2332f744b1091a1d> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract In this paper the thought on the uniform convergence of an empirical Bayes estimator or linear empirical Bayes (l.e.B.) estimator is advanced. Under two different models the l.e.B. estimators of the parameter are constructed respectively. It is proved that the convergence rates and uniform convergence rates of these l.e.B. estimators are all one with respect to the corresponding prior families. It is shown that the uniform convergence rate one is the best, under mild assumptions imposed on the conditional density of the sample." .
<http://www.springernature.com/scigraph/things/articles/05db324de51a9f9027ddada458173846> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract. In this paper we discuss the issue of when oligopolization in collective rent-seeking occurs, that is, when some groups retire from rent-seeking. A complete characterization of the pure-strategy Nash equilibrium in a collective rent-seeking game among m (≥2) heterogeneous groups is derived. The conditions of oligopolization are derived by using this result and related to the works of Nitzan [9, 10] and Hillman and Riley [3]. Also, the subgame perfect equilibrium of a simple two-stage collective rent-seeking game (Lee [7]) is fully characterized. In this game, it is confirmed that no group retires from the contest in the second stage and oligopolization never occurs. An example of the two-stage collective rent-seeking game with monitoring costs is devised to show the possibilities of oligopolization." .
<http://www.springernature.com/scigraph/things/articles/26b498521c544a279f0c9918801cf3b7> <http://www.springernature.com/scigraph/ontologies/core/abstract> "Abstract Contingent choice surveys can provide national park managers rich information to help inform management decisions, but they have almost never been used in this context. The surveys can be integrated easily into multiple stages of the existing National Park Service planning process and can foster interdisciplinarity. They yield estimates of monetary and nonmonetary benefits created by park resources, including benefits derived from both recreation and preservation. Many alternative management scenarios can be explored efficiently. Recent innovations in the design and statistical analysis of contingent choice surveys have increased their accuracy and flexibility. This paper describes why contingent choice surveys are useful for park management and how they can fit into current management policies. It then describes contingent choice surveys and the econometric techniques used to analyze them, presenting two examples as illustrations." .
