Abstract Latent Dirichlet allocation (LDA) is a popular topic modeling method which has found many multimedia applications, such as motion analysis and image categorization. Communication cost is one of the main bottlenecks for large-scale parallel learning of LDA. To reduce communication cost, we introduce Zipfâ€™s law and propose novel parallel LDA algorithms that communicate only partial important information at each learning iteration. The proposed algorithms are much more efficient than the current state-of-the-art algorithms in both communication and computation costs. Extensive experiments on large-scale data sets demonstrate that our algorithms can greatly reduce communication and computation costs to achieve a better scalability.
computation         0.9873299336297611^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Computation           

law                           0.9990665815682881^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Law                   

Latent Dirichlet allocation   1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Latent_Dirichlet_allocation

computation                   0.9873299336297611^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Computation           

communication                 0.7936084513946388^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Communication         

LDA                           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Latent_Dirichlet_allocation

algorithms                    0.9999999994938662^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

data sets                     1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Data_set              

iteration                     0.8933293281256712^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Iteration             

communication                 0.7936084513946388^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Communication         

topic modeling                1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Topic_model           

multimedia                    0.9999786286429946^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Multimedia            

Zipf                          0.9999999999999432^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Zipf's_law            

algorithms                    0.9999999994938662^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

LDA                           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Latent_Dirichlet_allocation

bottlenecks                   0.9999999974420462^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Bottleneck            

motion analysis               0.9999999999995453^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Motion_analysis       

algorithms                    0.9999999994938662^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

LDA                           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Latent_Dirichlet_allocation

communication                 0.7936084513946388^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Communication         

algorithms                    0.9999999994938662^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

scalability                   1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Scalability           

