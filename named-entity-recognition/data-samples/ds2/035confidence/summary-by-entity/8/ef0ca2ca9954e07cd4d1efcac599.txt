Abstract Givenn data points ind-dimensional space, nearest-neighbor searching involves determining the nearest of these data points to a given query point. Most averagecase analyses of nearest-neighbor searching algorithms are made under the simplifying assumption thatd is fixed and thatn is so large relative tod thatboundary effects can be ignored. This means that for any query point the statistical distribution of the data points surrounding it is independent of the location of the query point. However, in many applications of nearest-neighbor searching (such as data compression by vector quantization) this assumption is not met, since the number of data pointsn grows roughly as 2 d .Largely for this reason, the actual performances of many nearest-neighbor algorithms tend to be much better than their theoretical analyses would suggest. We present evidence of why this is the case. We provide an accurate analysis of the number of cells visited in nearest-neighbor searching by the bucketing andk-d tree algorithms. We assumem dpoints uniformly distributed in dimensiond, wherem is a fixed integer ≥2. Further, we assume that distances are measured in theL ∞ metric. Our analysis is tight in the limit asd approaches infinity. Empirical evidence is presented showing that the analysis applies even in low dimensions.
algorithms          0.9999999999957936^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

metric                        0.9977049659124335^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Metric_space          

tod                           0.9999999999798774^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Fox                   

cells                         0.9996678683512822^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Cell_(biology)        

algorithms                    0.9999999999957936^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

integer                       0.9999999999821512^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Integer               

statistical distribution      0.9999999941700253^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Probability_distribution

asd                           0.9914236971763544^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Autism_spectrum       

tree                          0.999986978721121^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Tree_(data_structure) 

vector quantization           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Vector_quantization   

uniformly distributed         0.9800163267062201^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Uniform_distribution_(continuous)

data compression              0.9999999999467946^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Data_compression      

independent                   1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Independence_(probability_theory)

infinity                      0.9999521404975198^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Infinity              

algorithms                    0.9999999999957936^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Algorithm             

Empirical evidence            1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Empirical_evidence    

