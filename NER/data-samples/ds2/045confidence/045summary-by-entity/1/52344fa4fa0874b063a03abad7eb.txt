Abstract Due to its simplicity and efficiency, the Barzilai and Borwein (BB) gradient method has received various attentions in different fields. This paper presents a new analysis of the BB method for two-dimensional strictly convex quadratic functions. The analysis begins with the assumption that the gradient norms at the first two iterations are fixed. We show that there is a superlinear convergence step in at most three consecutive steps. Meanwhile, we provide a better convergence relation for the BB method. The influence of the starting point and the condition number to the convergence rate is comprehensively addressed.
condition number    1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Condition_number      

convergence                   0.9981621931356044^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Rate_of_convergence   

gradient                      0.9890147805926698^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Gradient_descent      

gradient                      0.9890147805926698^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Gradient_descent      

convergence                   0.9981621931356044^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Rate_of_convergence   

convex                        0.9086383621279429^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Convex_optimization   

convergence                   0.9981621931356044^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Rate_of_convergence   

quadratic functions           0.9999891961210051^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Quadratic_function    

Borwein                       0.9999951034918066^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Peter_Borwein         

