Abstract Additive randomization has been a primary tool for hiding sensitive private information. Previous work empirically showed that individual data values can be approximately reconstructed from the perturbed values, using spectral filtering techniques. This poses a serious threat of privacy breaches. In this paper we conduct a theoretical study on how the reconstruction error varies, for different types of additive noise. In particular, we first derive an upper bound for the reconstruction error using matrix perturbation theory. Attackers who use spectral filtering techniques to estimate the true data values may leverage this bound to determine how close their estimates are to the original data. We then derive a lower bound for the reconstruction error, which can help data owners decide how much noise should be added to satisfy a given threshold of the tolerated privacy breach.
additive noise      1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Additive_white_Gaussian_noise

upper bound                   0.985830890909542^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Upper_and_lower_bounds

randomization                 0.8781504482240164^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Resampling_(statistics)

matrix                        0.999998882632723^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Matrix_(mathematics)  

perturbation theory           0.999916880148861^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Perturbation_theory   

