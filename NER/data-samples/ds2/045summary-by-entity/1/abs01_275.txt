Abstract We consider the problem of maximizing the expected utility of the terminal wealth of a portfolio in a continuous-time pure jump market with general utility function. This leads to an optimal control problem for piecewise deterministic Markov processes. Using an embedding procedure we solve the problem by looking at a discrete-time contracting Markov decision process. Our aim is to show that this point of view has a number of advantages, in particular as far as computational aspects are concerned. We characterize the value function as the unique fixed point of the dynamic programming operator and prove the existence of optimal portfolios. Moreover, we show that value iteration as well as Howardâ€™s policy improvement algorithm works. Finally, we give error bounds when the utility function is approximated and when we discretize the state space. A numerical example is presented and our approach is compared to the approximating Markov chain method.
expected utility    0.818869646807847^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Utility               

utility function              1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Utility               

Markov processes              0.9999976741458786^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Markov_chain          

dynamic programming           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Dynamic_programming   

piecewise                     1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Piecewise             

utility function              1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Utility               

algorithm                     1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Algorithm             

optimal control               1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Optimal_control       

deterministic                 0.9999760736137431^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Deterministic_algorithm

discrete-time                 0.9995511138784158^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Discrete_time         

Markov chain                  1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Markov_chain          

fixed point                   0.9999634162272023^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Fixed_point_(mathematics)

Markov decision process       1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Markov_decision_process

