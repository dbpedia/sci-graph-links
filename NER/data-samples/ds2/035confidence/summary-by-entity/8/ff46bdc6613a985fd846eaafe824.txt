Abstract Privacy is an important issue in data publishing. Many organizations distribute non-aggregate personal data for research, and they must take steps to ensure that an adversary cannot predict sensitive information pertaining to individuals with high confidence. This problem is further complicated by the fact that, in addition to the published data, the adversary may also have access to other resources (e.g., public records and social networks relating individuals), which we call adversarial knowledge. A robust privacy framework should allow publishing organizations to analyze data privacy by means of not only data dimensions (data that a publishing organization has), but also adversarial-knowledge dimensions (information not in the data). In this paper, we first describe a general framework for reasoning about privacy in the presence of adversarial knowledge. Within this framework, we propose a novel multidimensional approach to quantifying adversarial knowledge. This approach allows the publishing organization to investigate privacy threats and enforce privacy requirements in the presence of various types and amounts of adversarial knowledge. Our main technical contributions include a multidimensional privacy criterion that is more intuitive and flexible than previous approaches to modeling background knowledge. In addition, we identify an important congregation property of the adversarial-knowledge dimensions. Based on this property, we provide algorithms for measuring disclosure and sanitizing data that improve computational efficiency several orders of magnitude over the best known techniques.
privacy             0.9999837717115577^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Privacy               

sanitizing                    0.915413184081532^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Sanitation            

algorithms                    1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Algorithm             

privacy                       0.9999837717115577^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Privacy               

public records                1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Public_records        

magnitude                     0.9999680132933639^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Euclidean_vector      

privacy                       0.9999837717115577^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Privacy               

data privacy                  0.9999999971608986^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Information_privacy   

privacy                       0.9999837717115577^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Privacy               

privacy                       0.9999837717115577^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Privacy               

social networks               0.999837845958205^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Social_network        

