Abstract This paper maps out some of the few remaining challenges to artificial intelligence from the point of view of philosophy and fuzzy logic. Certain key ideas of Lotfi Zadeh are used as a point of reference. Human reasoning is a complex procedure which is able to handle such problems as the counterfactual truth and the supervenience relation, which are difficult to explain in terms of the classical logical theory. To achieve this, one needs to understand them in a more natural manner than the standard positivistic logic is able to do. Next some examples taken from ethical theory are discussed, such as the fact/value-distinction and supererogation. These provide typically hard cases to the positivist methodology, as its representatives have always admitted. The results are applied to the philosophical problems of robotics, especially to the notion of a Cyborg on the information web. A Cyborg on the Web should be able to combine human-like reasoning with unlimited information processing.
logic               0.999925557811093^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Logic                 

Cyborg                        0.9999993526955498^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Cyborg                

logical theory                1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Model_theory          

hard cases                    0.9999589282862422^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Hard_Cases            

robotics                      0.9910869619066263^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Robotics              

artificial intelligence       0.999999236176969^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Artificial_intelligence

philosophical                 0.9999489254367044^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Philosophy_of_science 

ethical theory                0.9908714845809318^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Ethics                

Lotfi Zadeh                   1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Lotfi_A._Zadeh        

classical                     0.9999997516080465^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Classical_logic       

Cyborg                        0.9999993526955498^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Cyborg                

positivistic                  0.7488124227822055^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Positivism            

methodology                   0.9987680578061834^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Methodology           

counterfactual                0.9999998803409724^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Counterfactual_conditional

supervenience                 1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Supervenience         

positivist                    0.8207274035713191^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Positivism            

philosophy                    0.9997834659878759^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Philosophy_of_science 

supererogation                0.999999997375653^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Supererogation        

fuzzy logic                   1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Fuzzy_logic           

