Abstract We consider the problem of maximizing the expected utility of the terminal wealth of a portfolio in a continuous-time pure jump market with general utility function. This leads to an optimal control problem for piecewise deterministic Markov processes. Using an embedding procedure we solve the problem by looking at a discrete-time contracting Markov decision process. Our aim is to show that this point of view has a number of advantages, in particular as far as computational aspects are concerned. We characterize the value function as the unique fixed point of the dynamic programming operator and prove the existence of optimal portfolios. Moreover, we show that value iteration as well as Howardâ€™s policy improvement algorithm works. Finally, we give error bounds when the utility function is approximated and when we discretize the state space. A numerical example is presented and our approach is compared to the approximating Markov chain method.
algorithm           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Algorithm             

dynamic programming           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Dynamic_programming   

continuous-time               0.9999999997851319^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Continuous-time_stochastic_process

Markov processes              0.9999976741458786^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Markov_chain          

fixed point                   0.9999634162272023^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Fixed_point_(mathematics)

iteration                     0.4004445851910622^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Dynamical_system      

piecewise                     1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Piecewise             

Markov chain                  1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Markov_chain          

function                      0.9999999988496029^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Function_(mathematics)

expected utility              0.818869646807847^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Utility               

Markov decision process       1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Markov_decision_process

deterministic                 0.9999760736137431^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Deterministic_algorithm

discrete-time                 0.9995511138784158^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Discrete_time         

terminal                      0.9999921907471178^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Computer_terminal     

utility function              1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Utility               

discretize                    1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Discretization        

portfolio                     0.9999999992511448^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Portfolio_(finance)   

embedding                     0.9996225315372995^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Embedding             

optimal control               1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Optimal_control       

utility function              1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Utility               

