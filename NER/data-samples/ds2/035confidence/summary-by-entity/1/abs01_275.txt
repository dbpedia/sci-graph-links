Abstract We consider the problem of maximizing the expected utility of the terminal wealth of a portfolio in a continuous-time pure jump market with general utility function. This leads to an optimal control problem for piecewise deterministic Markov processes. Using an embedding procedure we solve the problem by looking at a discrete-time contracting Markov decision process. Our aim is to show that this point of view has a number of advantages, in particular as far as computational aspects are concerned. We characterize the value function as the unique fixed point of the dynamic programming operator and prove the existence of optimal portfolios. Moreover, we show that value iteration as well as Howardâ€™s policy improvement algorithm works. Finally, we give error bounds when the utility function is approximated and when we discretize the state space. A numerical example is presented and our approach is compared to the approximating Markov chain method.
expected utility    0.818869646807847^^http://www.w3.org/2001/XMLSchema#double            http://dbpedia.org/resource/Utility               

utility function              1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Utility               

Markov processes              0.9999976741458786^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Markov_chain          

dynamic programming           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Dynamic_programming   

piecewise                     1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Piecewise             

terminal                      0.9999921907471178^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Computer_terminal     

embedding                     0.9996225315372995^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Embedding             

utility function              1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Utility               

discretize                    1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Discretization        

function                      0.9999999988496029^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Function_(mathematics)

algorithm                     1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Algorithm             

optimal control               1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Optimal_control       

deterministic                 0.9999760736137431^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Deterministic_algorithm

continuous-time               0.9999999997851319^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Continuous-time_stochastic_process

iteration                     0.4004445851910622^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Dynamical_system      

discrete-time                 0.9995511138784158^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Discrete_time         

portfolio                     0.9999999992511448^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Portfolio_(finance)   

fixed point                   0.9999634162272023^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Fixed_point_(mathematics)

Markov chain                  1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Markov_chain          

Markov decision process       1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Markov_decision_process

