Abstract This manuscript chronicles the process and products of a redesign for evaluation of the graduate college experience (GCE) which was initiated by a university graduate college, based on its observed need to reconsider and update its measures and methods for assessing graduate students’ experiences. We examined the existing instrumentation and procedures; met with and interviewed staff and stakeholders regarding individual and organizational needs; collected systematic questionnaire data on stakeholder perceptions; and then redesigned, developed, and tested new evaluation instruments, systems, and procedures. The previously paper-based, one-time global exit questionnaire was redesigned into a digitally administered, multi-event assessment series, with content relevant to students’ incremental academic progress. Previously discrete items were expanded into psychometrically coherent variable scales in parallel forms to assess change over time (entry, mid-point, exit, post-graduation). They were also strategically designed as stable and independent enough so administrators could vary the timing and sequence of administration to fit their ongoing needs The team conducted two testing cycles, gathering pertinent information on the redesigned assessment and procedures (N = 2,835). The final redesigned evaluation serves as an exemplar of evaluation that enhances assessment quality including psychometric properties and multiple stakeholder validation, more effectively addresses the organization’s incremental evaluation needs, increases timeliness of data collection, improves reach to and participation of distributed students, and enables longitudinal data collection to provide ongoing trajectory-of-change evaluation and a research data stream. Product and process analysis informs strategies for more effectively and dynamically assessing graduate education.