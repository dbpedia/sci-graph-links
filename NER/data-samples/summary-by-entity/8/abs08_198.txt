Abstract Multi-label learning is an effective framework for learning with objects that have multiple semantic labels, and has been successfully applied into many real-world tasks. In contrast with traditional single-label learning, the cost of labeling a multi-label example is rather high, thus it becomes an important task to train an effectivemulti-label learning model with as few labeled examples as possible. Active learning, which actively selects the most valuable data to query their labels, is the most important approach to reduce labeling cost. In this paper, we propose a novel approach MADM for batch mode multi-label active learning. On one hand, MADM exploits representativeness and diversity in both the feature and label space by matching the distribution between labeled and unlabeled data. On the other hand, it tends to query predicted positive instances, which are expected to be more informative than negative ones. Experiments on benchmark datasets demonstrate that the proposed approach can reduce the labeling cost significantly.
semantic            0.9784204634825079^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Semantics             

benchmark                     0.9746449883125007^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Statistical_hypothesis_testing

Active learning               1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Active_learning       

batch mode                    1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Batch_processing      

active learning               1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Active_learning       

datasets                      1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Data_set              

