Abstract One particular problem in large vocabulary continuous speech recognition for low-resourced languages is finding relevant training data for the statistical language models. Large amount of data is required, because models should estimate the probability for all possible word sequences. For Finnish, Estonian and the other fenno-ugric languages a special problem with the data is the huge amount of different word forms that are common in normal speech. The same problem exists also in other language technology applications such as machine translation, information retrieval, and in some extent also in other morphologically rich languages. In this paper we present methods and evaluations in four recent language modeling topics: selecting conversational data from the Internet, adapting models for foreign words, multi-domain and adapted neural network language modeling, and decoding with subword units. Our evaluations show that the same methods work in more than one language and that they scale down to smaller data resources.
neural network      0.9999999999979536^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Artificial_neural_network

language modeling             1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Language_model        

Finnish                       0.9999666689649477^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Finnish_language      

fenno-ugric                   0.9932583849082112^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Finno-Ugric_languages 

probability                   0.9874126669072903^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Probability           

Internet                      0.9686395598483778^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Internet              

machine translation           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Machine_translation   

vocabulary                    0.9991963014853066^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Vocabulary            

speech recognition            0.9872783900731473^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Natural_language_processing

language technology           1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Language_technology   

statistical language models   1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Language_model        

language modeling             1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Language_model        

continuous                    0.9999974416711876^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Probability_distribution

training data                 1.0^^http://www.w3.org/2001/XMLSchema#double                          http://dbpedia.org/resource/Training_set          

multi-domain                  0.9999999999895408^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Protein_domain        

Estonian                      0.9998357099550094^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Estonian_language     

language                      0.9947300719973755^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Natural_language      

morphologically               0.9999986836453014^^http://www.w3.org/2001/XMLSchema#double           http://dbpedia.org/resource/Morphology_(linguistics)

