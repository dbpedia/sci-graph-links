Abstract Integrating letters and sounds are essential for successful reading in alphabetic languages. It remains unclear if native speakers of non-alphabetic languages integrate letters and sounds in reading an alphabetic language in the same way as native alphabetic readers do. Chinese is a morpho-syllabic system (each character corresponds to one syllable) and contrasts sharply with alphabetic languages such as English. Several fMRI studies have shown that native Chinese speakers apply their native language system to read English words. By using the cross-modal mismatch negativity (MMN) paradigm, we directly investigated letter–sound integration for reading in English among native Chinese speakers. To investigate the effect of native language background on letter–sound integration in second language reading, a group of native Korean English learners served as a comparison group. We compared MMN responses between an auditory only condition (only vowels presented) and two audiovisual conditions (AV0, vowel presented synchronously with the corresponding letter; AV200, the letter presented 200 ms before the corresponding vowel) for both native Chinese and native Korean speakers. Native Chinese speakers demonstrated significantly attenuated MMN amplitudes in audiovisual conditions compared with the auditory only condition, regardless of their phonological decoding speed. In contrast, native Korean speakers showed amplified amplitude MMN in AV200 compared with that in the auditory only condition. The results suggest that native language may shape the brain responses of second language learners to reading a second language in the early stages. Native non-alphabetic language speakers may be unable to use visual information to facilitate their phonological processing in the early stage while native alphabetic language speakers are capable of integrating letter sounds automatically.
