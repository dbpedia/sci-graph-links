<http://www.springernature.com/scigraph/things/articles/77e09513194865d14f627f1ad3248c55> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The inability to effectively construct data supply chain in distributed environments is becoming one of the top concerns in big data area. Aiming at this problem, a novel method of constructing data supply chain based on layered PROV is proposed. First, to abstractly describe the data transfer processes from creation to distribution, a data provenance specification presented by W3C is used to standardize the information records of data activities within and across data platforms. Then, a distributed PROV data generation algorithm for multi-platform is designed. Further, we propose a tiered storage management of provenance based on summarization technology, which reduces the provenance records by compressing mid versions so as to realize multi-level management of PROV. In specific, we propose a hierarchical visual technique based on a layered query mechanism, which allows users to visualize data supply chain from general to detail. The experimental results show that the proposed approach can effectively improve the construction performance for data supply chain." .
<http://www.springernature.com/scigraph/things/articles/9ccdca48e4717df0f69d1db326ae75d5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Computational complexity of the semigroup fragment (of the algebraic semantics) and the implicational fragment of some fuzzy logics is studied, from the perspective of the complexity of the full logic. The available results appear to confirm the key role of the implicational fragments. Some other language fragments, as well as the notion of language fragment itself, are discussed." .
<http://www.springernature.com/scigraph/things/articles/ba4ab000309a236a59afed80ef4fdc85> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The finite-time stability problem of discrete switched singular positive systems (DSSPSs) is investigated in this paper. First, the concept of finite-time stability for DSSPSs is proposed, and a necessary and sufficient condition of finite-time stability for DSSPSs under arbitrary switching is obtained. Second, based on the mode-dependent average dwell time approach, by constructing the quasi-linear Lyapunov function, a sufficient stability criterion of finite-time stability for DSSPSs is derived in terms of a set of linear matrix inequalities. Finally, a numerical example is given to show the effectiveness of the proposed techniques." .
<http://www.springernature.com/scigraph/things/articles/d3b4a90df54ec1c151570cb7a74226d1> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract We enumerate 1035 user comments from 190 online articles to gauge public opinion about safety and privacy when transgender women use female bathrooms. In these comments, we find that cisgender males are around 1.55× as likely to express concern about safety and privacy as cisgender females. Moreover, we find that when expressing concern (a) cisgender females are around 4× as likely as cisgender males to assert that transgender women do not directly cause their safety and privacy concerns, typically emphasizing their concerns are about ‘perverts’ posing as transgender females, and (b) cisgender males are around 1.5× as likely as cisgender females to assert that transgender females directly cause their safety and privacy concerns. We theorize that the heightened concern seen in males in these comments stems from them being more likely to view transgender females not as females, but as males who are lying or mistaken about their gender, and consequently they view themselves as protecting females from these males intruding into private, female-only spaces. This may be further exacerbated by a fear of deception and a belief that transgender people are mentally ill or ‘sick’." .
<http://www.springernature.com/scigraph/things/articles/270f87bafda8ea8fe999068fe361824d> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The maximum set k-covering problem (MKCP) is a famous combinatorial optimization problem with widely many practical applications. In our work, we design a restart local search algorithm for solving MKCP, which is called RNKC. This algorithm effectively makes use of several advanced ideas deriving from the random restart mechanism and the neighborhood search method. RNKC designs a new random restart method to deal with the serious cycling problem of local search algorithms. Thanks to the novel neighborhood search method that allows a neighborhood exploration of as many feasible search areas as possible, the RNKC can obtain some greatly solution qualities. Comprehensive results on the classical instances show that the RNKC algorithm competes very favorably with a famous commercial solver CPLEX. In particular, it discovers some improved and great results and matches the same solution quality for some instances." .
<http://www.springernature.com/scigraph/things/articles/dcbd650b221603fc62b1d158903c0124> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Component-based software development can help reduce time and cost by means of reusing software components, but the quality of the software may not be ensured if the adopted components contain errors. The Structured Object-oriented Formal Language (SOFL) is a formal specification language that can be used for quality software development. This paper describes a development of desktop application software by connecting with several software components, and how it is developed using SOFL. We introduce how the requirements are analyzed through writing an informal specification and then refining it into a semi-formal specification. We also discuss how the design is carried out by constructing a formal specification in SOFL. Finally, we present the implementation and explain the details of a testing conducted for the quality assurance of the system." .
<http://www.springernature.com/scigraph/things/articles/bb50f64db70ba1298d3f743812c135c2> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0803> "Abstract The audio-to-score framework consists of two separate stages: preprocessing and alignment. The alignment is commonly solved through offline dynamic time warping (DTW), which is a method to find the path over the distortion matrix with the minimum cost to determine the relation between the performance and the musical score times. In this work we propose a parallel online DTW solution based on a client–server architecture. The current version of the application has been implemented for multi-core architectures ($$\\times $$ × 86, $$\\times $$ × 64 and ARM), thus covering either powerful systems or mobile devices. An extensive experimentation has been conducted to validate the software. The experiments also show that our framework allows to achieve a good score alignment within the real-time window using parallel computing techniques." .
<http://www.springernature.com/scigraph/things/articles/d9de6674cb6a141284cd1436fc37c441> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract BackgroundIn the United States, 795,000 people suffer strokes each year; 10–15 % of these strokes can be attributed to stenosis caused by plaque in the carotid artery, a major stroke phenotype risk factor. Studies comparing treatments for the management of asymptomatic carotid stenosis are challenging for at least two reasons: 1) administrative billing codes (i.e., Current Procedural Terminology (CPT) codes) that identify carotid images do not denote which neurovascular arteries are affected and 2) the majority of the image reports are negative for carotid stenosis. Studies that rely on manual chart abstraction can be labor-intensive, expensive, and time-consuming. Natural Language Processing (NLP) can expedite the process of manual chart abstraction by automatically filtering reports with no/insignificant carotid stenosis findings and flagging reports with significant carotid stenosis findings; thus, potentially reducing effort, costs, and time. MethodsIn this pilot study, we conducted an information content analysis of carotid stenosis mentions in terms of their report location (Sections), report formats (structures) and linguistic descriptions (expressions) from Veteran Health Administration free-text reports. We assessed an NLP algorithm, pyConText’s, ability to discern reports with significant carotid stenosis findings from reports with no/insignificant carotid stenosis findings given these three document composition factors for two report types: radiology (RAD) and text integration utility (TIU) notes. ResultsWe observed that most carotid mentions are recorded in prose using categorical expressions, within the Findings and Impression sections for RAD reports and within neither of these designated sections for TIU notes. For RAD reports, pyConText performed with high sensitivity (88 %), specificity (84 %), and negative predictive value (95 %) and reasonable positive predictive value (70 %). For TIU notes, pyConText performed with high specificity (87 %) and negative predictive value (92 %), reasonable sensitivity (73 %), and moderate positive predictive value (58 %). pyConText performed with the highest sensitivity processing the full report rather than the Findings or Impressions independently. ConclusionWe conclude that pyConText can reduce chart review efforts by filtering reports with no/insignificant carotid stenosis findings and flagging reports with significant carotid stenosis findings from the Veteran Health Administration electronic health record, and hence has utility for expediting a comparative effectiveness study of treatment strategies for stroke prevention." .
<http://www.springernature.com/scigraph/things/articles/54759361d700365c53e1fe433df13744> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract E-Healthcare is an emerging field that provides mobility to its users. The protected health information of the users are stored at a remote server (Telecare Medical Information System) and can be accessed by the users at anytime. Many authentication protocols have been proposed to ensure the secure authenticated access to the Telecare Medical Information System. These protocols are designed to provide certain properties such as: anonymity, untraceability, unlinkability, privacy, confidentiality, availability and integrity. They also aim to build a key exchange mechanism, which provides security against some attacks such as: identity theft, password guessing, denial of service, impersonation and insider attacks. This paper reviews these proposed authentication protocols and discusses their strengths and weaknesses in terms of ensured security and privacy properties, and computation cost. The schemes are divided in three broad categories of one-factor, two-factor and three-factor authentication schemes. Inter-category and intra-category comparison has been performed for these schemes and based on the derived results we propose future directions and recommendations that can be very helpful to the researchers who work on the design and implementation of authentication protocols." .
<http://www.springernature.com/scigraph/things/articles/38b74129ac4fd49a25fac867a873a4e0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract This paper considers enumeration of substring equivalence classes introduced by Blumer et al. (J ACM 34(3):578–595, 1987). These equivalence classes were originally proposed to define a text indexing structure called compact directed acyclic word graphs (CDAWGs). These equivalence classes are also useful for text analysis, since they group together redundant substrings with essentially identical occurrences. In this paper, we present how to enumerate these equivalence classes using only suffix arrays and two auxiliary arrays (rank arrays and lcp arrays), in O(n) time for a given string of length n over the integer alphabet. The proposed method overcomes all the existing algorithms which require $$O(n \\log \\sigma )$$ O(nlogσ) time, where $$\\sigma $$ σ is the alphabet size. Our experimental results show that the proposed method is also practically faster and more memory efficient than the existing ones. Furthermore, we propose an O(n)-time algorithm which constructs the CDAWG of an input string over the integer alphabet. This algorithm is based on the above-mentioned algorithm to enumerate equivalence classes. Our experiments show that the proposed method runs faster than the existing algorithm on large alphabets." .
<http://www.springernature.com/scigraph/things/articles/f4042d7a108618e80d4495eb53ed8270> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Nature-inspired metaheuristic algorithms are considered as the most effective techniques for solving various optimization problems. This paper provides a briefly review of the key features of the cuckoo-inspired metaheuristics: cuckoo search (CS) and cuckoo optimization algorithm (COA). In addition, it discusses some of their important and emerging studies, investigates their applications in several fields, and finally clarifies the differences between both algorithms so as to remove confusion between them." .
<http://www.springernature.com/scigraph/things/articles/e0e48d5a7827d3af7806e71ae71f1436> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We show that the minimum number of orientations of the edges of the n-vertex complete graph having the property that every triangle is made cyclic in at least one of them is $$\\lceil \\log _2(n-1)\\rceil $$ ⌈log2(n-1)⌉ . More generally, we also determine the minimum number of orientations of $$K_n$$ Kn such that at least one of them orients some specific k-cycles cyclically on every k-element subset of the vertex set. Though only formally related, the questions answered by these results were motivated by an analogous problem of Vera T. Sós concerning triangles and 3-edge-colorings. Some variants of the problem are also considered." .
<http://www.springernature.com/scigraph/things/articles/b82afe603a0d009cc95fea93e252d2e0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "One of the basic assumptions for traditional univariate and multivariate control charts is that the data are independent in time. For the latter, in many cases, the data are serially dependent (autocorrelated) and cross‐correlated because of, for example, frequent sampling and process dynamics. It is well known that the autocorrelation affects the false alarm rate and the shift‐detection ability of the traditional univariate control charts. However, how the false alarm rate and the shift‐detection ability of the Hotelling T2 control chart are affected by various autocorrelation and cross‐correlation structures for different magnitudes of shifts in the process mean is not fully explored in the literature. In this article, the performance of the Hotelling T2 control chart for different shift sizes and various autocorrelation and cross‐correlation structures are compared based on the average run length using simulated data. Three different approaches in constructing the Hotelling T2 chart are studied for two different estimates of the covariance matrix: (i) ignoring the autocorrelation and using the raw data with theoretical upper control limits; (ii) ignoring the autocorrelation and using the raw data with adjusted control limits calculated through Monte Carlo simulations; and (iii) constructing the control chart for the residuals from a multivariate time series model fitted to the raw data. To limit the complexity, we use a first‐order vector autoregressive process and focus mainly on bivariate data." .
<http://www.springernature.com/scigraph/things/articles/310e1570c3c48fb235583dea4ba11706> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract One key driver of the Linked Data paradigm is the ability to lift data graphs from legacy systems by employing various adapters and RDFizers (e.g., D2RQ for relational databases, XLWrap for spreadsheets). Such approaches aim towards removing boundaries of enterprise data silos by opening them to cross-organizational linking within a “Web of Data”. An insufficiently tapped source of machine-readable semantics is the underlying graph nature of diagrammatic conceptual models – a kind of information that is richer compared to what is typically lifted from table schemata, especially when a domain-specific modeling language is employed. The paper advocates an approach to Linked Data enrichment based on a diagrammatic model RDFizer originally developed in the context of the ComVantage FP7 research project. A minimal but illustrative example is provided from which arguments will be generalized, leading to a proposed vision of “conceptual model”-aware information systems." .
<http://www.springernature.com/scigraph/things/articles/206734fac36c0f172f1e222e9e7dac6d> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Production plants are usually kept in operation for several decades. During this long operational phase operation requirements and other production conditions change frequently. Accordingly, the plants have to be adjusted in behavior and/or structure by adapting software and physics of the plant to avoid degeneration. Unfortunately, in industrial practice, changes, especially smaller ones, are often performed ad-hoc without appropriate adaptation of formal models or documentation. As a consequence, knowledge about the process is only implicitly available and an evaluation of performed changes is often omitted, resulting in sub-optimal production performance. Present research approaches to overcome these deficiencies usually concentrate on (a) manual modelling with manual or automatic analysis on a high level of abstraction; or (b) on automatic model generation from observations without lifting gathered knowledge to easy interpretable indicators. The approach presented in this paper combines both methods (a) and (b) by learning models from observation of input / output signals of the production plant’s control system. Semantics are added by using a priori information modelling which is less tedious compared to modelling the process itself. The learned models are used to automatically detect changes by continuously comparing their behavior with real plant behavior during operation as well as to evaluate performed changes. An analysis of the models results in high-level property values such as key performance indicators or flexibility measures of the production system." .
<http://www.springernature.com/scigraph/things/articles/2fab74ef134f4edfe01262667b8753ef> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Most of the existing researches simply convert associations of nodes within the snapshot of the evolutionary social network to the weight of edges. However, because of the obvious Matthew effect existing in the interactions of nodes in the real social network, the association strength matrices extracted directly by snapshots are extremely uneven. This paper introduces a new evolutionary social network model. Firstly, we generate probabilistic snapshots of the evolutionary social network data. Afterwards, we use the probabilistic factor model to detect the variation points brought by network events. Finally we partition the network community based on snapshots with stable structures before and after the variation points. According to experimental results, our proposed probabilistic snapshot model is effective for network events detection and network community partition." .
<http://www.springernature.com/scigraph/things/articles/4386376b1f4f19fe334a00121bf48ec0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract This article describes a novel approach to verification of articulated arm coordinate measuring machines (AA CMMs) based on ISO 10360-2 standard. The approach utilizes the LaserTracer (LT) system as standard of length and automation of calibration procedure using an industrial robot. In this method, the robot is programmed to repeatedly move the AA CMM. The retroreflector is integrated with the stylus of AA CMM. Location of the retroreflector is constantly tracked by LaserTracer and, in select positions, the measurements of distance are performed by both the AA CMM and LT system. The verification of AA CMM accuracy is carried out through the comparison of the two measurement values. The developed procedure is recommended mainly for checking AA CMMs with large measuring volume, where the application of common artefacts is usually insufficient, or time-consuming, due to the fact that measurements have to be performed for several subspaces in the AA CMM measuring volume." .
<http://www.springernature.com/scigraph/things/articles/5b942c42bc5f703e209779bb137c4a1b> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The proliferation of GPS-enabled smart mobile devices enables us to collect a large-scale trajectories of moving objects with GPS tags. While the raw trajectories that only consists of positional information have been studied extensively, many recent works have been focusing on enriching the raw trajectories with semantic knowledge. The resulting data, called activity trajectories, embed the information about behaviors of the moving objects and support a variety of applications for better quality of services. In this paper, we propose a Top-k Spatial Keyword (TkSK) query for activity trajectories, with the objective to find a set of trajectories that are not only close geographically but also meet the requirements of the query semantically. Such kind of query can deliver more informative results than existing spatial keyword queries for static objects, since activity trajectories are able to reflect the popularity of user activities and reveal preferable combinations of facilities. However, it is a challenging task to answer this query efficiently due to the inherent difficulties in indexing trajectories as well as the new complexity introduced by the textual dimension. In this work, we provide a comprehensive solution, including the novel similarity function, hybrid indexing structure, efficient search algorithm and further optimizations. Extensive empirical studies on real trajectory set have demonstrated the scalability of our proposed solution." .
<http://www.springernature.com/scigraph/things/articles/2f175aa2bf6c71af3970a0976bdfdcb6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Originated from the military domain, Situation Awareness (SAW) is proposed with the aim to obtain information superiority through information fusion and thus to achieve decision superiority. It requires not only the perception of the environment, but also the reasoning of the implicit or implicated meaning under the explicit phenomenon. The principal goal of this paper is to exploit the semantic web technologies to enhance the situation awareness through autonomous information fusion and inference. Recently, ontology has played a significant role in the representation and integration of domain knowledge for high-level reasoning. The multi-level ontology merging paradigm is followed in this work for the conceptual modeling and knowledge representation. Firstly, Military Scenario Ontology (MSO) and Battle Management Ontology (BMO) are defined according to corresponding reputable standards as the domain ontology. We propose the Situation Awareness Ontology (SAO) as the core ontology to integrate MSO, BMO and even other publicly defined ontology for higher-level information fusion. The SAO is composed of objects representations, relations and events that are necessary to capture the information for further cognition, reasoning and decision-making about the situation evolving over time. Military doctrines and domain knowledge are expressed as Horn clause type rules for reasoning and inference. Multi-layered semantic information fusion that integrates ontologies, semantic web technologies and rule-based reasoning can therefore be conducted. An experimental scenario is presented to demonstrate the feasibility of this architecture." .
<http://www.springernature.com/scigraph/things/articles/f6d46bcc9ef2b3abb40a2212b7bf8425> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The term fingerprint-based (FP) positioning includes a wide variety of methods for determining a receiver’s position using a database of radio signal strength measurements that were collected earlier at known locations. Nonparametric methods such as the weighted k-nearest neighbor (WKNN) method are infeasible for large-scale mobile device services because of the large data storage and transmission requirements. In this work we present an overview of parametric FP methods that use model-based representations of the survey data. We look at three different groups of parametric methods: methods that use coverage areas, methods that use path loss models, and methods that use Gaussian mixtures. Within each group we study different approaches and discuss their pros and cons. Furthermore, we test the positioning performance of several of the analyzed approaches in different scenarios using real-world WLAN indoor data and compare the results to those of the WKNN method." .
<http://www.springernature.com/scigraph/things/articles/62d5392d9884d8e0a320434ebe51e3c3> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract To realize efficient quantum communication based on quantum repeater, we propose a secure quantum network coding scheme for controlled repeater networks, which adds a controller as a trusted party and is able to control the process of EPR-pair distribution. As the key operations of quantum repeater, local operations and quantum communication are designed to adopt quantum one-time pad to enhance the function of identity authentication instead of local operations and classical communication. Scheme analysis shows that the proposed scheme can defend against active attacks for quantum communication and realize long-distance quantum communication with minimal resource consumption." .
<http://www.springernature.com/scigraph/things/articles/b3267c5a71db07ee43e71ae7004b4866> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Braess’s paradox states that removing a part of a network may improve the players’ latency at equilibrium. In this work, we study the approximability of the best subnetwork problem for the class of random $${\\mathcal {G}}_{n,p}$$ Gn,p instances proven prone to Braess’s paradox by Valiant and Roughgarden RSA ’10 (Random Struct Algorithms 37(4):495–515, 2010), Chung and Young WINE ’10 (LNCS 6484:194–208, 2010) and Chung et al. RSA ’12 (Random Struct Algorithms 41(4):451–468, 2012). Our main contribution is a polynomial-time approximation-preserving reduction of the best subnetwork problem for such instances to the corresponding problem in a simplified network where all neighbors of source s and destination t are directly connected by 0 latency edges. Building on this, we consider two cases, either when the total rate r is sufficiently low, or, when r is sufficiently high. In the first case of low $$r= O(n_{+})$$ r=O(n+) , here $$n_{+}$$ n+ is the maximum degree of $$\\{s, t\\}$$ {s,t} , we obtain an approximation scheme that for any constant $$\\varepsilon > 0$$ ε>0 and with high probability, computes a subnetwork and an $$\\varepsilon $$ ε -Nash flow with maximum latency at most $$(1+\\varepsilon )L^*+ \\varepsilon $$ (1+ε)L∗+ε , where $$L^*$$ L∗ is the equilibrium latency of the best subnetwork. Our approximation scheme runs in polynomial time if the random network has average degree $$O(\\mathrm {poly}(\\ln n))$$ O(poly(lnn)) and the traffic rate is $$O(\\mathrm {poly}(\\ln \\ln n))$$ O(poly(lnlnn)) , and in quasipolynomial time for average degrees up to o(n) and traffic rates of $$O(\\mathrm {poly}(\\ln n))$$ O(poly(lnn)) . Finally, in the second case of high $$r= {\\varOmega }(n_{+})$$ r=Ω(n+) , we compute in strongly polynomial time a subnetwork and an $$\\varepsilon $$ ε -Nash flow with maximum latency at most $$(1+2\\varepsilon + o(1))L^*$$ (1+2ε+o(1))L∗ ." .
<http://www.springernature.com/scigraph/things/articles/3af271415cc569ab2a169aa930857437> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Zusammenfassung Dieser Artikel befasst sich mit den Grenzen und Chancen von Usability-Methoden, welche als Ergebnis quantitative Daten liefern. Dies wird beispielhaft anhand der Feldstudie eines Anästhesiegerätes erläutert, welches im laufenden Betrieb in einer Kinder-Tagesklinik untersucht wurde. Im Fokus dieser Untersuchung lag es die Vorteile und Grenzen unterschiedlicher Methoden aufzuzeigen, die als Ergebnis ausschließlich quantitative Daten liefern. Die Erfahrungen der durchgeführten Studie werden erläutert und Verbesserungspotentiale werden aufgezeigt, um die Qualität und das Kosten-Nutzen-Verhältnis dieser Art von Studie zu verbessern und um die zukünftige Produktgestaltung hierdurch nachhaltiger zu unterstützen." .
<http://www.springernature.com/scigraph/things/articles/500de2ad59844d016fdac1d4a29e0212> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We analyze the structure of a large class of connected algebraic rings over an algebraically closed field of positive characteristic using Greenberg’s perfectization functor. We then give applications to rigidity problems for representations of Chevalley groups." .
<http://www.springernature.com/scigraph/things/articles/cb20b0c5391c1fc973410121716f1f11> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract Digital library has begun to enter a new era of cloud computing after Internet era, Web era, Grid era and Web 2.0 era. Combined with cloud computing technology, this thesis constructed a cloud service platform of digital library and described the service process and operating mechanism of digital library cloud service platform." .
<http://www.springernature.com/scigraph/things/articles/3390d7cebf2087678e786cdc9de1d0e8> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract In this paper, we present a path-following infeasible interior-point method for $$P_*(\\kappa )$$ P∗(κ) horizontal linear complementarity problems ($$P_*(\\kappa )$$ P∗(κ) -HLCPs). The algorithm is based on a simple kernel function for finding the search directions and defining the neighborhood of the central path. The algorithm follows the central path related to some perturbations of the original problem, using the so-called feasibility and centering steps, along with only full such steps. Therefore, it has the advantage that the calculation of the step sizes at each iteration is avoided. The complexity result shows that the full-Newton step infeasible interior-point algorithm based on the simple kernel function enjoys the best-known iteration complexity for $$P_*(\\kappa )$$ P∗(κ) -HLCPs." .
<http://www.springernature.com/scigraph/things/articles/3c724e1b229c1bea4d6ba2bb718d8d55> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Attribute based encryption (ABE) has been widely applied for secure data protection in various data sharing systems. However, the efficiency of existing ABE schemes is not high enough since running encrypt and decrypt algorithms need frequent bilinear pairing operations, which may occupy too much computing resources on terminal devices. What’s more, since different users may share the same attributes in the system, a single user’s private key exposure will threaten the security and confidentiality of the whole system. Therefore, to further decrease the computation cost in attribute based cryptosystem as well as provide secure protection when key exposure happens, in this paper, we firstly propose a high efficient key-insulated ABE algorithm without pairings. The key-insulated mechanism guarantees both forward security and backward security when key exposure or user revocation happens. Besides, during the running of algorithms in our scheme, users and attribute authority needn’t run any bilinear pairing operations, which will increase the efficiency to a large extent. The high efficiency and security analysis indicate that our scheme is more appropriate for secure protection in data sharing systems." .
<http://www.springernature.com/scigraph/things/articles/2a487942d93757bdd9b40b07ad083ee0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Placing information at specific locations in the home provides rich and intuitive ways for people to cope with information, as they leverage semantics of the locations within the home. However, there is no deeper investigation yet on how users would embed digital cloud-based information into various locations in their homes, partly because previous systems were not robust enough to be deployed in real settings for an extended period of time. To this end, we have developed PostBits, a system of display blocks that integrate cloud information with contextually rich physical space. PostBits were designed for long battery life, robust communication and simple interactions, to enable a field deployment. A field study was conducted with 6 families, each using the system in their home for 1 week. We have identified patterns and strategies of how users embed cloud information at contextual locations in the home, and reflect on future design opportunities." .
<http://www.springernature.com/scigraph/things/articles/88ce9ce84b0df1efee794057c7902ee5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Our purpose is to study the pairings of edges of hyperbolic polygonswith p edges, who are associated with a tessellation {p, q} = {12g−6, 3}, where g corresponds to the genus of the surface.We will define surgeries of pairings of edges associated with this tessellation, which allows us to get families of pairings graphs, for all g." .
<http://www.springernature.com/scigraph/things/articles/18cfed866a9c2928a404213b06edb8b3> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract This article presents a novel framework XSS-Secure, which detects and alleviates the propagation of Cross-Site Scripting (XSS) worms from the Online Social Network (OSN)-based multimedia web applications on the cloud environment. It operates in two modes: training and detection mode. The former mode sanitizes the extracted untrusted variables of JavaScript code in a context-aware manner. This mode stores such sanitized code in sanitizer snapshot repository and OSN web server for further instrumentation in the detection mode. The detection mode compares the sanitized HTTP response (HRES) generated at the OSN web server with the sanitized response stored at the sanitizer snapshot repository. Any variation observed in this HRES message will indicate the injection of XSS worms from the remote OSN servers. XSS-Secure determines the context of such worms, perform the context-aware sanitization on them and finally sanitized HRES is transmitted to the OSN user. The prototype of our framework was developed in Java and integrated its components on the virtual machines of cloud environment. The detection and alleviation capability of our cloud-based framework was tested on the platforms of real world multimedia-based web applications including the OSN-based Web applications. Experimental outcomes reveal that our framework is capable enough to mitigate the dissemination of XSS worm from the platforms of non-OSN Web applications as well as OSN web sites with acceptable false negative and false positive rate." .
<http://www.springernature.com/scigraph/things/articles/4557580c1e87e5dd76aa8c39a0d509fd> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "An information systems (IS) support community represents a knowledge-intensive network where IS professionals interact with end-users to resolve system use problems during the IS post-implementation stage. For IS professionals in the support function, providing support for multiple information systems to multiple business units requires knowledge about different domains (business units or technical systems). In this paper, we take a network perspective to empirically evaluate the effects of an IS worker's network position and knowledge boundary spanning on productivity. Drawing upon theories of experiential learning and knowledge boundary, we perform social network analysis and linear mixed effects modeling to analyze archival data comprising 36 IS workers and 23,450 support requests made by 4568 end-users during the first 13months post SAP/R3 implementation in a large U.S. organization. Our findings reveal that IS workers' network centrality and boundary spanning positively influence productivity. Surprisingly, their boundary-spanning experience plays a substantially more important role than network centrality. This study makes important contributions to theory and practice in individual experiential learning in knowledge-intensive networks." .
<http://www.springernature.com/scigraph/things/articles/b1002b95e8afafe6d800505a62a47ff7> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract The burden of cardiovascular diseases (CVDs) in the world is ever growing. They represent the first cause of death worldwide and in Latin America. Nuclear cardiology has a well-established role in the management of patient with CVDs and is being increasingly integrated into the healthcare systems in the region. However, there remains variability as to the infrastructure available across the countries, in terms of existing technology, radiopharmaceuticals, and human resources. The approximate number of gamma (γ) cameras in the region is 1348, with an average of 2.25 per million population; Argentina and Brazil having the largest number. Nearly 80% of the existing cameras are single-photon emission tomography (SPECT), of which 8% are hybrid SPECT-CT systems. Positron emission tomography technology is steadily increasing, and currently, there is an average of 0.25 scanners per million inhabitants, indicating that there is a potential to expand the capacities in order to cover the needs. Four countries have nuclear reactors for research purposes, which allow the production of technetium-99 m (Argentina, Chile, Mexico and Peru), while four (Argentina, Brazil, Cuba, and Mexico) assemble 99Mo-99mTc generators. As for the nuclear cardiology studies, about 80% of studies performed are gated SPECT myocardial perfusion imaging; less than 10% are multi-gated acquisition (mainly for evaluation of cardiac toxicity in cancer patients), and the other 10% correspond to other types of studies, such as viability detection, and adrenergic innervation studies with 123I-MIBG. Physical stress is preferred, when possible, based on the clinical condition of the patient. Regarding human resources, there is an average of 1.1 physicians and 1.3 technologists per γ camera, with 0.1 medical physicists and 0.1 radiopharmacists per center in the region. The future of nuclear cardiology in Latin America and the Caribbean is encouraging, with great potential and possibilities for growth. National, regional, and international cooperation including support from scientific societies and organizations such as International Atomic Energy Agency, American Society of Nuclear Cardiology, and Latin American Association of Biology and Nuclear Medicine Societies, as well as governmental commitment are key factors for the development of the specialty. A multimodality approach in cardiac imaging will contribute to a better management of patients with CVDs." .
<http://www.springernature.com/scigraph/things/articles/9812df6b8fbf5c1d093c7747c3154c53> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We continue the investigation of parameterized extensions of linear temporal logic (LTL) that retain the attractive algorithmic properties of LTL: a polynomial space model checking algorithm and a doubly-exponential time algorithm for solving games. Alur et al. and Kupferman et al. showed that this is the case for parametric LTL (PLTL) and PROMPT-LTL respectively, which have temporal operators equipped with variables that bound their scope in time. Later, this was also shown to be true for parametric LDL (PLDL), which extends PLTL to be able to express all $$\\omega $$ ω -regular properties. Here, we generalize PLTL to systems with costs, i.e., we do not bound the scope of operators in time, but bound the scope in terms of the cost accumulated during time. Again, we show that model checking and solving games for specifications in PLTL with costs is not harder than the corresponding problems for LTL. Finally, we discuss PLDL with costs and extensions to multiple cost functions." .
<http://www.springernature.com/scigraph/things/articles/e69e9784fca10e03334d29e0afad72a2> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The last few years have witnessed tremendous interest in understanding the structure as well as the behavior of dynamics for inhomogeneous random graph models to gain insight into real-world systems. In this study we analyze the maximal components at criticality of one famous class of such models, the rank-one inhomogeneous random graph model (Norros and Reittu, Adv Appl Probab 38(1):59–75, 2006; Bollobás et al., Random Struct Algorithms 31(1):3–122, 2007, Section 16.4). Viewing these components as measured random metric spaces, under finite moment assumptions for the weight distribution, we show that the components in the critical scaling window with distances scaled by $$n^{-1/3}$$ n-1/3 converge in the Gromov–Haussdorf–Prokhorov metric to rescaled versions of the limit objects identified for the Erdős–Rényi random graph components at criticality in Addario-Berry et al. (Probab. Theory Related Fields, 152(3–4):367–406, 2012). A key step is the construction of connected components of the random graph through an appropriate tilt of a fundamental class of random trees called $$\\mathbf {p}$$ p -trees (Camarri and Pitman, Electron. J. Probab 5(2):1–18, 2000; Aldous et al., Probab Theory Related Fields 129(2):182–218, 2004). This is the first step in rigorously understanding the scaling limits of objects such as the minimal spanning tree and other strong disorder models from statistical physics (Braunstein et al., Phys Rev Lett 91(16):168701, 2003) for such graph models. By asymptotic equivalence (Janson, Random Struct Algorithms 36(1):26–45, 2010), the same results are true for the Chung–Lu model (Chung and Lu, Proc Natl Acad Sci 99(25):15879–15882, 2002; Chung and Lu, Ann Combin 6(2):125–145, 2002; Chung and Lu, Complex graphs and networks, 2006) and the Britton–Deijfen–Martin–Löf model (Britton et al., J Stat Phys 124(6):1377–1397, 2006). A crucial ingredient of the proof of independent interest are tail bounds for the height of $$\\mathbf {p}$$ p -trees. The techniques developed in this paper form the main technical bedrock for the general program developed in Bhamidi et al. (Scaling limits of random graph models at criticality: Universality and the basin of attraction of the Erdős–Rényi random graph. arXiv preprint, 2014) for proving universality of the continuum scaling limits in the critical regime for a wide array of other random graph models including the configuration model and inhomogeneous random graphs with general kernels (Bollobás et al., Random Struct Algorithms 31(1):3–122, 2007)." .
<http://www.springernature.com/scigraph/things/articles/d15093f140f080cffce7f91ae375698f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The total chromatic sum of a graph is the minimum sum of colors (natural numbers) taken over all proper colorings of vertices and edges of a graph. We construct infinite families of graphs for which the minimum number of colors to achieve the total chromatic sum is larger than the total chromatic number." .
<http://www.springernature.com/scigraph/things/articles/c8987d2144c76676a5c5c6a01e82b135> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract A semi-matching in a bipartite graph $$G = (U, V, E)$$ G=(U,V,E) is a set of edges $$M \\subseteq E$$ M⊆E such that each vertex in U is incident to exactly one edge in M, i.e., $$deg_M(u)=1$$ degM(u)=1 for each $$u \\in U$$ u∈U . An optimal semi-matching is a semi-matching with the minimal value of the cost function $$\\sum _{v \\in V} \\frac{deg_M(v) \\cdot (deg_M(v)+1)}{2}$$ ∑v∈VdegM(v)·(degM(v)+1)2 . Exploiting the divide-and-conquer nature of the semi-matching problem, we reduce the problem to a simpler problem whose objective is to compute a maximum weak bounded-degree semi-matching. Using the reduction we derive three algorithms for the optimal semi-matching problem. The first one runs in time $$O(\\sqrt{n} \\cdot m \\cdot \\log {n})$$ O(n·m·logn) on a graph with n vertices and m edges. The second one is randomized and computes an optimal semi-matching with high probability in time $$O(n^{\\omega } \\cdot \\log ^{1+o(1)} n)$$ O(nω·log1+o(1)n) , where $$\\omega $$ ω is the exponent of the best known matrix multiplication algorithm. Since $$\\omega < 2.38$$ ω<2.38 , this algorithm breaks through $$O(n^{2.5})$$ O(n2.5) barrier for dense graphs. In the case of planar graphs, the third one computes an optimal semi-matching in deterministic time $$O(n\\cdot \\log ^4{n})$$ O(n·log4n) ." .
<http://www.springernature.com/scigraph/things/articles/5034df4e6e79e3116e9d0755b9a0d0a6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract The forest fire occurs every year and brings huge losses to human life and property. How to predict the trend of forest fire accurately for commanders to make decisions in a very short period of time, has become a hot issue of research in recent years. In many cases, temporal and spatial variation of wind direction and wind speed become the main factors in affecting the spread of forest fire. Research on local wind field in micro scale is helpful to improve the accuracy of the prediction of forest fire spreading, but in reality, the data provided by meteorological department are large scale wind field data. Micro scale of the local wind field data mostly rely on the speculation based on the experience of people. So the system which can transform the large scale wind field data to the micro scale local wind field data to improve the prediction accuracy of forest fire spreading is especially necessary. In this paper, according to the characteristics of the near surface wind field we calculate the wind speed by the wind profile, get differential of wind direction of each grid position through the diagnosis of the wind field model, so as to realize the finer micro scale wind field in the complex topography. Wind field and forest fire model can be displayed in real time visualization platform. In the final of this paper, we selected multiple fire cases contained with the southern typical fire cases which have the complete data as the research object to analyze, and have implemented the simulation of forest fire inversion in the self-developed software FFSimulator v1. 0. The simulation of local wind field, fixed wind field and the no wind field forest fire are conducted under the conditions of the same terrain and the same combustible material. With the comparison of simulation results and the case study of forest fire burning area and spread edges, the experimental results show that the simulation using local wind field data of forest fire is more accurate in forecasting the trend of fire spreading, and can provide more favorable reference for making fire prevention and fire fighting decisions and transportation planning in forest." .
<http://www.springernature.com/scigraph/things/articles/84371556390333abaecab5072a518a08> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Application of artificial neural networks (ANN) in various aspects of geotechnical engineering problems such as site characterization due to have difficulty to solve or interrupt through conventional approaches has demonstrated some degree of success. In the current paper a developed and optimized five layer feed-forward back-propagation neural network with 4-4-4-3-1 topology, network error of 0.00201 and R2 = 0.941 under the conjugate gradient descent ANN training algorithm was introduce to predict the clay sensitivity parameter in a specified area in southwest of Sweden. The close relation of this parameter to occurred landslides in Sweden was the main reason why this study is focused on. For this purpose, the information of 70 piezocone penetration test (CPTu) points was used to model the variations of clay sensitivity and the influences of direct or indirect related parameters to CPTu has been taken into account and discussed in detail. Applied operation process to find the optimized ANN model using various training algorithms as well as different activation functions was the main advantage of this paper. The performance and feasibility of proposed optimized model has been examined and evaluated using various statistical and analytical criteria as well as regression analyses and then compared to in situ field tests and laboratory investigation results. The sensitivity analysis of this study showed that the depth and pore pressure are the two most and cone tip resistance is the least effective factor on prediction of clay sensitivity." .
<http://www.springernature.com/scigraph/things/articles/f5899d48a2a8693b05a6e36b096d2bf5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract The evolution of modern web application involves a broad range of web technologies such as ActiveX, JavaScript and CGI. It mitigates the demand of bolt-on security services, but remains suffered from code vulnerabilities. Two common issues of web application code vulnerability are the wrong style of writing code and improper server configuration. Enhancing the web application’s functionalities and ease of use are the primary concern of developers. Security is their second concern, resulting in code vulnerabilities. The application developers may effectively deal with code vulnerabilities through adhering to Secure Coding Standards. But manually applying all the Secure Coding Standard is susceptible to human errors. Hence, a graph-based interactive system is developed in the context of Secure Coding Standards to handle code vulnerabilities. Evaluation of the developed system is carried out by using standard available datasets such as CVE, NVD, Syhunt Vulnerable PHP Code and OWASP." .
<http://www.springernature.com/scigraph/things/articles/ecb8b63b0aa00df89609855f5c87c492> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract A multi-objective evolutionary algorithm which can be applied to many nonlinear multi-objective optimization problems is proposed. Its aim is to quickly obtain a fixed size Pareto-front approximation. It adapts ideas from different multi-objective evolutionary algorithms, but also incorporates new devices. In particular, the search in the feasible region is carried out on promising areas (hyperspheres) determined by a radius value, which decreases as the optimization procedure evolves. This mechanism helps to maintain a balance between exploration and exploitation of the search space. Additionally, a new local search method which accelerates the convergence of the population towards the Pareto-front, has been incorporated. It is an extension of the local optimizer SASS and improves a given solution along a search direction (no gradient information is used). Finally, a termination criterion has also been proposed, which stops the algorithm if the distances between the Pareto-front approximations provided by the algorithm in three consecutive iterations are smaller than a given tolerance. To know how far two of those sets are from each other, a modification of the well-known Hausdorff distance is proposed. In order to analyze the algorithm performance, it has been compared to the reference algorithms NSGA-II and SPEA2 and the state-of-the-art algorithms MOEA/D and SMS-EMOA. Several quality indicators have been considered, namely, hypervolume, average distance, additive epsilon indicator, spread and spacing. According to the computational tests performed, the new algorithm, named FEMOEA, outperforms the other algorithms." .
<http://www.springernature.com/scigraph/things/articles/6bdaab42ffed42a0e08901586720b66a> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Untethered and wirelessly-controlled micro-robots have been catching substantial attention for a long time due to their great potentials in biomedical areas. Their small sizes and property of wireless magnetic actuation and control make them fit in tiny and closed environments both in vitro and in vivo such as lab-on-a-chip and human blood vessels for micromanipulations, minimum/non-invasive theoretical and diagnostic applications, respectively. In recent years, micro-robots driven by magnetic fields become a hotspot due to their good controllability and motion performance they have shown in both wet and dry environments. And they hardly bring harm under magnetic actuation and control, which qualify them especially for biomedical applications. This paper reviews the state of the art of hjbvmagnetic-micro-robot systems, including the related knowledge and theories, design works of magnetic micro-robots and magnetic navigation systems. For a straightforward understanding, several types of magnetic micro-robot systems are presented. And some applications of magnetic micro-robot systems are introduced at the end to show their great potentials. However, for further developments, many obstacles still need to be solved." .
<http://www.springernature.com/scigraph/things/articles/213e12b2de87c7d5793167ac9048ce27> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Recently, a multi-level hp-version of the finite element method (FEM) was proposed to ease the difficulties of treating hanging nodes, while providing full hp-approximation capabilities. In the original paper, the refinement procedure made use of a-priori knowledge of the solution. However, adaptive procedures can produce discretizations which are more effective than an intuitive choice of element sizes h and polynomial degree distributions p. This is particularly prominent when a-priori knowledge of the solution is only vague or unavailable. The present contribution demonstrates that multi-level hp-adaptive schemes can be efficiently driven by an explicit a-posteriori error estimator. To this end, we adopt the classical residual-based error estimator. The main insight here is that its extension to multi-level hp-FEM is possible by considering the refined-most overlay elements as integration domains. We demonstrate on several two- and three-dimensional examples that exponential convergence rates can be obtained." .
<http://www.springernature.com/scigraph/things/articles/0d8c9c3cdef052ed5d733be9dddd90df> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract The ubiquitous cloud infrastructure different access methods are analyses to understand new message protocols that are used ubiquitous IoT mobile application environment that presented the cloud computing platform for mobile application. It supports a combined architecture of ubiquitous and cloud computing which provides a powerful framework for mobile application that requires high performance. The cloud infrastructure for ubiquitous computing environment mobile application (CI-UCEMA), which consist of three layers it cloud service layer (CSL), M2M service layer (MSL) and ubiquitous service layer (USL). The M2M consists of IoT services layer (MSL) will involve a decrease in complexity of both the improvement and controlling of IoT systems. This can be distinguished by improved interoperability and, carefully related, the improvement and use of normal. Security will also remain a grassroots regard as device management and provisioning are accomplished. The MSL is responsible for shielding the user from the underlying complexity and variability through self-tuning environment by mobility and adaptation which are points in CDPS and CIMS. The MSL components has human to object communication (HOC), human to human communication (HHC), object remote information device (OID) and micro M2M data access (M3DA). HOC has something concerned communications with PC, TV, PDA, Wearable PC, mobile phone and LTE black box. HHC supports services concerned with making same human to human communications environment in the everywhere. The UML (called uMain) is responsible for shielding the user from the underlying complexity and variability through self-tuning environment by mobility and adaptation which are points in cloud distributed parallel data processing service (CDPS) and cloud infrastructure management (CIMS). We have presented a system which gives a context-aware infrastructure that supports the gathering of context information from various simulations and the delivery of appropriate context information to mobile applications. Relevant simulations and experiments are given to evaluate the performance of the proposed system demand model. The CI-UCEMA is that have presented a ubiquitous computing environment on cloud computing platform for mobile application. This supports a combined architecture of ubiquitous and cloud computing this is a powerful framework for mobile applications along with high performance result." .
<http://www.springernature.com/scigraph/things/articles/e822f94709f40394cefc0d13321fd3d6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Military-led nation building campaigns can face many challenges as advances in certain aspects such as the economy and infrastructure may well be accompanied by setbacks in other areas such as security, making it difficult to judge overall progress. In this context, campaign assessments provide vital decision support for adapting strategy and deploying resources to best effect. The value of such assessments is enhanced when they report not only what has happened but why and when they also indicate likely future events—mirroring the three levels in Endsley’s model of Situation Awareness. Our aim is to develop a process for evaluating changes to the complex organisational structure and processes used for producing assessment documents, even if it is difficult to understand the linkages between such changes and output quality. Using 2 years’ worth of Australian Defence Force quarterly campaign assessments, we study the effect of adoption of a new analysis framework in their production. Using the conventions of thematic analysis and Endsley’s model of Situation Awareness, we introduce the Situation Awareness Elicitation method for obtaining metrics pertaining to the value of assessments before and after introduction of the framework and perform statistical analysis on this data." .
<http://www.springernature.com/scigraph/things/articles/7c125bdc08e445f6ec6fb6d852ecbf4b> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Periodicity is embedded in all societies. As most of us organize our lives based on temporal structures, it is hard to imagine what life would be like without it. We experience periodicity through naturally occurring rhythms that exist in nature, such as sunrise/sunset, seasonal changes in the weather, and the tides. We also experience it through abstract means via cultural, political, religious ties, such as the weekend, Independence Day, and Ramadan. Forms of periodicity, like the examples above, are foundational to making sense of human activity because they provide contextual rationale and frame normaility. However, disparate calendars (e.g. Islamic vs. Gregorian), localized idiosyncrasies, and other variables greatly complicate the analytical ability to uncover and understand human activity at a given time within a specified region. We have developed PerSE (Periodicity in Spatiotemporal Events): a web application designed to aid users in the detection and analysis of calendar related periodicity in spatiotemporal event data sets via exploratory user interaction. PerSE is composed of several crossfiltering views: the Map, Attribute View, Time-Wheel, Timeline, and Table. Users interactively set and release filters on one or more of the views to detect and analyze calendar related periodicity. This paper illustrates the utility of PerSE through an in-depth description of the tool and proof of concept usage example." .
<http://www.springernature.com/scigraph/things/articles/161bc0f8d940281575bb22d9137eefbd> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract This paper investigates coordinated scheduling on uniform parallel batch machines with batch transportation. Jobs are characterized by different processing time and sizes, and they are first delivered to manufacturers in batches and then processed on the uniform parallel batch machines. The manufacturers are distributed in different geographic zones and there exists one parallel batch machine in each manufacturer. A mixed integer programming model is developed for the studied problem, and its objective is to minimize the makespan. In addition, the structural properties of the problem are analyzed. A hybrid algorithm combining the merits of discrete particle swarm optimization (DPSO) and genetic algorithm (GA) is proposed to solve this problem. In the hybrid algorithm, a heuristic and a local search strategy are introduced. Finally, computational experiments are conducted and the results show that the proposed hybrid algorithm can effectively and efficiently solve the problem within a reasonable time, particularly in large-scale instances." .
<http://www.springernature.com/scigraph/things/articles/c7331de176b5a0b4bf5000cfd26be355> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Starting from a norm-contoured or star-shaped, bivariate vector distribution giving rise to a generalized (non-Euclidean) radius coordinate, the conditional density of the polar angle given the fixed radius variable is derived and visualized. A model is fitted to real life data." .
<http://www.springernature.com/scigraph/things/articles/c8a90ae3fb7e964036186cc28ab41ae6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Pseudo-centroid clustering replaces the traditional concept of a centroid expressed as a center of gravity with the notion of a pseudo-centroid (or a coordinate free centroid) which has the advantage of applying to clustering problems where points do not have numerical coordinates (or categorical coordinates that are translated into numerical form). Such problems, for which classical centroids do not exist, are particularly important in social sciences, marketing, psychology and economics, where distances are not computed from vector coordinates but rather are expressed in terms of characteristics such as affinity relationships, psychological preferences, advertising responses, polling data and market interactions, where distances, broadly conceived, measure the similarity (or dissimilarity) of characteristics, functions or structures. We formulate a K-PC algorithm analogous to a K-Means algorithm and focus on two key types of pseudo-centroids, MinMax-centroids and (weighted) MinSum-centroids, and describe how they, respectively, give rise to a K-MinMax algorithm and a K-MinSum algorithm which are analogous to a K-Means algorithm. The K-PC algorithms are able to take advantage of problem structure to identify special diversity-based and intensity-based starting methods to generate initial pseudo-centroids and associated clusters, accompanied by theorems for the intensity-based methods that establish their ability to obtain best clusters of a selected size from the points available at each stage of construction. We also introduce a regret-threshold PC algorithm that modifies the K-PC algorithm together with an associated diversification method and a new criterion for evaluating the quality of a collection of clusters." .
<http://www.springernature.com/scigraph/things/articles/d5399dabd9c07f287f2f71a67c7462cb> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Cloud is a collection of resources such as hardware, networks, servers, storage, applications, and interfaces to provide on-demand services to customers. Since access to cloud is through internet, data stored in clouds are vulnerable to attacks from external as well as internal intruders. In order to preserve privacy of the data in cloud, several intrusion detection approaches, authentication techniques, and access control policies are being used. The common intrusion detection systems are predominantly incompetent to be used in cloud environments. In this paper, the usage of type-2 fuzzy neural network based on genetic algorithm is discussed to incorporate intrusion detection techniques into cloud. These systems are intelligent to gain knowledge of fuzzy sets and fuzzy rules from data to detect intrusions in a cloud environment. Using a standard benchmark data from a cloud intrusion detection dataset experiments are done, tested, and compared with other existing approaches in terms of detection rate accuracy, precision, recall, MSE, and scalability." .
<http://www.springernature.com/scigraph/things/articles/8dec8b009227ddb4c8050957ab589d9f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Genome sequencing remains a challenge for species with large and complex genomes containing extensive repetitive sequences, of which the bulbous and monocotyledonous plants tulip and lily are examples. In such a case, sequencing of only the active part of the genome, represented by the transcriptome, is a good alternative to obtain information about gene content. In this study we aimed to generate a high quality transcriptome of tulip and lily and to make this data available as an open-access resource via a user-friendly web-based interface. The Illumina HiSeq 2000 platform was applied and the transcribed RNA was sequenced from a collection of different lily and tulip tissues, respectively. In order to obtain good transcriptome coverage and to facilitate effective data mining, assembly was done using different filtering parameters for clearing out contamination and noise of the RNAseq datasets. This analysis revealed limitations of commonly applied methods and parameter settings used in de novo transcriptome assembly. The final created transcriptomes are publicly available via a user friendly Transcriptome browser (http://www.bioinformatics.nl/bulbs/db/species/index). The usefulness of this resource has been exemplified by a search for all potential transcription factors in lily and tulip, with special focus on the TCP transcription factor family. This analysis and other quality parameters point out the quality of the transcriptomes, which can serve as a basis for further genomics studies in lily, tulip, and bulbous plants in general." .
<http://www.springernature.com/scigraph/things/articles/3128dce9e2d3996e33553218208bc314> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract People-flow counting is one of the key techniques of intelligence video surveillance systems and the information of people-flow obtained from this technique is an very important evidence for many applications, such as business analysis, staff planning, security, etc. Traditionally, the color image information based methods encounter kinds of challenges, such as shadows, illumination changing, cloth color, etc., while the depth information based methods suffer from lack of texture. In this paper, we propose an effective approach of people-flow counting by combining color and depth information. First, we adopt a background subtraction technique to fast obtain the moving regions on depth images. Second, the water filling algorithm is used to effectively detect head candidates on the moving regions. Then we use the SVM to recognize the real heads from the candidates. Finally, we adopt a weighted K Nearest Neighbor based multi-target tracking method to track each confirmed head and count the people through the surveillance region. Four datasets constructed from two surveillance scenes are used to evaluate the proposed method. Experimental results show that our method outperform the state-of-the-art methods. Our method can work stably on condition of kinds of interruptions and can not only obtain high precisions, but also high recalls on four datasets." .
<http://www.springernature.com/scigraph/things/articles/9199d9953103c8a27d1818b362ee223d> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Wasserstein barycenters correspond to optimal solutions of transportation problems for several marginals, and as such have a wide range of applications ranging from economics to statistics and computer science. When the marginal probability measures are absolutely continuous (or vanish on small sets) the theory of Wasserstein barycenters is well-developed [see the seminal paper (Agueh and Carlier in SIAM J Math Anal 43(2):904–924, 2011)]. However, exact continuous computation of Wasserstein barycenters in this setting is tractable in only a small number of specialized cases. Moreover, in many applications data is given as a set of probability measures with finite support. In this paper, we develop theoretical results for Wasserstein barycenters in this discrete setting. Our results rely heavily on polyhedral theory which is possible due to the discrete structure of the marginals. The results closely mirror those in the continuous case with a few exceptions. In this discrete setting we establish that Wasserstein barycenters must also be discrete measures and there is always a barycenter which is provably sparse. Moreover, for each Wasserstein barycenter there exists a non-mass-splitting optimal transport to each of the discrete marginals. Such non-mass-splitting transports do not generally exist between two discrete measures unless special mass balance conditions hold. This makes Wasserstein barycenters in this discrete setting special in this regard. We illustrate the results of our discrete barycenter theory with a proof-of-concept computation for a hypothetical transportation problem with multiple marginals: distributing a fixed set of goods when the demand can take on different distributional shapes characterized by the discrete marginal distributions. A Wasserstein barycenter, in this case, represents an optimal distribution of inventory facilities which minimize the squared distance/transportation cost totaled over all demands." .
<http://www.springernature.com/scigraph/things/articles/915d9f1c2f431e61fed1b586f7d5fff1> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Frequency-domain photoacoustic radar (FD-PAR) imaging of absorbers in turbid media and their comparison and/or validation as well as co-registration with their corresponding ultrasound (US) images are demonstrated in this paper. Also presented are the FD-PAR tomography and the effects of reducing the number of scan lines (or angles) on image quality, resolution, and contrast. The FD-PAR modality uses intensity-modulated (coded) continuous wave laser sources driven by frequency-swept (chirp) waveforms. The spatial cross-correlation function between the PA response and the reference signal used for laser source modulation produces the reconstructed image. Live animal testing is demonstrated, and images of comparable signal-to-noise ratio, contrast, and spatial resolution were obtained. Various image improvement techniques to further reduce absorber spread and artifacts in the images such as normalization, filtering, and amplification were also investigated. The co-registered image produced from the combined US and PA images provides more information than both images independently. The significance of this work lies in the fact that achieving PA imaging functionality on a commercial ultrasound instrument could accelerate its clinical acceptance and use. This work is aimed at functional PA imaging of small animals in vivo." .
<http://www.springernature.com/scigraph/things/articles/0a5b74f95fa977436bd72acf9e432b08> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Formulae to compute the mutual potential, force, and torque between two rigid bodies are given. These formulae are expressed in Cartesian coordinates using inertia integrals. They are valid for rigid bodies with arbitrary shapes and mass distributions. By using recursive relations, these formulae can be easily implemented on computers. Comparisons with previous studies show their superiority in computation speed. Using the algorithm as a tool, the planar problem of two ellipsoids is studied. Generally, potential truncated at the second order is good enough for a qualitative description of the mutual dynamics. However, for ellipsoids with very large non-spherical terms, higher order terms of the potential should be considered, at the cost of a higher computational cost. Explicit formulae of the potential truncated to the fourth order are given." .
<http://www.springernature.com/scigraph/things/articles/843473fdfed2dbdc0f70a11aa5b913f8> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Neuronavigation has become an essential neurosurgical tool in pursuing minimal invasiveness and maximal safety, even though it has several technical limitations. Augmented reality (AR) neuronavigation is a significant advance, providing a real-time updated 3D virtual model of anatomical details, overlaid on the real surgical field. Currently, only a few AR systems have been tested in a clinical setting. The aim is to review such devices. We performed a PubMed search of reports restricted to human studies of in vivo applications of AR in any neurosurgical procedure using the search terms “Augmented reality” and “Neurosurgery.” Eligibility assessment was performed independently by two reviewers in an unblinded standardized manner. The systems were qualitatively evaluated on the basis of the following: neurosurgical subspecialty of application, pathology of treated lesions and lesion locations, real data source, virtual data source, tracking modality, registration technique, visualization processing, display type, and perception location. Eighteen studies were included during the period 1996 to September 30, 2015. The AR systems were grouped by the real data source: microscope (8), hand- or head-held cameras (4), direct patient view (2), endoscope (1), and X-ray fluoroscopy (1) head-mounted display (1). A total of 195 lesions were treated: 75 (38.46 %) were neoplastic, 77 (39.48 %) neurovascular, and 1 (0.51 %) hydrocephalus, and 42 (21.53 %) were undetermined. Current literature confirms that AR is a reliable and versatile tool when performing minimally invasive approaches in a wide range of neurosurgical diseases, although prospective randomized studies are not yet available and technical improvements are needed." .
<http://www.springernature.com/scigraph/things/articles/175cde5a10f543f746540baea2bac911> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Block-matching algorithms (BMAs) are widely employed for motion estimation. BMAs divide input frames into several blocks and minimize an error function for each block to calculate motion vectors. Afterward, each motion vector is applicable for all of the pixels within the block. Since computing the error functions is resource intensive, many fast-search motion estimation algorithms have been suggested to reduce the computational cost. These fast algorithms provide a significant reduction in computation but often converge to a local minimum. A learning automaton is an adaptive decision-making unit that learns the optimal action through repeated interactions with its environment. Learning automata (LA) have been applied successfully to a wide range of applications including pattern recognition, dynamic channel assignment, and social network analysis. In this paper, we apply LA to motion estimation problem, which is one of the basic problems in computer vision. We compare the accuracy and performance of the suggested algorithms with other well-known BMAs. Interestingly, the obtained results indicate high efficiency and accuracy of the proposed methods. The results suggest that simplicity, efficiency, parallel nature, and accuracy of LA-based methods make them a good candidate to solve computer vision problems." .
<http://www.springernature.com/scigraph/things/articles/59257827a8790526d4fa5d78a55d8166> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract In large-scale online open participative (LSOOP) activities, participants can join and leave at any time, and they often do not have a history of working together. Although the communication history is usually accessible to the participants in the environment, it is time consuming for them to process the communication data because of the large volume of messages. These characteristics make it difficult for one to keep track of, identify, and interpret the others’ ideas, opinions, and their rationales in LSOOP activities. We argue for a computational approach that automatically identifies and extracts the rationales from LSOOP communication data and presents them to the participants through rationale-based awareness tools. In this paper we bring together different and hitherto independent lines of research, and propose to use them in a conceptual framework integrating three analytical aspects related to the detection of rationales: linguistic, informational, and argumentative and communicative. We also review the design effort on offering rationale-based awareness in the LSOOP activities." .
<http://www.springernature.com/scigraph/things/articles/730c2c8978e147346897521fd570a4fb> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Advanced learning technologies are reaching a new phase of their evolution where they are finally entering mainstream educational contexts, with persistent user bases. However, as AIED scales, it will need to follow recent trends in service-oriented and ubiquitous computing: breaking AIED platforms into distinct services that can be composed for different platforms (web, mobile, etc.) and distributed across multiple systems. This will represent a move from learning platforms to an ecosystem of interacting learning tools. Such tools will enable new opportunities for both user-adaptation and experimentation. Traditional macro-adaptation (problem selection) and step-based adaptation (hints and feedback) will be extended by meta-adaptation (adaptive system selection) and micro-adaptation (event-level optimization). The existence of persistent and widely-used systems will also support new paradigms for experimentation in education, allowing researchers to understand interactions and boundary conditions for learning principles. New central research questions for the field will also need to be answered due to these changes in the AIED landscape." .
<http://www.springernature.com/scigraph/things/articles/883d046be222db64e8c6a1d15e86bf35> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract BackgroundIt is extremely common to need to select a subset of reads from a BAM file based on their specific properties. Typically, a user unpacks the BAM file to a text stream using SAMtools, parses and filters the lines using AWK, then repacks them using SAMtools. This process is tedious and error-prone. In particular, when working with many columns of data, mix-ups are common and the bit field containing the flags is unintuitive. There are several libraries for reading BAM files, such as Bio-SamTools for Perl and pysam for Python. Both allow access to the BAM’s read information and can filter reads, but require substantial boilerplate code; this is high overhead for mostly ad hoc filtering. ResultsWe have created a query language that gathers reads using a collection of predicates and common logical connectives. Queries run faster than equivalents and can be compiled to native code for embedding in larger programs. ConclusionsBAMQL provides a user-friendly, powerful and performant way to extract subsets of BAM files for ad hoc analyses or integration into applications. The query language provides a collection of predicates beyond those in SAMtools, and more flexible connectives." .
<http://www.springernature.com/scigraph/things/articles/86357d867c28bc2077b1e54a14d40ef3> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Data outsourcing service has gained remarkable popularity with considerable amount of enterprises and individuals, as it can relief heavy computation and management burden locally. While in most existing models, honest-but-curious cloud service provider (CSP) may return incorrect results and inevitably give rise to serious security breaches, thus the results verification mechanism should be raised to guarantee data accuracy. Furthermore, the construction of secure-channel incurs heavy cryptographic operations and single keyword search returns many irrelevant results. Along these directions, we further design a significantly more effective and secure cryptographic primitive called as verifiable conjunctive keywords search over encrypted data without secure-channel scheme to assure data integrity and availability. Formal security analysis proves that it can effectively stand against outside keyword-guessing attack. As a further contribution, our actual experiments show that it can admit wide applicability in practice." .
<http://www.springernature.com/scigraph/things/articles/00142ec45fb7842ff420709894a372b7> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract In recent years, graphics processing units (GPUs) have emerged as a powerful architecture for solving a broad spectrum of applications in very short periods of time. However, most existing GPU optimization approaches do not exploit the full power available in a CPU–GPU platform. They have a tendency to leave one of them partially unused (usually the CPU) and fail to establish an accurate exchange of information that could help solve the target problem efficiently. Thus, better performance is expected from devising a hybrid CPU–GPU parallel algorithm that combines the highly parallel stream processing power of GPUs with the higher power of multi-core architectures. We have developed a hybrid methodology to efficiently solve optimization problems. We use a hybrid CPU–GPU architecture, to benefit from running it, in parallel, on both the CPU and the GPU. Our experiments over a heterogeneous set of combinatorial optimization problems with increasing dimensionality show a time gain of up to $$365\\times $$ 365× in our proposal, while demonstrating high numerical accuracy. This work is intended to open up a new line of research that matches both architectures with new algorithms and cooperation techniques." .
<http://www.springernature.com/scigraph/things/articles/011e8aeeeb91ce3917872053e6a946e4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The greedy spanner is the highest quality geometric spanner (in e.g. edge count and weight, both in theory and practice) known to be computable in polynomial time. Unfortunately, all known algorithms for computing it on n points take $$\\varOmega (n^2)$$ Ω(n2) time, limiting its applicability on large data sets. We propose a novel algorithm design which uses the observation that for many point sets, the greedy spanner has many ‘short’ edges that can be determined locally and usually quickly. To find the usually few remaining ‘long’ edges, we use a combination of already determined local information and the well-separated pair decomposition. We give experimental results showing large to massive performance increases over the state-of-the-art on nearly all tests and real-life data sets. On the theoretical side we prove a near-linear expected time bound on uniform point sets and a near-quadratic worst-case bound. Our bound for point sets drawn uniformly and independently at random in a square follows from a local characterization of t-spanners we give on such point sets. We give a geometric property that holds with high probability, which in turn implies that if an edge set on these points has t-paths between pairs of points ‘close’ to each other, then it has t-paths between all pairs of points. This characterization gives an $$O(n \\log ^2 n \\log ^2 \\log n)$$ O(nlog2nlog2logn) expected time bound on our greedy spanner algorithm, making it the first subquadratic time algorithm for this problem on any interesting class of points. We also use this characterization to give an $$O((n + |E|) \\log ^2 n \\log \\log n)$$ O((n+|E|)log2nloglogn) expected time algorithm on uniformly distributed points that determines whether E is a t-spanner, making it the first subquadratic time algorithm for this problem that does not make assumptions on E." .
<http://www.springernature.com/scigraph/things/articles/57bbfc6865bca29a2af6b70cc2b2035e> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract White-box cryptography (WBC) aims to resist attacks from attackers who can control all the implementation details of cryptographic schemes. In 2009, Saxena et al. proposed a fundamental of white-box cryptography via the notion “white-box property” (WBP). Under this model, they proved that there do not exist obfuscators that can satisfy every security notion for a program (the negative result). On the other hand, they proved that there exists an obfuscator satisfying WBP for some security notion (the positive result). These contributions provide us a general cognition of WBC, which is big progress for the theoretical research. To better understand them, we make discussion on each result and achieve some new results. For the negative result, we prove that insufficiently secure obfuscator is the real cause of the negative result. We point out that the security of a white-box scheme cannot be guaranteed if it is instantiated by a less secure obfuscator, since the obfuscator used in their proof does not satisfy the “Virtual Black-box Property” with auxiliary input. From our proof, we also conclude that the notion WBP is equal to “Virtual Black-box Property with auxiliary input”. For the positive result, we prove that security notion under black-box model should not be used in white-box context without any modification; although the positive result is meaningful, it is unlikely to prove that an obfuscator satisfies WBP for IND-CPA, since the security notion “IND-CPA” is under black-box model, which has different adversary with WBP." .
<http://www.springernature.com/scigraph/things/articles/816bf699b8c4a06300164488cd08a60e> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract System of systems (SoS) architecting is the process of bringing together and connecting a set of systems so that the collection of the systems, i.e., the SoS is equipped with a set of required capabilities. A system is defined as inflexible in case it contributes to the SoS with all of the capabilities it can provide. On the other hand, a flexible system can collaborate with the SoS architect in the capabilities it will provide. In this study, we formulate and analyze a SoS architecting problem representing a military mission planning problem with inflexible and flexible systems as a multi-objective mixed-integer-linear optimization model. We discuss applications of an exact and an evolutionary method for generating and approximating the Pareto front of this model, respectively. Furthermore, we propose a decomposition approach, which decomposes the problem into smaller sub-problems by adding equality constraints, to improve both the exact and the evolutionary methods. Results from a set of numerical studies suggest that the proposed decomposition approach reduces the computational time for generating the exact Pareto front as well as it reduces the computational time for approximating the Pareto front while not resulting in a worse approximated Pareto front. The proposed decomposition approach can be easily used for different problems with different exact and heuristic methods and thus is a promising tool to improve the computational time of solving multi-objective combinatorial problems. Furthermore, a sample scenario is presented to illustrate the effects of system flexibility." .
<http://www.springernature.com/scigraph/things/articles/a9e0704fdf95d1bc49a5732f3e7925ed> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract A relational dependency network (RDN) is a directed graphical model widely used for multi-relational data. These networks allow cyclic dependencies, necessary to represent relational auto-correlations. We describe an approach for learning both the RDN’s structure and its parameters, given an input relational database: First learn a Bayesian network (BN), then transform the Bayesian network to an RDN. Thus fast Bayesian network learning translates into fast RDN learning. The BN-to-RDN transform comprises a simple, local adjustment of the Bayesian network structure and a closed-form transform of the Bayesian network parameters. This method can learn an RDN for a dataset with a million tuples in minutes. We empirically compare our approach to a state-of-the-art RDN learning approach that applies functional gradient boosting, using six benchmark datasets. Learning RDNs via BNs scales much better to large datasets than learning RDNs with current boosting methods." .
<http://www.springernature.com/scigraph/things/articles/128642cd5e4838aca7f048a9422b4743> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract A new general method of computational electromagnetism based on extremizing the electromagnetic action using the geometric algebra of space-time is described. Special cases include a boundary element method and a finite element method. These methods are derived and discussed, computational examples given, and compared with some well known methods of computational electromagnetism." .
<http://www.springernature.com/scigraph/things/articles/2bef8a5499743aef4ef26a6a63cf722a> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Whether they thrive as they grow must be determined for all constantly expanding networks. However, few studies have focused on this important network feature or the development of quantitative analytical methods. Given the formation and growth of the global container-shipping network, we proposed the concept of network temporal robustness and quantitative method. As an example, we collected container liner companies’ data at two time points (2004 and 2014) and built a shipping network with ports as nodes and routes as links. We thus obtained a quantitative value of the temporal robustness. The temporal robustness is a significant network property because, for the first time, we can clearly recognize that the shipping network has become more vulnerable to damage over the last decade: When the node failure scale reached 50% of the entire network, the temporal robustness was approximately −0.51% for random errors and −12.63% for intentional attacks. The proposed concept and analytical method described in this paper are significant for other network studies." .
<http://www.springernature.com/scigraph/things/articles/e35555073c26ee473b2a9313470090bf> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract This work investigates the attitude control of reentry vehicle under modeling inaccuracies and external disturbances. A robust adaptive fuzzy PID-type sliding mode control (AFPID-SMC) is designed with the utilization of radial basis function (RBF) neural network. In order to improve the transient performance and ensure small steady state tracking error, the gain parameters of PID-type sliding mode manifold are adjusted online by using adaptive fuzzy logic system (FLS). Additionally, the designed new adaptive law can ensure that the closed-loop system is asymptotically stable. Meanwhile, the problem of the actuator saturation, caused by integral term of sliding mode manifold, is avoided even under large initial tracking error. Furthermore, to eliminate the need of a priori knowledge of the disturbance upper bound, RBF neural network observer is used to estimate the disturbance information. The stability of the closed-loop system is proved via Lyapunov direct approach. Finally, the numerical simulations verify that the proposed controller is better than conventional PID-type SMC in terms of improving the transient performance and robustness." .
<http://www.springernature.com/scigraph/things/articles/ae8079809a86c2bbef4cd33f92c0f1b6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Fingerprint has been widely used in a variety of biometric identification systems in the past several years due to its uniqueness and immutability. With the rapid development of fingerprint identification techniques, many fingerprint identification systems are in urgent need to deal with large-scale fingerprint storage and high concurrent recognition queries, which bring huge challenges to the system. In this circumstance, we design and implement a distributed and load-balancing fingerprint identification system named Pegasus, which includes a distributed feature extraction subsystem and a distributed feature storage subsystem. The feature extraction procedure combines the Hadoop Image Processing Interface (HIPI) library to enhance its overall processing speed; the feature storage subsystem optimizes MongoDB’s default load balance strategy to improve the efficiency and robustness of Pegasus. Experiments and simulations are carried out, and results show that Pegasus can reduce the time cost by 70% during the feature extraction procedure. Pegasus also balances the difference of access load among front-end mongos nodes to less than 5%. Additionally, Pegasus reduces over 40% of data migration among back-end data shards to obtain a more reasonable data distribution based on the operation load (insertion, deletion, update, and query) of each shard." .
<http://www.springernature.com/scigraph/things/articles/b2605005aa27609bc11d094a6a365ebe> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract State-of-the-art image classification approaches are mainly based on robust image representation, such as the bag-of-features (BoF) model or the convolutional neural network (CNN) architecture. In real applications, the orientation (left/right) of an image or an object might vary from sample to sample, whereas some handcrafted descriptors (e.g., SIFT) and network operations (e.g., convolution) are not reversal-invariant, leading to the unsatisfied stability of image features extracted from these models. To deal with, a popular solution is to augment the dataset by adding a left-right reversed copy for each image. This strategy improves the recognition accuracy to some extent, but also brings the price of almost doubled time and memory consumptions on both the training and testing stages. In this paper, we present an alternative solution based on designing reversal-invariant representation of local patterns, so that we can obtain the identical representation for an image and its left-right reversed copy. For the BoF model, we design a reversal-invariant version of SIFT descriptor named Max-SIFT, a generalized RIDE algorithm which can be applied to a large family of local descriptors. For the CNN architecture, we present a simple idea of generating reversal-invariant deep features (RI-Deep), and, inspired by which, design reversal-invariant convolution (RI-Conv) layers to increase the CNN capacity without increasing the model complexity. Experiments reveal consistent accuracy gain on various image classification tasks, including scene understanding, fine-grained object recognition, and large-scale visual recognition." .
<http://www.springernature.com/scigraph/things/articles/c065e5dddf0a947719caab939b179def> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract In the past 10 years, the independent and innovative communications-based train control system has experienced breakthroughs in key technologies by conducting pilot experiments, field tests, and demonstration projects. For the first time, the design theories and technical aspects of moving block systems, which cover the entire life cycle of fail-safe systems, are set up. The models and algorithms are proposed to control the safe operation of trains. The safety technologies for short-interval train sequencing are adopted to realize the 90 s headway between consecutive trains. The optimized automatic train operation strategies are used to save energy and allow trains to safely reach their destinations. The highly dependable and bi-directional train-to-ground communication technologies are introduced for reliable transmission of safety related train-to-ground information in a complex environment which is compatible with multiple media, such as free waves, leaky waveguides, and leaky feeders. The simulation, tests, and verification technologies based on the minimum system and test cases were adopted to conduct the following: principle demonstration, functional tests, integrated tests, field failure data replay, analysis and disposal, system upgrade, and maintenance." .
<http://www.springernature.com/scigraph/things/articles/657bc40f1b945fcca0faccbb1acc4a57> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We present a technique for efficient stateless model checking of programs that execute under the relaxed memory models TSO and PSO. The basis for our technique is a novel representation of executions under TSO and PSO, called chronological traces. Chronological traces induce a partial order relation on relaxed memory executions, capturing dependencies that are needed to represent the interaction via shared variables. They are optimal in the sense that they only distinguish computations that are inequivalent under the widely-used representation by Shasha and Snir. This allows an optimal dynamic partial order reduction algorithm to explore a minimal number of executions while still guaranteeing full coverage. We apply our techniques to check, under the TSO and PSO memory models, LLVM assembly produced for C/pthreads programs. Our experiments show that our technique reduces the verification effort for relaxed memory models to be almost that for the standard model of sequential consistency. This article is an extended version of Abdulla et al. (Tools and algorithms for the construction and analysis of systems, Springer, New York, pp 353–367, 2015), appearing in TACAS 2015." .
<http://www.springernature.com/scigraph/things/articles/34281fe37653b1b3d9835733f4d93292> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Blasting is important and an essential prerequisite in any opencast mine for fragmenting hard deposits. Blasting always produces unwanted effects like ground vibrations, noise and fly rock; among which ground vibrations effect is more on surrounding structures. Propagation of ground vibrations can lead to destruction of surrounding structures. Prediction of ground vibrations especially in terms of peak particle velocity is beneficial as opposed to conventional data monitoring techniques which can be expensive as well as time consuming. This paper uses predictors to estimate the intensity of ground vibrations and compares different methods of prediction methods like linear regression, multiple linear regression, non linear regression (NLR) and artificial neural networks. Intensity of ground vibrations generated from blasting operations was monitored in three different mines of limestone, dolomite and coal; obtaining about 168 ground vibration recordings in total. The statistical modelling or data-driven modeling has shown promise in the prediction of blast vibrations. Proposed a system of introducing site specific rock parameters like poison’s ratio, uniaxial compressive strength of rock and Young’s modulus to improve the correlation coefficient using statistical modelling (commonly called feature engineering in machine learning circles)." .
<http://www.springernature.com/scigraph/things/articles/dc53043ded8032a5fa13372559f7b3ad> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract For integers k ≥1 and n≥2k+1 the Kneser graph K(n;k) has as vertices all k-element subsets of [n]:={1;2;:::;n} and an edge between any two vertices (=sets) that are disjoint. The bipartite Kneser graph H(n,k) has as vertices all k-element and (n—k)-element subsets of [n] and an edge between any two vertices where one is a subset of the other. It has long been conjectured that all Kneser graphs and bipartite Kneser graphs except the Petersen graph K(5, 2) have a Hamilton cycle. The main contribution of this paper is proving this conjecture for bipartite Kneser graphs H(n,k). We also establish the existence of cycles that visit almost all vertices in Kneser graphs K(n,k) when n=2k+o(k), generalizing and improving upon previous results on this problem." .
<http://www.springernature.com/scigraph/things/articles/ce679993d99f058dee79f04610bb8acd> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract In this paper we show the use of commutative operads in public-key cryptography. Commutative operads were introduced by S.N. Tronin in 2006. They are a special case of algebraic operads and a natural generalization of commutative algebraic theories. We consider some cryptographic protocols based on commutative operads. For the protocol of the creation a common secret key, we describe and investigate its implementation and cryptographic security in particular cases." .
<http://www.springernature.com/scigraph/things/articles/c50b2ce7a376bda35e9898c49b36a960> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract To improve localization accuracy, device-free passive localization studies usually deploy a number of sensor nodes in indoor environments, which causes redundant features and produces large data volumes and high deployment costs. This paper proposes the concept of a two-level redundancy and formulates the node reduction problem as a redundancy control problem. With the goal of using fewer nodes while maintaining high localization accuracy, a method is proposed to control the two-level redundancy efficiently and reduce the number of nodes greatly. Experiments are performed in two completely different environments. The proposed method is able to maintain accuracy levels above 90% and can efficiently reduce the total number of nodes by 59.09% in a large room (150 $${\\mathrm{m}}^2$$ m2 ) and by 68.75% in a small room (25 $${\\mathrm{m}}^2$$ m2 ). Furthermore, due to reduced nodes the proposed method can drastically reduce the needed amount of localization data and the hardware costs." .
<http://www.springernature.com/scigraph/things/articles/2477b50f62cba1280d2d910ce248e26b> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract A face-spoofing attack occurs when an imposter manipulates a face recognition and verification system to gain access as a legitimate user by presenting a 2D printed image or recorded video to the face sensor. This paper presents an efficient and non-intrusive method to counter face-spoofing attacks that uses a single image to detect spoofing attacks. We apply a nonlinear diffusion based on an additive operator splitting scheme. Additionally, we propose a specialized deep convolution neural network that can extract the discriminative and high-level features of the input diffused image to differentiate between a fake face and a real face. Our proposed method is both efficient and convenient compared with the previously implemented state-of-the-art methods described in the literature review. We achieved the highest reported accuracy of 99% on the widely used NUAA dataset. In addition, we tested our method on the Replay Attack dataset which consists of 1200 short videos of both real access and spoofing attacks. An extensive experimental analysis was conducted that demonstrated better results when compared to previous static algorithms results. However, this result can be improved by applying a sparse autoencoder learning algorithm to obtain a more distinguishable diffused image." .
<http://www.springernature.com/scigraph/things/articles/434913e62f85444edeb50f98b7f0b877> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Steiner tree problems (STPs) are very important in both theory and practice. In this paper, we introduce a powerful swap-vertex move operator which can be used as a basic element of any neighborhood search heuristic to solve many STP variants. Given the incumbent solution tree T, the swap-vertex move operator exchanges a vertex in T with another vertex out of T, and then attempts to construct a minimum spanning tree, leading to a neighboring solution (if feasible). We develop a series of dynamic data structures, which allow us to efficiently evaluate the feasibility of swap-vertex moves. Additionally, in order to discriminate different swap-vertex moves corresponding to the same objective value, we also develop an auxiliary evaluation function. We present a computational assessment based on a number of challenging problem instances (corresponding to three representative STP variants) which clearly shows the effectiveness of the techniques introduced in this paper. Particularly, as a key element of our KTS algorithm which participated in the 11th DIMACS implementation challenge, the swap-vertex operator as well as the auxiliary evaluation function contributed significantly to the excellent performance of our algorithm." .
<http://www.springernature.com/scigraph/things/articles/5c64f845d72de28db7954426da1121c4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract At present, to realize or improve the quality of experience (QoE) is a major goal for network media transmission service, and QoE evaluation is the basis for adjusting the transmission control mechanism. Therefore, a kind of QoE collaborative evaluation method based on fuzzy clustering heuristic algorithm is proposed in this paper, which is concentrated on service score calculation at the server side. The server side collects network transmission quality of service (QoS) parameter, node location data, and user expectation value from client feedback information. Then it manages the historical data in database through the “big data” process mode, and predicts user score according to heuristic rules. On this basis, it completes fuzzy clustering analysis, and generates service QoE score and management message, which will be finally fed back to clients. Besides, this paper mainly discussed service evaluation generative rules, heuristic evaluation rules and fuzzy clustering analysis methods, and presents service-based QoE evaluation processes. The simulation experiments have verified the effectiveness of QoE collaborative evaluation method based on fuzzy clustering heuristic rules." .
<http://www.springernature.com/scigraph/things/articles/8601901e757944a6876420077f9cfffc> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We study the Reliable Broadcast problem in incomplete networks against a Byzantine adversary. We examine the problem under the locally bounded adversary model of Koo (Proceedings of the 23rd annual ACM symposium on principles of distributed computing, PODC ’04, St. John’s, Newfoundland, Canada, 25–28 July 2004, ACM New York pp 275–282, 2004) and the general adversary model of Hirt and Maurer (Proceedings of the 16th annual ACM symposium on principles of distributed computing, PODC ’97, Santa Barbara, California, USA, August 21–24, 1997 ACM, New York pp 25–34, 1997) and explore the tradeoff between the level of topology knowledge and the solvability of the problem. In order to explore this tradeoff we introduce the partial knowledge model which captures the situation where each player has arbitrary topology knowledge. We refine the local pair-cut technique of Pelc and Peleg (Inf Process Lett 93(3):109–115, 2005) in order to obtain impossibility results for every level of topology knowledge and any type of corruption distribution. On the positive side we devise protocols that match the obtained bounds, and thus, exactly characterize the classes of graphs in which Reliable Broadcast is possible. Among others, we show that Koo’s Certified Propagation Algorithm (CPA) is unique, against locally bounded adversaries in ad hoc networks, among all safe algorithms, i.e., algorithms which never cause a node to decide on an incorrect value. This means that CPA can tolerate as many local corruptions as any other safe algorithm; this settles an open question posed by Pelc and Peleg. We also provide an adaptation of CPA achieving reliable broadcast against general adversaries and prove that this algorithm too is unique under this model. To the best of our knowledge this is the first optimal algorithm for Reliable Broadcast in generic topology ad hoc networks against general adversaries." .
<http://www.springernature.com/scigraph/things/articles/daed860ce0939e69f895770aac06da32> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract There is a growing recognition that various planning agencies in warranty system sectors have a significant interest in measuring and forecasting the growth of green warranty claims. The difficulties lie in finding a forecasting model that can incorporate both internal and external influences on green warranty diffusion, as well as an acceptable measure for green warranty growth. This paper uses models based on the knowledge of traditional diffusion theories as well as artificial neural networks. Additionally, it integrates the two into a hybrid model in order to study green warranty growth. A count of warranty claims is used as a reliable measure of green warranty growth in all the models. This paper demonstrates that a simple Neural Network model, if properly calibrated, can create a very flexible response function to forecast green warranty diffusion. The neural network model successfully modeled both the internal and external influences in the warranty data, while the traditional formulations could only model the internal influences. The predictive validation of the results was enhanced by replicating the comparisons on simulated data with various degrees of external influence. This paper suggests that when there are external influences such as green warranty, the neural network model will be superior to the best traditional diffusion model." .
<http://www.springernature.com/scigraph/things/articles/44015daee7708dc92b9230e70ef98e26> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract In order to fully utilize all potential available network resources and make the interoperability of systems possible, we propose to integrate cloud computing and peer-to-peer (P2P) computing environments together. We utilize the mobile multi-agent technology to construct an effective hierarchical integration model named Cloud-P2P. As the original management mechanisms for traditional cloud computing and P2P computing systems are no longer applicable to Cloud-P2P, we propose a novel hybrid collaborative management ring based on mobile multi-agent in order to ensure the efficiency and success rate of task implementation in the Cloud- P2P environment. This mechanism needs to divide the system into core ring, cloud inner rings and several peer rings. In each ring, every node is in collaboration with its neighbor nodes with multi-agent, or uses mobile agent moving from node to node with string or parallel methods to monitor the statuses and performances of all nodes, in order to avoid problems of performance bottleneck and single point failure. This paper analyses the node conditions of cloud computing and P2P computing environments in-depth, then elaborates on Cloud-P2P and the hybrid collaborative management ring based on mobile multi-agent (HCMRMMA). After that, the construction method of the network ring topology for Cloud-P2P is introduced. Finally, experimental results and performance analysis of HCMRMMA are presented." .
<http://www.springernature.com/scigraph/things/articles/25e7fb8dde95de6181769f894fb8a688> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Mobile cloud storage service is used for users’ multimedia content data sharing or synchronization in effective way with several mobile devices. To save various content data in the mobile cloud storage, the matters of security should be treated in the process of data sharing to provide flexibility and expandability for solving its heterogeneousness. Currently, the cloud storage service generally encrypts the content data for the security. However, this method is not perfectly safe for it manages ID, password, and encryption key simply with software; thus it may accept unauthorized users. This research suggests the data access control model and the method for multimedia content sharing and security based on XMDR-DAI in the mobile cloud storage. It supports key management based on hardware, identification for the integrity of client software, and security key sharing. Also, the suggested model saves/manages different types of multimedia content, thus it establishes XMDR-DAI-based metadata relationship for the problems that occurred in searching to increase the reliability. And this research suggests the prototype using TPM emulator that is operated in secure world of ARM TrustZone and TrustZone environment." .
<http://www.springernature.com/scigraph/things/articles/1fe763ae1ba678adea865a8898dc12c6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Recently, Liu and Xue proposed a secure two-party password-based authenticated key exchange protocol by utilizing the semi-group property of the Chebyshev chaotic maps. We exploit the vulnerability of the protocol in this paper by illustrating an off-line password guessing attack. In this attack, the password of a honest user will be recover by an attacker without being noticed by the server or the victim. To overcome such problem, we propose a simple and compatible fix." .
<http://www.springernature.com/scigraph/things/articles/aa9633d2f678230e92a27665cafc4d0f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We present a declarative framework for the compilation of constraint logic programs into variable-free relational theories which are then executed by rewriting. This translation provides an algebraic formulation of the abstract syntax of logic programs. Logic variables, unification, and renaming apart are completely elided in favor of manipulation of variable-free relation expressions. In this setting, term rewriting not only provides an operational semantics for logic programs, but also a simple framework for reasoning about program execution. We prove the translation sound, and the rewriting system complete with respect to traditional SLD semantics." .
<http://www.springernature.com/scigraph/things/articles/7428ebcbbb7aa8749b0fff71bca2e863> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract Supervisory Control and Data Acquisition (SCADA) systems are widely used in critical infrastructures such as water distribution networks, electricity generation and distribution plants, oil refineries, nuclear plants, and public transportation systems. However, the increased use of standard protocols and interconnectivity has exposed SCADA systems for potential cyber-attacks. In recent years, the cyber-security of SCADA systems has become a hot issue for governments, industrial sectors and academic community. Recently some security solutions have been proposed to secure SCADA systems. However, due to the critical nature of SCADA systems, evaluation of such proposed solutions on real system is im-practical. In this paper, we proposed an easily scalable and reconfigurable virtual SCADA security testbed, which can be used for developing and evaluating SCADA specific security solutions. With Distributed Denial of Service (DDoS) and false data injection attack scenarios, we demonstrated how attackers could disrupt the normal operation of SCADA systems. Experimental results show that, the pro-posed testbed can be effectively used for cyber security assessment and vulner-ability investigation on SCADA systems. One of the outcomes of this work is a labeled dataset, which can be used by researchers in the area of SCADA security." .
<http://www.springernature.com/scigraph/things/articles/c0f8ed9cccb54ad05ed08fa4715ffd89> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract In 3D video, view synthesis is used to create new virtual views between encoded camera views. Errors in the coding of the depth maps introduce geometry inconsistencies in synthesized views. In this paper, a new 3D plane representation of the scene is presented which improves the performance of current standard video codecs in the view synthesis domain. Two image segmentation algorithms are proposed for generating a color and depth segmentation. Using both partitions, depth maps are segmented into regions without sharp discontinuities without having to explicitly signal all depth edges. The resulting regions are represented using a planar model in the 3D world scene. This 3D representation allows an efficient encoding while preserving the 3D characteristics of the scene. The 3D planes open up the possibility to code multiview images with a unique representation." .
<http://www.springernature.com/scigraph/things/articles/6a3157f5a962169bd9dc417f2de376b5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Delivery of information to highly dynamic nodes is a big challenge in vehicular ad hoc networks (VANETs). Existing location management protocols for VANET maintain locations of mobile nodes, but they exploit mobile vehicles as location servers, which increases location server changes and reduces stability. In this paper collaborative vehicle location management service (CVLMS) for an enhanced hybrid reactive and proactive multicast (EHRPM) facilitates knowing the location information of the moving destinations. EHRPM uses speeds, length, and densities of roads to choose the least delivery delay path. Existing information dissemination in VANETs does not discuss how location servers are used in localization. CVLMS exploits roadside units (RSUs) in cashing and dissemination of locations and dissemination of multicast messages. CVLMS guarantees stability using static RSUs that maintain locations to overcome multiple location server change problem. Location tables are stored in multiple RSUs which maintain load distribution. CVLMS provides an infrastructure platform which enables collaboration of RSUs to exchange locations. Scalability of the CVLMS is provided by increasing the number of vehicles and still gives high-performance results. Results demonstrate that CVLMS outperforms grid location service, intersection location service, Dynamic MANET On-demand with RSUs, and time-based vehicle-to-roadside unit communication in terms of packet delivery ratio, packet loss ratio, end-to-end delay, and overhead." .
<http://www.springernature.com/scigraph/things/articles/d62f380cb1b2995046148abfa302777f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract In a world where trusting software systems is increasingly important, formal methods and formal proof can help provide some basis for trust. Proof checking can help to reduce the size of the trusted base since we do not need to trust an entire theorem prover: instead, we only need to trust a (smaller and simpler) proof checker. Many approaches to building proof checkers require embedding within them a full programming language. In most modern proof checkers and theorem provers, that programming language is a functional programming language, often a variant of ML. In fact, aspects of ML (e.g., strong typing, abstract datatypes, and higher-order programming) were designed to make ML a trustworthy “meta-language” for checking proofs. While there is considerable overlap between logic programming and proof checking (e.g., both benefit from unification, backtracking search, efficient term structures, etc.), the discipline of logic programming has, in fact, played a minor role in the history of proof checking. I will argue that logic programming can have a major role in the future of this important topic." .
<http://www.springernature.com/scigraph/things/articles/bb0035ddfde9f5bcf183a8eb651f40b5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We provide an approach to formally analyze the computational behavior of coroutines in logic programs and to compile these computations into new programs, not requiring any support for coroutines. The problem was already studied near to 30 years ago, in an analysis and transformation technique called compiling control. However, this technique had a strong ad hoc flavor: the completeness of the analysis was not well understood and its symbolic evaluation was also rather ad hoc. We show how abstract conjunctive partial deduction, introduced by Leuschel in 2004, provides an appropriate setting to redefine compiling control. We define an abstract domain and all abstract operations required by abstract conjunctive partial deduction. We prove that these concepts satisfy all the correctness conditions imposed by the framework and therefore inherit its main correctness theorem. We also show that there exist more complex coroutining examples which do not fit within abstract conjunctive partial deduction and we propose some further extensions to include them." .
<http://www.springernature.com/scigraph/things/articles/d745ac09cf0d6d46a3234ba44a8b766e> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Computing the mechanical response of materials requires accurate constitutive descriptions, especially their plastic behavior. Furthermore, the ability of a model to be used as a predictive, rather than a descriptive, tool motivates the development of physically based constitutive models. This work investigates combining a homogenized viscoplastic self-consistent (VPSC) approach to reduce the development time for a high-resolution viscoplastic model based on the fast Fourier transform (FFT). An optimization scheme based on a least-squares algorithm is presented. The constitutive responses of copper, interstitial-free steel, and pearlite are investigated, and the model parameters are presented. Optimized parameters from the low-fidelity model provide close agreement (<2 MPa, ~1 % error) with stress-strain data at low strains (<10 %) in the high-fidelity FFT model. Simple adjustments to constitutive law parameters bring the FFT stress-strain curve in alignment with experimental data at strains greater than 10 %. A two-phase constitutive law is developed for a pearlitic steel using a single stress-strain curve, supplemented by data for the constituent phases. Sources of error and methods of using material information are discussed that lead to optimal estimates of initial parameter values." .
<http://www.springernature.com/scigraph/things/articles/a60f3d713d6ae598cac126528e9011f6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We contribute to the theoretical understanding of randomized search heuristics by investigating their optimization behavior on satisfiable random k-satisfiability instances both in the planted solution model and the uniform model conditional on satisfiability. Denoting the number of variables by n, our main technical result is that the simple ($$1+1$$ 1+1 ) evolutionary algorithm with high probability finds a satisfying assignment in time $$O(n \\log n)$$ O(nlogn) when the clause-variable density is at least logarithmic. For low density instances, evolutionary algorithms seem to be less effective, and all we can show is a subexponential upper bound on the runtime for densities below $$\\frac{1}{k(k-1)}$$ 1k(k-1) . We complement these mathematical results with numerical experiments on a broader density spectrum. They indicate that, indeed, the ($$1+1$$ 1+1 ) EA is less efficient on lower densities. Our experiments also suggest that the implicit constants hidden in our main runtime guarantee are low. Our main result extends and considerably improves the result obtained by Sutton and Neumann (Lect Notes Comput Sci 8672:942–951, 2014) in terms of runtime, minimum density, and clause length. These improvements are made possible by establishing a close fitness-distance correlation in certain parts of the search space. This approach might be of independent interest and could be useful for other average-case analyses of randomized search heuristics. While the notion of a fitness-distance correlation has been around for a long time, to the best of our knowledge, this is the first time that fitness-distance correlation is explicitly used to rigorously prove a performance statement for an evolutionary algorithm." .
<http://www.springernature.com/scigraph/things/articles/3e49bea3e270e79c19b62473548074da> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Mobile robot networks emerged in the past few years as a promising distributed computing model. Existing work in the literature typically ensures the correctness of mobile robot protocols via ad hoc handwritten proofs, which, in the case of asynchronous execution models, are both cumbersome and error-prone. Our contribution is twofold. We first propose a formal model to describe mobile robot protocols operating in a discrete space i.e., with a finite set of possible robot positions, under synchrony and asynchrony assumptions. We translate this formal model into the DVE language, which is the input format of the model-checkers DiVinE and ITS tools, and formally prove the equivalence of the two models. We then verify several instances of two existing protocols for variants of the ring exploration in an asynchronous setting: exploration with stop and perpetual exclusive exploration. For the first protocol we refine the correctness bounds and for the second one, we exhibit a counter-example. This protocol is then modified and we establish the correctness of the new version with an inductive proof." .
<http://www.springernature.com/scigraph/things/articles/eba222c199daec2b038ff2b64fdde8d1> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The NP-hard Effectors problem on directed graphs is motivated by applications in network mining, particularly concerning the analysis of probabilistic information-propagation processes in social networks. In the corresponding model the arcs carry probabilities and there is a probabilistic diffusion process activating nodes by neighboring activated nodes with probabilities as specified by the arcs. The point is to explain a given network activation state as well as possible by using a minimum number of “effector nodes”; these are selected before the activation process starts. We correct, complement, and extend previous work from the data mining community by a more thorough computational complexity analysis of Effectors, identifying both tractable and intractable cases. To this end, we also exploit a parameterization measuring the “degree of randomness” (the number of ‘really’ probabilistic arcs) which might prove useful for analyzing other probabilistic network diffusion problems as well." .
<http://www.springernature.com/scigraph/things/articles/9f193957d085133e01faa2fd175a92c2> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Internet search data could be a useful source of information for policymakers when formulating decisions based on their understanding of the current economic environment. This paper builds on earlier literature via a structured value assessment of the data provided by Google Trends. This is done through two empirical exercises related to the forecasting of changes in UK unemployment. Firstly, economic intuition provides the basis for search term selection, with a resulting Google indicator tested alongside survey‐based variables in a traditional forecasting environment. Secondly, this environment is expanded into a pseudo‐time nowcasting framework which provides the backdrop for assessing the timing advantage that Google data have over surveys. The framework is underpinned by a MIDAS regression which allows, for the first time, the easy incorporation of Internet search data at its true sampling rate into a nowcast model for predicting unemployment." .
<http://www.springernature.com/scigraph/things/articles/381d5921f7f87fba3bd90bfebbea4f88> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract R. Lavi and C. Swamy (FOCS 2005, J. ACM 58(6), 25, 2011) introduced a general method for obtaining truthful-in-expectation mechanisms from linear programming based approximation algorithms. Due to the use of the Ellipsoid method, a direct implementation of the method is unlikely to be efficient in practice. We propose to use the much simpler and usually faster multiplicative weights update method instead. The simplification comes at the cost of slightly weaker approximation and truthfulness guarantees." .
<http://www.springernature.com/scigraph/things/articles/cc67a9b25b36e5e6c5829ac03333d180> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "The aim of this research is to propose a framework for classifying 14 quality management tools based on quality principles. For this purpose, multi‐criteria decision‐making, importance performance analysis and a survey on 13 process owners of Marjan Tile Company have been conducted. Based on the findings, three packages have been proposed for quality management tools as: 1) relation diagram and process decisions planning chart; 2) check sheets, Pareto diagram, cause and effect diagram, histograms and tree diagram; 3) control chart, procedure diagram, matrix analysis of data, matrix diagrams, scatter diagram, affinity diagram and diagram of concentration of defects." .
<http://www.springernature.com/scigraph/things/articles/e4c82336f0c853aa81e3eb8346c5d1b0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract BackgroundTwo point four out of 100 people suffer from one or more fractures in the course of average lifetimes. Traditional casts are featured as cumbersome structures that result in high risk of cutaneous complications. Clinical demands for developing a hygienic cast have gotten more and more attention. 3D printing technique is rapidly growing in the fabrication of custom-made rehabilitation tools. The objective of this study is to develop a rapid and intelligent modeling technique for developing patient-specific and hygienic orthopedic casts produced by 3D printing technologies. ResultsA cast model is firstly created from a patient’s image to develop patient-specific features. A unique technique to creating geometric reference has been developed to perform detail modeling cast. The cast is modeled as funnel-shaped geometry to create smooth edges to prevent bruises from mild movements of injured limbs. Surface pattern includes ventilation structure and opening gap for hygienic purpose and wearing comfort. The cast can be adjusted to accommodate swelling from injured limbs during treatment. Finite element analysis (FEA) is employed to validate the mechanical performance of the cast structure and identify potential risk of the structural collapse due to concentrated stresses. The cast is fabricated by 3D printing technology using approval material. ConclusionsThe 3D-printed prototype is featured as super lightweight with 1/10 of weight in compared with traditional alternatives. Medical technicians with few experiences can design cast within 20 min using the proposed technique. The image-based design minimizes the distortion during healing process because of the best fit geometry. The highly ventilated structure develops hygienic benefits on reducing the risk of cutaneous complications and potentially improve treatment efficacy and increase patients’ satisfactions." .
<http://www.springernature.com/scigraph/things/articles/530bd07ca5d0cbce7e29882287e42987> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract In multi-agent system (MAS) applications, teamwork among the agents is essential as the agents are required to collaborate and pool resources to execute the given tasks and complete the objectives successfully. A vital part of the collaboration is sharing of information and resources in order to optimize their efforts in achieving the given objectives. Under such collaborative environment, trust among the agents plays a critical role to ensure efficient cooperation. This study looks into developing a trust evaluation model that can empirically evaluate the trust of one agent on the other. The proposed model is developed using temporal difference learning method, incorporating experience gained through interactions into trust evaluation. Simulation experiments are conducted to evaluate the performance of the developed model against some of the most recent models reported in the literature. The results of the simulation experiments indicate that the proposed model performs better than the comparison models in estimating trust more effectively." .
<http://www.springernature.com/scigraph/things/articles/38492e194cec8451d1d52e9707538152> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Internal users are the main causes of anomalous and suspicious behaviors in a communication network. Even when traditional security middleboxes are present, internal attacks may lead the network to outages or to leakage of sensitive information. In this article, we propose BroFlow, an Intrusion Detection and Prevention System based on Bro traffic analyzer and on the global network view of the software-defined networks (SDN) which is provided by the OpenFlow. BroFlow main contributions are (i) dynamic and elastic resource provision of traffic-analyzing machines under demand; (ii) real-time detection of DoS attacks through simple algorithms implemented in a policy language for network events; (iii) immediate reaction to DoS attacks, dropping malicious flows close of their sources, and (iv) near-optimal placement of sensors through a proposed heuristic for strategically positioning sensors in the network infrastructure, which is shared by multi-tenants, with a minimum number of sensors. We developed a prototype of the proposed system, and we evaluated it in a virtual environment of the Future Internet Testbed with Security (FITS). An evaluation of the system under attack shows that BroFlow guarantees the forwarding of legitimate packets at the maximal link rate, reducing up to 90 % of the maximal network delay caused by the attack. BroFlow reaches 50 % of bandwidth gain when compared with conventional firewalls approaches, even when the attackers are legitimate tenants acting in collusion. In addition, the system reduces the sensors number, while keeping full coverage of network flows." .
<http://www.springernature.com/scigraph/things/articles/4327a6d60ed62071aa78384ad1a7a506> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Flooding-based protocols are a reliable solution to deliver packets in underwater sensor networks. However, these protocols potentially involve all the nodes in the forwarding process. Thus, the performance and energy efficiency are not optimal. In this work, we propose some advances of a flooding-based protocol with the goal to improve the performance and the energy efficiency. The first idea considers the node position information in order to reduce the number of relays that may apply flooding. Second, a network coding-based protocol is proposed in order to make a better use of the duplicates. With network coding, each node in the network recombines a certain number of packets into one or more output packets. This may give good results in flooding-based protocols considering the high amount of packets that are flooded in the network. Finally, a fusion of both ideas is considered in order to exploit the benefits of both of them." .
<http://www.springernature.com/scigraph/things/articles/72d858a6b788967e8443e9fb71de9402> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Digital Earth is a global reference model for integrating, processing and visualizing geospatial datasets. In this reference model, various data-types, including Digital Elevation Models (DEM) and imagery (orthophotos), are universally and openly available for the entire globe. However, 3D content such as detailed terrains with features, man-made structures, 3D water bodies and 3D vegetation are not commonly available in Digital Earth. In this paper, we present an interactive system for the rapid creation and integration of these types of 3D content to augment Digital Earth. The inputs to our system include available data sources, such as DEM and imagery information depicting landscapes and urban environments. The proposed system employs sketch-based and image-assisted tools to support interactive creation of textured 3D content. For adding terrain features visible in orthophotos, and also the basin of water bodies, we use a multiscale least square surface fitting to generate an adaptive triangular subdivision. For modeling forests and vegetation, we use image-based techniques and take advantage of visible regions and colors of forests in orthophotos. For 3D man-made structures, starting from a single photograph, we provide a simple image-assisted sketching tool to extract these objects, correct for perspective distortion and place them into desired locations." .
<http://www.springernature.com/scigraph/things/articles/63f9accc81826b4eb1631a8337453670> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Humans use many modalities such as face, speech and body gesture to express their feeling. So, to make emotional computers and make the human-computer interaction (HCI) more naturally and friendly, computers should be able to understand human feelings using speech and visual information. In this paper, we recognize the emotions from audio and visual information using fuzzy ARTMAP neural network (FAMNN). Audio and visual systems fuse at decision and feature levels. Finally, the particle swarm optimization (PSO) is employed to determine the optimum values of the choice parameter (α), the vigilance parameters (ρ), and the learning rate (β) of the FAMNN. Experimental results showed that the feature-level and decision-level fusions improve the outcome of unimodal systems. Also PSO improved the recognition rate. By using the PSO-optimized FAMNN at feature level fusion, the recognition rate was improved by about 57 % with respect to the audio system and by about 4.5 % with respect to the visual system. The final emotion recognition rate on the SAVEE database was reached to 98.25 % using audio and visual features by using optimized FAMNN." .
<http://www.springernature.com/scigraph/things/articles/3d89c6ee8edb3bdedc62a6b4a02612c2> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract With the increasing number of geographically distributed scientific collaborations and the growing sizes of scientific data, it has become challenging for users to achieve the best possible network performance on a shared network. We have developed a model to forecast expected bandwidth utilization on high-bandwidth wide area networks. The forecast model can improve the efficiency of the resource utilization and scheduling of data movements on high-bandwidth networks to accommodate ever increasing data volume for large-scale scientific data applications. A univariate time-series forecast model is developed with the Seasonal decomposition of Time series by Loess (STL) and the AutoRegressive Integrated Moving Average (ARIMA) on Simple Network Management Protocol (SNMP) path utilization measurement data. Compared with the traditional approach such as Box-Jenkins methodology to train the ARIMA model, our forecast model reduces computation time up to 92.6 %. It also shows resilience against abrupt network usage changes. Our forecast model conducts the large number of multi-step forecast, and the forecast errors are within the mean absolute deviation (MAD) of the monitored measurements." .
<http://www.springernature.com/scigraph/things/articles/20355a1dd5c5ba00794ff5d0556d54b4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract The emerging area of mobile cloud computing will influence the future of varied applications, such as electronic commerce and health informatics. It is expected to rise in popularity over other models in cloud computing. This is facilitated by its simplicity, accessibility and ease of use. With mobile cloud computing, resource-constrained mobile devices could capitalize on the computation/storage resources of cloud servers via communication networks. Despite the advantage of this innovative computing model, mobile devices in mobile cloud computing are open to more security risks because they often have to access cloud servers through untrusted networks from different locations. Therefore, security is a critical problem to be tackled in mobile cloud computing. One of the most important aspects of mobile cloud computing security is to establish authenticated communication sessions between mobile devices and cloud servers. In this paper, we present a novel authentication scheme, Message Digest-based Authentication (MDA). Technically, MDA strategically incorporates hashing, in addition to traditional user ID and passwords, to achieve mutual authentication. The effectiveness of MDA is validated with Scyther, a widely-used security protocol analyzer. Our experimental results indicate that MDA is capable of withstanding a variety of different security attacks, such as man-in-the-middle, replay attacks, etc." .
<http://www.springernature.com/scigraph/things/articles/a87cc3ef9cb91e76e4e88394ed360692> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract A computing grid interconnects resources such as high performance computers, scientific databases, and computercontrolled scientific instruments of cooperating organizations each of which is autonomous. It precedes and is quite different from cloud computing, which provides computing resources by vendors to customers on demand. In this article, we describe the grid computing model and enumerate the major differences between grid and cloud computing." .
<http://www.springernature.com/scigraph/things/articles/7c83df374aaf4ff09593eb709a24cbc2> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Detection of salient objects in an image is now gaining increasing research interest in computer vision community. In this study, a novel region-contrast based saliency detection solution involving three phases is proposed. First, a color-based super-pixels segmentation approach is used to decompose the image into regions. Second, three high-level saliency measures which could effectively characterize the salient regions are evaluated and integrated in an effective manner to produce the initial saliency map. Finally, we construct a pairwise graphical model to encourage that adjacent image regions with similar features take continuous saliency values, thus producing the more perceptually consistent saliency map. We extensively evaluate the proposed method on three public benchmark datasets, and show it can produce promising results when compared to 14 state-of-the-art salient object detection approaches." .
<http://www.springernature.com/scigraph/things/articles/dff237184cb785bead3e334db82f615f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract In this work, we use algebraic methods for studying distance computation and subgraph detection tasks in the congested clique model. Specifically, we adapt parallel matrix multiplication implementations to the congested clique, obtaining an $$O(n^{1-2/\\omega })$$ O(n1-2/ω) round matrix multiplication algorithm, where $$\\omega < 2.3728639$$ ω<2.3728639 is the exponent of matrix multiplication. In conjunction with known techniques from centralised algorithmics, this gives significant improvements over previous best upper bounds in the congested clique model. The highlight results include:1.triangle and 4-cycle counting in $$O(n^{0.158})$$ O(n0.158) rounds, improving upon the $$O(n^{1/3})$$ O(n1/3) algorithm of Dolev et al. [DISC 2012],2.a $$(1 + o(1))$$ (1+o(1)) -approximation of all-pairs shortest paths in $$O(n^{0.158})$$ O(n0.158) rounds, improving upon the $$\\tilde{O} (n^{1/2})$$ O~(n1/2) -round $$(2 + o(1))$$ (2+o(1)) -approximation algorithm given by Nanongkai [STOC 2014], and3.computing the girth in $$O(n^{0.158})$$ O(n0.158) rounds, which is the first non-trivial solution in this model. In addition, we present a novel constant-round combinatorial algorithm for detecting 4-cycles." .
<http://www.springernature.com/scigraph/things/articles/294fc0812f74d1d1d836d004d19b60c9> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Identifying critical nodes in complex networks aims to fragment a graph $$G = (V, E)$$ G=(V,E) by removing a set of vertices R with cardinality $$\\left| R \\right| \\le $$ R≤ k, such that the residual graph has minimum pairwise connectivity. Existing optimization algorithms are incapable of finding a good set R in complex networks. By investigating the role of nodes, a minimum dominating set approach is considered in controlling a network. This paper presents an algorithmic procedure to compute the critical nodes using a novel minimum connected dominating set, in which the critical nodes are identified based on the number of close subsequences. Through experimental verification on some randomly generated networks and comparing with the similar algorithms, the results showed that the proposed algorithm has high capability of identifying the critical nodes and low time complexity." .
<http://www.springernature.com/scigraph/things/articles/7dfe9f6f4674ddc91c542c0c58977d90> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "This paper seeks to investigate maritime cargo logistics using customer‐oriented service quality analysis, determine service quality improvement strategies for liner‐carrier‐based global logistics companies, and establish the priority of service improvements based on weights calculated by combining fuzzy set theory with quality function deployment. This paper also seeks to relay customers' voices to these companies in order to help them achieve a maximal improvement effect. The findings of this study were as follows: 1) customers pay close attention to the accuracy and efficiency of responses to their inquiries from the companies' sales staff, especially when new customers make first‐time inquiries; 2) companies should stress the education and training of their personnel in order to improve their competitive advantage and sustainability; 3) sales departments play a very important role in the improvement of customer service quality at liner‐carrier‐based global logistics companies." .
<http://www.springernature.com/scigraph/things/articles/4be7c49b30fe1a7d0b2d2e33f12808cc> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The goal of this paper is to demonstrate the various models of perspective anamorphosis used in the visual arts, which are also applicable to stage design. Through comparative analysis, borderline conditions emerge through which certain perspective models assume traits of anamorphosis, as well as conditions for their use in stage design. The idea is to provide practical instructions which are usable on the stage. This effort saw the use of constructive perspective methods, projective and descriptive geometry, while retaining a pictorial and an optical-physiological perspective. The examples of stage design that are shown in the paper are mostly from the National Theatre in Belgrade, the oldest theatre in Belgrade, and an institution that collaborates with the Faculty of Applied Arts. The perspective models of anamorphosis, analysed here, were chosen according to the unique features of the stage and its elements, which include: a perspective image projected on multiple planes, relief perspective as the anamorphosis of space, and the cylindrical perspective." .
<http://www.springernature.com/scigraph/things/articles/f29f92425e0f910b283e720c4a54edbf> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract This paper presents a review of the literature on generating cutting paths for laser cutting machines. Firstly, the cutting path problem is defined including all relevant technical side constraints which exist plentifully in laser cutting. Secondly, a former classification method is updated to include all types of cutting path problems. Thirdly, a comprehensive review of solution methods and related applications is presented. Throughout the literature review, trends in research in cutting path generation and interesting areas for future research are identified." .
<http://www.springernature.com/scigraph/things/articles/d4f4a940f18d19a3be158c8eaae1de1c> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Metamaterials composed of artificial subwavelength structures exhibit extraordinary properties that cannot be found in nature. Designing artificial structures having exceptional properties plays a pivotal role in current metamaterial research. We present a new numerical simulation scheme for metamaterial research. The scheme is based on a graphic processing unit (GPU)-accelerated finite-difference time-domain (FDTD) method. The FDTD computation can be significantly accelerated when GPUs are used instead of only central processing units (CPUs). We explain how the fast FDTD simulation of large-scale metamaterials can be achieved through communication optimization in a heterogeneous CPU/GPU-based computer cluster. Our method also includes various advanced FDTD techniques: the non-uniform grid technique, the total-field/scattered-field (TFSF) technique, the auxiliary field technique for dispersive materials, the running discrete Fourier transform, and the complex structure setting. We demonstrate the power of our new FDTD simulation scheme by simulating the negative refraction of light in a coaxial waveguide metamaterial." .
<http://www.springernature.com/scigraph/things/articles/5969470fc41151fea3dccf3759bafeb4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Résumé Réaliser une césarienne en urgence est un événement assez fréquent en maternité. La rapidité d’exécution est dictée par le niveau potentiel de souffrance de l’enfant à naître. Chaque pays a essayé de définir des délais idéaux de réalisation. Cette contrainte de temps peut impacter négativement la prise en charge de la douleur de la mère et son vécu. L’optimisation de la prise en charge passe par une réflexion sur les conditions logistiques et techniques du déroulement ainsi que sur l’amélioration de la communication verbale et non verbale." .
<http://www.springernature.com/scigraph/things/articles/4a4c91727296dcac79e2cc56af8effcf> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The authors propose a new method to solve classification problem based on separation of two sets in space R d . The necessary and sufficient conditions of ε-separability are proved. The algorithm of constructing two separable ε-nets of size [2d / ε] is proposed. The paper contains an example of applying this algorithm to two sets generated from normally distributed sets. The classification results for the proposed method and for support vector machines are compared." .
<http://www.springernature.com/scigraph/things/articles/afdce88edbd9007964d709c420926ebf> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Depth First Search (DFS) tree is a fundamental data structure for graphs used in solving various algorithmic problems. However, very few results are known for maintaining DFS tree in a dynamic environment—insertion or deletion of edges. We present the first algorithm for maintaining a DFS tree for an undirected graph under insertion of edges. For processing any arbitrary online sequence of edge insertions, this algorithm takes total $$O(n^2)$$ O(n2) time." .
<http://www.springernature.com/scigraph/things/articles/fb1af4d75d8e372e2cc04f3114871229> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Understanding the behavior of users in online systems is of essential importance for sociology, system design, e-commerce, and beyond. Most existing models assume that individuals in diverse systems, ranging from social networks to e-commerce platforms, tend to what is already popular. We propose a statistical time-aware framework to identify the users who differ from the usual behavior by being repeatedly and persistently among the first to collect the items that later become hugely popular. Since these users effectively discover future hits, we refer them as discoverers. We use the proposed framework to demonstrate that discoverers are present in a wide range of real systems. Once identified, discoverers can be used to predict the future success of new items. We finally introduce a simple network model which reproduces the discovery patterns observed in the real data. Our results open the door to quantitative study of detailed temporal patterns in social systems." .
<http://www.springernature.com/scigraph/things/articles/588837cac6b08144534d7f97cde0c2b6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Private comparison is fundamental to secure multiparty computation. In this study, we propose novel protocols to privately determine $$x>y, x<y$$ x>y,x<y , or $$x=y$$ x=y in one execution. First, a 0–1-vector encoding method is introduced to encode a number into a vector, and the Goldwasser–Micali encryption scheme is used to compare integers privately. Then, we propose a protocol by using a geometric method to compare rational numbers privately, and the protocol is information-theoretical secure. Using the simulation paradigm, we prove the privacy-preserving property of our protocols in the semi-honest model. The complexity analysis shows that our protocols are more efficient than previous solutions." .
<http://www.springernature.com/scigraph/things/articles/0f9d5ed49b3857c5614de424014c7ca9> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract We give generic constructions of several fundamental cryptographic primitives based on a new encryption primitive that combines circular security for bit encryption with the so-called reproducibility property (Bellare et al. in Public key cryptography—PKC 2003, vol. 2567, pp. 85–99, Springer, 2003). At the heart of our constructions is a novel technique which gives a way of de-randomizing reproducible public-key bit encryption schemes and also a way of reducing one-wayness conditions of a constructed trapdoor function family (TDF) to circular security of the base scheme. The main primitives that we build from our encryption primitive include k-wise one-way TDFs (Rosen and Segev in SIAM J Comput 39(7):3058–3088, 2010), chosen-ciphertext-attack-secure encryption and deterministic encryption. Our results demonstrate a new set of applications of circularly secure encryption beyond fully homomorphic encryption and symbolic soundness. Finally, we show the plausibility of our assumptions by showing that the decisional Diffie–Hellman-based circularly secure scheme of Boneh et al. (Advances in cryptology—CRYPTO 2008, vol. 5157, Springer, 2008) and the subgroup indistinguishability-based scheme of Brakerski and Goldwasser (Advances in cryptology—CRYPTO 2010, vol. 6223, pp. 1–20, Springer, 2010) are both reproducible." .
<http://www.springernature.com/scigraph/things/articles/be5ede69ea8122c02cc7b7757d10604d> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Quality assessment of a protein model is to predict the absolute or relative quality of a protein model using computational methods before the native structure is available. Single-model methods only need one model as input and can predict the absolute residue-specific quality of an individual model. Here, we have developed four novel single-model methods (Wang_deep_1, Wang_deep_2, Wang_deep_3, and Wang_SVM) based on stacked denoising autoencoders (SdAs) and support vector machines (SVMs). We evaluated these four methods along with six other methods participating in CASP11 at the global and local levels using Pearson’s correlation coefficients and ROC analysis. As for residue-specific quality assessment, our four methods achieved better performance than most of the six other CASP11 methods in distinguishing the reliably modeled residues from the unreliable measured by ROC analysis; and our SdA-based method Wang_deep_1 has achieved the highest accuracy, 0.77, compared to SVM-based methods and our ensemble of an SVM and SdAs. However, we found that Wang_deep_2 and Wang_deep_3, both based on an ensemble of multiple SdAs and an SVM, performed slightly better than Wang_deep_1 in terms of ROC analysis, indicating that integrating an SVM with deep networks works well in terms of certain measurements." .
<http://www.springernature.com/scigraph/things/articles/5885af4bb0385a08c4dba538af950441> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract This paper presents an effective method which needs free parameters as little as possible to autonomously extract the weld seam profile and edges from the molten background in two kinds of weld images within robotic MAG welding. First, orientation saliency detection produced by Gabor filtering nicely highlights the weld seam profile and edges from the molten background. Then, an unsupervised clustering algorithm combing a cluster validity index via an optimization rule, referred to as parameter self-optimizing clustering, is applied to discern the weld seam profile and edges from interference data after the orientation saliency detection result is given threshold segmentation. The validity index is better than the classical ones in two kinds of data sets through considerable tests. Last, two common applications of weld seam identification demonstrate the effectiveness of the proposed method." .
<http://www.springernature.com/scigraph/things/articles/06674226fda0c760b730711cede442a8> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Zusammenfassung Zukünftige Produktionskonzepte basieren zunehmend auf Mensch-Roboter-Kooperationsarbeitsplätzen ohne trennende Schutzeinrichtungen. Der Mensch und der Roboter teilen sich einen gemeinsamen Arbeitsraum und arbeiten je nach Anwendungsszenario auch Hand in Hand. Eine Verletzung des Menschen durch einen Roboter muss dabei sicher vermieden werden. Nach einer Einführung in das Thema und der Darstellung prinzipieller Lösungsansätze für neue Technologien zur Mensch-Roboter-Kooperation wird ein Überblick über die aktuelle Normenlage gegeben und das Forschungsfeld der biomechanischen Grenzwertbestimmung und der Kollisionsmessung beschrieben. Des Weiteren werden neue Technologien vorgestellt, die zukünftig die sichere Mensch-Roboter-Kooperation ermöglichen können." .
<http://www.springernature.com/scigraph/things/articles/f86c37a1829f6d86623794588a846639> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Drucker (Proceedings of the 53rd annual symposium on foundations of computer science (FOCS), pp 609–618. doi:10.1109/FOCS.2012.71, 2012) proved the following result: Unless the unlikely complexity-theoretic collapse $$\\mathsf {coNP}\\subseteq \\mathsf {NP/poly}$$ coNP⊆NP/poly occurs, there is no AND-compression for SAT. The result has implications for the compressibility and kernelizability of a whole range of NP-complete parameterized problems. We present a streamlined proof of Drucker’s theorem. An AND-compression is a deterministic polynomial-time algorithm that maps a set of SAT-instances $$x_1,\\ldots ,x_t$$ x1,…,xt to a single SAT-instance y of size $${\\text {poly}}(\\max _i|x_i|)$$ poly(maxi|xi|) such that y is satisfiable if and only if all $$x_i$$ xi are satisfiable. The “AND” in the name stems from the fact that the predicate “y is satisfiable” can be written as the AND of all predicates “$$x_i$$ xi is satisfiable”. Drucker’s theorem complements the result by Bodlaender et al. (J Comput Syst Sci 75:423–434, 2009) and Fortnow and Santhanam (J Comput Syst Sci 77:91–106, 2011), who proved the analogous statement for OR-compressions, and Drucker’s proof not only subsumes their result but also extends it to randomized compression algorithms that are allowed to have a certain probability of failure. Drucker (Proceedings of the 53rd annual symposium on foundations of computer science (FOCS), pp 609–618. doi:10.1109/FOCS.2012.71, 2012) presented two proofs: The first uses information theory and the minimax theorem from game theory, and the second is an elementary, iterative proof that is not as general. In our proof, we realize the iterative structure as a generalization of the arguments of Ko (J Comput Syst Sci 26:209–211, 1983) for $$\\mathsf {P}$$ P -selective sets, which use the fact that tournaments have dominating sets of logarithmic size. We generalize this fact to hypergraph tournaments. Our proof achieves the full generality of Drucker’s theorem, avoids the minimax theorem, and restricts the use of information theory to a single, intuitive lemma about the average noise sensitivity of compressive maps. To prove this lemma, we use the same information-theoretic inequalities as Drucker." .
<http://www.springernature.com/scigraph/things/articles/91edc9e02ab5a61366f813fca666da27> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract This paper reconstructs human model from multi-view RGB-D images of an Xbox One Kinect. We preprocess the depth images by implicit surface de-noising and then part-wisely register them into a point cloud. A template model is selected from the human model database to fit the registered point cloud of a human body by Laplacian deformation. Skin detection of RGB-D images helps to tightly constrain the skin parts of human body in template fitting step in order to get more precise and lifelike human model. We propose a robust skin detection method that is not affected by clothing pattern and background. Experiments demonstrate the effectiveness of our method." .
<http://www.springernature.com/scigraph/things/articles/8a8c337b205aacfe9d10d1b3f7ec3a67> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Zusammenfassung In modernen Kryptosystemen gewinnen elliptische Kurven (ECs) auf der Basis von endlichen Körpern zunehmend an Bedeutung. Als elementare Einführung werden die ECs zuerst in der Domäne der reellen Zahlen erklärt und ihre Eigenschaften besprochen. Das Problem, von einem Kurvenpunkt ausgehend eine Tangente an eine EC zu legen, wird mittels der Nullstellen eines Polynoms vierten Grades allgemein gelöst. Aus drei Punkten auf einer EC wird das erzeugende Polynom der Kurve berechnet. Die Arithmetik mit EC-Punkten wird in herkömmlicher Weise mit dem Bild der Addition von EC-Punkten verknüpft und die Bedeutung der ganzzahligen Vielfachen eines EC-Punktes für die kryptografischen Zwecke erläutert. Dem Programm zur Synthese des Vielfachen eines EC-Punktes wird ein Analyseprogramm zur Seite gestellt, das von einem Vielfachen den Wert des angewendeten Faktors bestimmt, wobel von der Lösung des Tangentenproblems Gebrauch gemacht wird. In der Domäne der rationalen Zahlen wird die Funktionsweise der Programme demonstriert und gezeigt, dass unter diesen Umständen das Analyseprogramm immer zu einer eindeutigen Lösung kommt. Zur Beschränkung der Zahlenwerte, aber auch zur Verkürzung der Programmlaufzeiten, werden zwei Mechanismen ins Auge gefasst und auf alle Zwischenergebnisse mit rationalen Zahlen angewendet. Das eine Mal werden die rationalen Zahlen als Ganzes durch eine Restklassenrechnung auf die ganzen Zahlen in einem endlichen Körper zurückgeführt, wobei sich de facto die Umstände der traditionellen EC-Anwendungen ergeben. Für diesen Ansatz spricht, dass die theoretischen Grundlagen der endlichen Körper mathematisch bestens fundiert sind. Der alternative Vorschlag besteht darin, bei allen rationalen Zahlen die Zähler und Nenner unabhängig voneinander in eine ganzzahlige Restklasse zu projizieren und den rationalen Charakter bei allen Zahlen bewusst beizubehalten. Von dieser Variante wird erwartet, dass sie in Hinblick auf die vorgeführten, eindeutigen Lösungen bei der Punktanalyse in der Domäne der rationalen Zahlen von besonderem Vorteil sein kann, was allerdings noch genauer zu untersuchen ist. Schließlich wird ein lapidarer Vergleich mit den Exponentialfunktionen vorgenommen. Die Arbeit verwendet das Programmsystem Mathematica als Plattform, auf der auch die eigenen Programme unmittelbar ablauffähig sind. Die angegebenen Programmlaufzeiten wurden mit Hilfe einer Mathematica-Prozedur evaluiert, wobei Optimierungen lediglich andiskutiert bleiben." .
<http://www.springernature.com/scigraph/things/articles/5ea74695c39d2293ccbed25389d479b8> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract The segmentation of symptoms during image analysis of diseased plant leaves is an essential process for detection and classification of diseases. However, there are challenges involved in the task, many of them related to the variability of image and host/symptom characteristics and conditions. As a result of those challenges, the methods proposed in the literature so far focus on a specific problem and are usually bounded by tight constraints regarding image capture conditions. This research explores a new automatic method for segmenting disease symptoms on plant leaves that was designed to be applicable in a wide range of situations. The proposed technique employs only color channel manipulations and Boolean operations applied on binary masks, thus being simpler and more robust compared to many previously described automatic methods. Its effectiveness is demonstrated by tests performed over a large database containing images of 77 different diseases of 11 plant species. A comparison with manual segmentation is also presented, further reinforcing the advantages of the proposed approach." .
<http://www.springernature.com/scigraph/things/articles/4384c6afa571dfc02c6326cd594a9bf7> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Modern rail–rail transshipment yards serve as hub nodes in railway networks and enable a rapid consolidation of containers among freight trains. The container transshipment is executed by parallel gantry cranes supported by a sorting system, where shuttle cars preposition containers to relieve the cranes from excessive movement along the spread of the yard. An important decision problem in this context is the scheduling of the gantry cranes, which is considerably complicated by the need to synchronize cranes and shuttle cars whenever container moves are executed via the sorting system. We formalize the resulting interdependent crane and shuttle car scheduling problem, introduce suited solution algorithms, and apply them in order to explore important managerial aspects. Our main findings in this regard are that the position of the sorter either in the middle of the tracks or at the outside has negligible impact on yard performance, while it is a challenging task to match the number of cranes with an appropriate fleet size of shuttles." .
<http://www.springernature.com/scigraph/things/articles/a8a4320021b5c610d4cb01cf4c5a5824> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Two-player zero-sum games of infinite duration and their quantitative versions are used in verification to model the interaction between a controller (Eve) and its environment (Adam). The question usually addressed is that of the existence (and computability) of a strategy for Eve that can maximize her payoff against any strategy of Adam. In this work, we are interested in strategies of Eve that minimize her regret, i.e. strategies that minimize the difference between her actual payoff and the payoff she could have achieved if she had known the strategy of Adam in advance. We give algorithms to compute the strategies of Eve that ensure minimal regret against an adversary whose choice of strategy is (1) unrestricted, (2) limited to positional strategies, or (3) limited to word strategies, and show that the two last cases have natural modelling applications. These results apply for quantitative games defined with the classical payoff functions $$\\mathsf {Inf}$$ Inf , $$\\mathsf {Sup}$$ Sup , $${\\mathsf {LimInf}}$$ LimInf , $$\\mathsf {LimSup}$$ LimSup , and mean-payoff. We also show that our notion of regret minimization in which Adam is limited to word strategies generalizes the notion of good for games introduced by Henzinger and Piterman, and is related to the notion of determinization by pruning due to Aminof, Kupferman and Lampert." .
<http://www.springernature.com/scigraph/things/articles/a858a392f0ac83591a2b70b70f969b7b> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract In order to improve the efficiency and quality of estimation of the technical condition and residual service life of technical devices, a special approach has been devised, based on informational support and the automation of preparation for this process and its execution. The methods, models, and means developed represent the methodology of inspection of technical devices with regard to industrial safety. Information technology has been developed, along with the Intelligent Software System that implements it, to automate the collection, storage, and processing of the information necessary to support decision-making in the estimation of technical conditions and residual service life, which constitutes the basis of industrial safety inspection." .
<http://www.springernature.com/scigraph/things/articles/6b144991cb77b78525e585043087afcc> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Collaborative ontology-engineering methods usually prescribe a set of processes, activities, stakeholders, and the roles each stakeholder plays in these activities. We, however, believe that (a) the stakeholder community of each ontology-engineering project is different, and (b) one can observe different types of user behavior. It may thus very well be that the prescribed set of stakeholder types and roles do not suffice. If one were able to identify these user behavior types, which we will call user profiles, one can compliment or revisit those predefined roles. For instance, those user profiles can be used to provide customized interfaces for optimizing activities in certain ontology-engineering projects. We present a method for discovering different user profiles based on the interactions users have with each other on a collaborative ontology-engineering environment. Our approach clusters users based on the types of interactions they perform, which are retrieved from datasets that were annotated with an interaction ontology—built on top of SIOC—that we have developed. We demonstrate our method using the database of two instances of the GOSPL ontology-engineering tool. The databases contain the interactions of two distinct ontology-engineering projects involving, respectively, 42 and 36 users. For each dataset, we discuss the findings by analyzing the different clusters. We found that we are able to discover different user profiles, indicating that the approach we have taken is viable, though more experiments are needed to validate the results and to discover patterns across ontology-engineering projects." .
<http://www.springernature.com/scigraph/things/articles/b0a75faaee282fcea33cb0cdca555b43> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract Among research opportunities in software engineering for cloud computing model, interoperability stands out. We found that the dynamic nature of cloud technologies and the battle for market domination make cloud applications locked-id, i.e, proprietary, non-portable and non-interoperable. In general context of cloud computing, interoperability goes beyond communication between systems like in other fields, it goes in direction of more dynamic, heterogeneous, complex and composed applications that take advantage of best features from different providers and services simultaneously. Interoperability in cloud constitutes a great challenge that must be overcome for that, in the future, software be more dynamic and improved. Objective: This paper aims at identifying how interoperability in cloud computing has been addressed in the existing literature, offering an up-to-date view of concepts relate to how to develop interoperable software that takes advantage of different cloud models. Thus, providing a basis for further research in the field and consolidating e better exploring existing concepts. Method: To fulfill this objective, we surveyed literature. We defined six research questions and conducted the study according to a protocol that included planning, and execution. Results: A first result of the review is that there is no well established definition for cloud interoperability. This study also identified cloud interoperability concepts (e.g., cloud brokers, multi-cloud and cloud federation), requirements for interoperable applications and existing cloud interoperability solutions, showing that these are either too specific for particular situations. Finally, the survey found no evaluation models for cloud interoperability solutions. We also present a discussion on the findings of this study. Conclusion: Since the study observed that there are no well-established cloud interoperability solutions yet, we conclude that the issues raised by lack of interoperability persist. Selecting one interoperable solution or even a cloud standard can free the system from the underlying providers, but it would still be locked into the selected particular solution." .
<http://www.springernature.com/scigraph/things/articles/5769653f677509d4ba49715d0aec58b5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract By simply describing a classic weakly hard real-time system’s performance with the number of tasks meeting or missing deadlines, the system’s real-time characteristics cannot be expressed accurately and its reliability cannot be established. The path real-time logic (RTL) is used to determine the reliability of real-time systems; though desirable, it cannot be used as a tool to configure an optimized real-time system. This paper introduces the notion of optimizing path RTL, where integer constants of arithmetic inequality in path RTL are replaced by integer constants or integer variables. With further modifications, optimizing path RTL can not only determine the reliability of a real-time system, but also be used to optimize the system. Furthermore, a unified framework for hard, soft and weakly hard real-time system is established based on optimizing path RTL. The process of transforming a weakly hard real-time system into this unified framework is demonstrated. Moreover, this work proposes and proves a theorem that if the directed ring of a constraint graph contains all elements of behaviour specification (SP) and only SP, then its value must not be greater than zero. This theorem can be used to quickly determine the reliability and safety of a real-time system. A case study is presented to show the validity and reliability of optimizing path RTL and the unified real-time system." .
<http://www.springernature.com/scigraph/things/articles/fbb7513812b368dc8f3ae87a7453006f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract The evaluation of unsupervised outlier detection algorithms is a constant challenge in data mining research. Little is known regarding the strengths and weaknesses of different standard outlier detection models, and the impact of parameter choices for these algorithms. The scarcity of appropriate benchmark datasets with ground truth annotation is a significant impediment to the evaluation of outlier methods. Even when labeled datasets are available, their suitability for the outlier detection task is typically unknown. Furthermore, the biases of commonly-used evaluation measures are not fully understood. It is thus difficult to ascertain the extent to which newly-proposed outlier detection methods improve over established methods. In this paper, we perform an extensive experimental study on the performance of a representative set of standard k nearest neighborhood-based methods for unsupervised outlier detection, across a wide variety of datasets prepared for this purpose. Based on the overall performance of the outlier detection methods, we provide a characterization of the datasets themselves, and discuss their suitability as outlier detection benchmark sets. We also examine the most commonly-used measures for comparing the performance of different methods, and suggest adaptations that are more suitable for the evaluation of outlier detection results." .
<http://www.springernature.com/scigraph/things/articles/dc050a99f25ecca29033d2a769c122fd> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract A cloud computing model gives cloud service providers the ability to retain multiple workloads on a single physical system. However, efficient resource provisioning and possible system fault management in the cloud can be a challenge. Early fault detection can provide room to recover from potential faults before impacting QoS. Current static techniques of fault management in computing systems are not satisfactory enough to safeguard the QoS requested by cloud users. Thus, new smart techniques are needed. This paper presents the ACCRS framework for cloud computing infrastructures to advance system’s utilization level, reduce cost and power consumption and fulfil SLAs. The ACCRS framework employs Autonomic Computing basic components which includes state monitoring, planning, decision making, fault predication, detection, and root cause analysis for recovery actions to improve system’s reliability, availability, and utilization level by scaling resources in response to changes in the cloud system state." .
<http://www.springernature.com/scigraph/things/articles/ac404d54ba1ecd451032fa45f662cccc> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract BackgroundVirtual Reality has been extensively used in a wide range of psychological experiments. In this study, we aimed to introduce NeuroVirtual 3D, a platform that clinicians could use free of charge. ImplementationThe platform we developed relies on NeuroVR software, but we extended it to apply to experiments. The software is available free of charge to researchers and clinical practitioners who can also use a large number of virtual environments and objects already developed. ResultsThe platform has been developed to connect to virtually every device ever produced by the means of Virtual-Reality Peripheral Network (VRPN) protocols; however, a number of these have already been included and tested in the platform. Among the available devices, the Microsoft Kinect low-cost sensor has already been configured for navigation through the virtual environments and to trigger specific action (sounds, videos, images, and the like) when a specific gesture is recognized, e.g., a step forward or an arm up. A task for neglect and a task for spatial abilities assessment were already implemented within the platform. Moreover, NeuroVirtual 3D integrated a TCP-IP-based module (bridge) to collect the data from virtually any existent biosensor (Thought-Technology, Zephyr and StarStim devices have already been included in the platform). It is able to record any psychophysiological signal during any experiment using also the computed indices in real time. ConclusionsNeuroVirtual 3D is able to record external and internal (e.g., coordinates, keys-press, timestamp) data with a millisecond precision, representing de facto the most advanced technology for experimental psychology using virtual environments available without the needs to program code." .
<http://www.springernature.com/scigraph/things/articles/fc98c64c48f5ce21450305708f276df4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract The Protocol for Lightweight Authentication of Identity (PLAID) aims at secure and private authentication between a smart card and a terminal. Originally developed by a unit of the Australian Department of Human Services for physical and logical access control, PLAID has now been standardized as an Australian standard AS-5185-2010 and is currently in the fast-track standardization process for ISO/IEC 25185-1. We present a cryptographic evaluation of PLAID. As well as reporting a number of undesirable cryptographic features of the protocol, we show that the privacy properties of PLAID are significantly weaker than claimed: using a variety of techniques, we can fingerprint and then later identify cards. These techniques involve a novel application of standard statistical and data analysis techniques in cryptography. We discuss potential countermeasures to our attacks and comment on our experiences with the standardization process of PLAID." .
<http://www.springernature.com/scigraph/things/articles/39990314ebc7296f9fa70b7f11d2523c> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract With the development of user-centered and environment sensing technology of 5G, large capacity and ubiquitous coverage and massive data collection and processing will bring new challenges in wireless networks. The cloud radio access network (C-RAN) has been envisioned to provide a new wireless architecture for reliable transmission of mobile big data. In this paper, we focus on network planning deployment issue based on the optical mixed diet (OMD) technology. Specifically, the ring and spur topology optimization (RSTO) problem under the C-RAN architecture is investigated. The RSTO problem is formulated as a generic integer linear program (ILP) which can optimally (i) minimize the network deploying cost; (ii) identify the locations of Remote Radio Units (RRUs) and optical add-drop multiplexers (OADMs); (iii) identify the association relations between RRUs and OADMs; and (iv) satisfy the mobile coverage requirements so as to allow the mobile big data to be transmitted through the RRUs. We propose a new heuristic algorithm based on C-RAN architecture. Numerical results validate the ILP formulation and show the performance benefits of the proposed algorithm in terms of efficiency and effectiveness against Gurobi, which is an ILP solver. In numerical studies, we also demonstrate the performance benefits of the incorporation of CoMP technology in terms of total deployment cost reduction." .
<http://www.springernature.com/scigraph/things/articles/8202cfb2fa54e5ae90cc9abfe5e63b4c> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract “Help bits\" are some limited trusted information about an instance or instances of a computational problem that may reduce the computational complexity of solving that instance or instances. In this paper, we study the value of help bits in the settings of randomized and average-case complexity. If k instances of a decision problem can be efficiently solved using $${\\ell < k}$$ ℓ<k help bits, then without access to help bits one can efficiently compute a k-bit vector that is not equal to the k-bit vector of solutions to the k instances. A decision problem with this property is called k-membership comparable. Amir, Beigel, and Gasarch (1990) show that for constant k, all k-membership comparable languages are in P/poly. We extend this result to the setting of randomized computation: We show that for k at most logarithmic, the decision problem is k-membership comparable if using $${\\ell}$$ ℓ help bits, k instances of the problem can be efficiently solved with probability greater than $${2^{\\ell-k}}$$ 2ℓ-k . The same conclusion holds if using less than $${k(1 - h(\\alpha))}$$ k(1-h(α)) help bits (where $${h(\\cdot)}$$ h(·) is the binary entropy function), we can efficiently solve $${1-\\alpha}$$ 1-α fraction of the instances correctly with non-vanishing probability. We note that when k is constant, k-membership comparability implies being in P/poly. Next we consider the setting of average-case complexity: Assume that we can solve k instances of a decision problem using some help bits whose entropy is less than k when the k instances are drawn independently from a particular distribution. Then we can efficiently solve an instance drawn from that distribution with probability better than 1/2. Finally, we show that in the case where k is super-logarithmic, assuming k-membership comparability of a decision problem, one cannot prove that the problem is in P/poly by a “relativizing\" proof technique. All previous known proofs in this area have been relativizing." .
<http://www.springernature.com/scigraph/things/articles/9ff225a7c31cab29a9fa69c0fb5d1990> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Recently, the incidence matrices of some block designs have been considered as the mother matrices of some quasi-cyclic (QC) low-density parity-check (LDPC) codes with maximum girth 20. In fact, the authors have introduced a deterministic algorithm which randomly, by a computer search, generates the slope vectors corresponding to the codes with desired girth, not greater than 20. In this paper, by rearranging the blocks of each block design, some slope vectors are proposed with an explicit method such that their corresponding QC LDPC codes have girth 8. Then, for each slope vector S, the lower bound Q(S) is found such that the QC LDPC codes with slope vector S and block size N, N ≥ Q, have girth at least 8." .
<http://www.springernature.com/scigraph/things/articles/ded50f19ad69cca1a08a9b03fde5b354> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract The wireless and dynamic nature of mobile ad hoc networks (MANET) render them more vulnerable to security attacks. However, providing a security mechanism implicitly has been a major challenge in such an ad-hoc environment. Certificate management plays an important role in securing an ad-hoc network. Certificate assignment, verification, and revocation complexity associated with the Public Key Infrastructure (PKI) framework is significantly large. Smaller the size of the network lesser will be the certificate management complexity. However, smaller the size, large will be the overall infrastructural cost, and also larger will be the overall redundant certificates due to multiple certificate assignment at the boundary regions, that in turn affects the prompt and accurate certificate revocation. By taking these conflicting requirements into consideration, we propose the trust-based hexagonal clustering for an efficient certificate management (THCM) scheme, to bear an absolutely protected MANET Disparate to the existing clustering techniques, we present a hexagonal geographic clustering model with Voronoi technique where trust is accomplished. In particular, to compete against attackers, we initiate a certificate management strategy in which certificate assignment, verification, and revocation are carried out efficiently. The performance of THCM is evaluated by both simulation and empirical analysis in terms of effectiveness of revocation scheme (with respect to revocation rate and time), security, and communication cost. Besides, we conduct a mathematical analysis of measuring the parameters obtained from the two platforms in multiple times. Relevant results demonstrate that our design is efficient to guarantee a secured mobile ad hoc network." .
<http://www.springernature.com/scigraph/things/articles/7f86b2902920c3e9a52d80e13229412a> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract In this paper, we study real hypersurfaces in complex Grassmannians of rank two. First, the nonexistence of mixed foliate real hypersurfaces is proven. With this result, we show that for Hopf hypersurfaces in complex Grassmannians of rank two, the Reeb principal curvature is constant along integral curves of the Reeb vector field. As a result the classification of contact real hypersurfaces is obtained. We also introduce the notion of q-umbilical real hypersurfaces in complex Grassmannians of rank two and obtain a classification of such real hypersurfaces." .
<http://www.springernature.com/scigraph/things/articles/f941e7211cb7dccc5ea04a8c5b645862> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract The Internet of things (IoT) is composed of a large number of end systems. Data gathered from these end systems are processed in the cloud environment. This paper delineates multi-tenancy as a prerequisite for enabling cost effective IoT solutions using any cloud platform. In the IoT world, a large number of end systems imply a large number of users who should have open access to specific subsets of data. As multi-tenancy includes sharing the same application instance, security is a key requirement when engineering new software as a service (SaaS) applications. This paper describes multi-tenant implementation approaches and inspects security aspects and data isolation. It proposes a solution for data layer scalability in order to achieve the desired performances. Furthermore, it proposes an SOA solution to provide a secure multi-tenant web service with scalable data layers. We demonstrate that the proposed approach results in some performance loss, which is not acceptable for performance critical applications but is acceptable for services developed for tenants themselves. We experimentally confirm our data scalability theory based on an actor model and developed a cost estimator. Finally, we conclude that application level multi-tenancy is necessary from a cost efficiency point of view in a scenario involving a large number of users. The solution was tested in a private cloud environment." .
<http://www.springernature.com/scigraph/things/articles/3754ede9b8e1a23d966b08cc5378f236> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Large-scale MapReduce clusters that routinely process big data bring challenges to the cloud computing. One of the key challenges is to reduce the response time of these MapReduce clusters by minimizing their makespans. It is observed that the order in which these jobs are executed can have a significant impact on their overall makespans and resource utilization. In this work, we consider a scheduling model for multiple MapReduce jobs. The goal is to design a job scheduler that minimizes the makespan of such a set of MapReduce jobs. We exploit classical Johnson model and propose a novel framework HScheduler, which combines features of both classical Johnson’s algorithm and MapReduce to minimize the makespan for both offline and online jobs. Our Offline HScheduler reaches the theoretical lower bound (optimum) and Online HScheduler is 2-competitive which is the best-known constant ratio for minimizing the makespan. Through extensive real data tests, we find that HScheduler has better performance than the best-known approach by 10.6–11.7 % on average for offline scheduling and 8–10 % on average for online scheduling. The HScheduler can be applied to improve responsive time, throughput and energy efficiency in cloud computing." .
<http://www.springernature.com/scigraph/things/articles/02a18b5fc577bcc525c599fbdd0362a5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract One difficulty in developing numerical methods for tsunami modeling is the fact that solutions contain time-varying regions where much higher resolution is required than elsewhere in the domain, particularly when tracking a tsunami propagating across the ocean. The open source GeoClaw software deals with this issue by using block-structured adaptive mesh refinement to selectively refine around propagating waves. For problems where only a target area of the total solution is of interest (e.g., one coastal community), a method that allows identifying and refining the grid only in regions that influence this target area would significantly reduce the computational cost of finding a solution. In this work, we show that solving the time-dependent adjoint equation and using a suitable inner product with the forward solution allows more precise refinement of the relevant waves. We present the adjoint methodology first in one space dimension for illustration and in a broad context since it could also be used in other adaptive software, and potentially for other tsunami applications beyond adaptive refinement. We then show how this adjoint method has been integrated into the adaptive mesh refinement strategy of the open source GeoClaw software and present tsunami modeling results showing that the accuracy of the solution is maintained and the computational time required is significantly reduced through the integration of the adjoint method into adaptive mesh refinement." .
<http://www.springernature.com/scigraph/things/articles/33c5c41fe246ac3af266bb6dc84f2f27> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "AbstractThe efficient visualization of dynamic network structures has become a dominant problem in many big data applications, such as large network analytics, traffic management, resource allocation graphs, logistics, social networks, and large document repositories. In this paper, we present a large-graph visualization system called ModuleGraph. ModuleGraph is a scalable representation of graph structures by treating a graph as a set of modules. The main objectives are: (1) to detect graph patterns in the visualization of large-graph data, and (2) to emphasize the interconnecting structures to detect potential interactions between local modules. Our first contribution is a hybrid modularity measure. This measure partitions the cohesion of the graph at various levels of details. We aggregate clusters of nodes and edges into several modules to reduce the overlap between graph components on a 2D display. Our second contribution is a k-clustering method that can flexibly detect the local patterns or substructures in modules. Patterns of modules are preserved by the ModuleGraph system to avoid information loss, while sub-graphs are clustered as a single node. Our experiments show that this method can efficiently support large-scale social and spatial network visualization. Graphical AbstractGraphical Abstract text" .
<http://www.springernature.com/scigraph/things/articles/a0ef3c2ebd143374d8c80a66dca02ce5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract In the literature, the notions of lumpability and time reversibility for large Markov chains have been widely used to efficiently study the functional and non-functional properties of computer systems. In this paper we explore the relations among different definitions of lumpability (strong, exact and strict) and the notion of time-reversed Markov chain. Specifically, we prove that an exact lumping induces a strong lumping on the reversed Markov chain and a strict lumping holds both for the forward and the reversed processes. Based on these results we introduce the class of $$\\lambda \\rho $$ λρ -reversible Markov chains which combines the notions of lumping and time reversibility modulo state renaming. We show that the class of autoreversible processes, previously introduced in Marin and Rossi (Proceedings of the IEEE 21st international symposium on modeling, analysis and simulation of computer and telecommunication systems MASCOTS, pp. 151–160, 2013), is strictly contained in the class of $$\\lambda \\rho $$ λρ -reversible chains." .
<http://www.springernature.com/scigraph/things/articles/c15b4e049975e1d3cd6e9db7afd424d5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract In this article, we present a new approach for breast thermogram image analysis by developing a fully automatic segmentation of right and left breast for asymmetry analysis, using shape features of the breast and Polynomial curve fitting. Segmentation results are validated with their respective Ground Truths. Histogram and grey level co-occurrence matrix-based texture features are extracted from the segmented images. Statistical test shows that features are highly significant in detection of breast cancer. We have obtained an accuracy of 90%, sensitivity of 87.5% and specificity of 92.5% for a set of eighty images with forty normal and forty abnormal using SVM RBF classifier." .
<http://www.springernature.com/scigraph/things/articles/dd1a9f5ec6f394ffd0fbb24207771ad0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract As web technology and (big) data continue to transform how we organize ourselves, scholarly research increasingly zooms in on the socio-material conditions of citizen participation and public engagement, the objects and devices that organize publics. Where social issues may often be the driver of such public engagement, increasingly the city and, more specifically, the neighborhood itself have become a central objects connecting their inhabitants through online networks and neighborhood events. Tools and apps for citizen participation then weave together neighborhood stakeholders (e.g. inhabitants, municipal parties and entrepreneurs). This paper zooms in on a sample of 40 such tools that enable and organize bottom-up citizen participation in the city of Amsterdam. Combining a theoretical framework with content analysis, digital methods and data visualization, this paper marks the starting point of a longitudinal analysis of online tools for the urban bottom-up movement." .
<http://www.springernature.com/scigraph/things/articles/95e80e6f2e17d810587c34037699ec7c> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Wireless capsule endoscopes are a growing research area because they can be easily swallowed by patients to capture images of the digestive system without pain. However, a drawback of current capsule endoscopes is that most use passive motion. To overcome this drawback, a maneuverable capsule endoscope (MCE) based on a gimbaled ducted-fan (GDF) system is proposed in this study. The system design, prototype development of the GDF system, and associated modeling and simulation are presented. The concept of the GDF is adopted from the thrust-vector control algorithm of a space shuttle. To prevent organ damage, the ducted fan, which generates and controls the thrust required for achieving maneuverability, is mounted on a gimbal structure. A scaled-up prototype of the GDF system was manufactured. The overall conceptual design of the MCE based on the GDF system is presented. A flow simulation and a three-dimensional path-following simulation are performed to evaluate the proposed MCE’s applicability. The mean terminal velocity of the 6:1 scaled-up MCE prototype was calculated from flow simulation to be 0.6047, 0.5941, and 0.9204 m/s for the three postures of the GDF system, respectively, which represented the three translational degrees of freedom. For the 1:1 scale prototype, the mean terminal velocity was calculated to be 0.1147, 0.1127, and 0.1746 m/s for the above three postures, respectively. The proposed MCE dynamic model follows the desired path profile when the Lyapunov stability-based path-following algorithm was applied to it. In summary, the terminal velocity achieved in this research is sufficient for maneuvering inside the stomach organ. The results show that the MCE concept could be used for detecting and diagnosing abnormalities in the digestive system." .
<http://www.springernature.com/scigraph/things/articles/b6956535e23ede507d54687889c36dde> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract New mass spectrometry instrumentation, particularly those with electron transfer dissociation fragmentation, has made the analysis of complex glycopeptide mixtures accessible. However, software tools need to be optimized for interpretation of this type of data. Glycopeptide identification is challenging due to the number of different peptide and sugar moieties that can be combined, leading to a large number of potential compositions to consider. In this manuscript, different strategies for reducing the number of peptides and glycopeptides considered in database searching are compared. Adaptation of the software Protein Prospector to support the use of a reference modification site database doubled the number of glycopeptide IDs. The potential of this as an improved analysis strategy is discussed. Graphical abstractThis manuscript compares the use of a restricted protein database based on a list of accession numbers of identified proteins to the use of a modification site database for intact glycopeptide analysis. It was found that the modification database is more effective for glycopeptide identification, particularly for larger glycopeptides" .
<http://www.springernature.com/scigraph/things/articles/c553e3cd5019db5b648629a60ca38032> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We present several sparsification lower and upper bounds for classic problems in graph theory and logic. For the problems 4-Coloring, (Directed) Hamiltonian Cycle, and (Connected) Dominating Set, we prove that there is no polynomial-time algorithm that reduces any n-vertex input to an equivalent instance, of an arbitrary problem, with bitsize $$O(n^{2-\\varepsilon })$$ O(n2-ε) for $$\\varepsilon > 0$$ ε>0 , unless $$\\mathsf {NP \\subseteq coNP/poly}$$ NP⊆coNP/poly and the polynomial-time hierarchy collapses. These results imply that existing linear-vertex kernels for k-Nonblocker and k-Max Leaf Spanning Tree (the parametric duals of (Connected) Dominating Set) cannot be improved to have $$O(k^{2-\\varepsilon })$$ O(k2-ε) edges, unless $$\\mathsf {NP \\subseteq coNP/poly}$$ NP⊆coNP/poly . We also present a positive result and exhibit a non-trivial sparsification algorithm for d-Not-All-Equal-SAT. We give an algorithm that reduces an n-variable input with clauses of size at most d to an equivalent input with $$O(n^{d-1})$$ O(nd-1) clauses, for any fixed d. Our algorithm is based on a linear-algebraic proof of Lovász that bounds the number of hyperedges in critically 3-chromatic d-uniform n-vertex hypergraphs by $$\\left( {\\begin{array}{c}n\\\\ d-1\\end{array}}\\right) $$ nd-1 . We show that our kernel is tight under the assumption that $$\\mathsf {NP} \\nsubseteq \\mathsf {coNP}/\\mathsf {poly}$$ NP⊈coNP/poly ." .
<http://www.springernature.com/scigraph/things/articles/495f7400b026ec53c465f1f89668c523> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The maritime transportation industry currently employs several mandatory and non-mandatory norms of organizational safety management. These safety norms are commonly included in integrated maritime safety management systems, which aim at developing, monitoring, controlling and improving the safety of all related shipping operations. These systems are typically evaluated by following key performance indicators, which enable defined measures for various safety management components. However, the identification of indicators addressing safety management requirements constitutes a complex and generally unsystematic process for safety managers in the maritime industry. This article proposes a new method to assess the guidelines available in maritime safety management norms. The proposed method is applied to assess the content of two maritime safety management norms. The aim of this assessment is to identify a set of maritime safety management indicators that can systematically measure the most relevant components of maritime safety management. The application of this method resulted in the identification of 53 key performance indicators for monitoring and reviewing 23 identified safety management components that are commonly integrated into the functioning of maritime safety management systems. The method proposed provides guidance to accurately capture the actual aim and function of the key performance indicators. Furthermore, the indicators and safety components obtained with this method can be adopted as the basis for a safety management system and/or for the analysis of a safety management system already established in the industry." .
<http://www.springernature.com/scigraph/things/articles/c08fcdc4d4d20c4cd43f09f0348a429f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "We focus on a cloud computing environment by using open source softwares such as OpenStack and Eucalyptus because of the unification management of data and low cost. A cloud computing is attracting attention as a network service to share the computing resources, that is, networks, servers, storage, applications, and services. We propose jump diffusion models based on stochastic differential equations in order to consider the interesting aspect of the provisioning process. Especially, the reliability and maintainability analysis tool for cloud computing is developed in this paper. Also, we analyze actual data to show numerical illustrations of application of the software analysis tool considering the characteristics of cloud computing." .
<http://www.springernature.com/scigraph/things/articles/4777a81bffda7ad54d980bf571c0a485> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The computation of the vertical attraction due to the topographic masses, the so-called Terrain Correction, is a fundamental step in geodetic and geophysical applications: it is required in high-precision geoid estimation by means of the remove–restore technique and it is used to isolate the gravitational effect of anomalous masses in geophysical exploration. The increasing resolution of recently developed digital terrain models, the increasing number of observation points due to extensive use of airborne gravimetry in geophysical exploration and the increasing accuracy of gravity data represents nowadays major issues for the terrain correction computation. Classical methods such as prism or point masses approximations are indeed too slow while Fourier based techniques are usually too approximate for the required accuracy. In this work a new software, called Gravity Terrain Effects (GTE), developed to guarantee high accuracy and fast computation of terrain corrections is presented. GTE has been thought expressly for geophysical applications allowing the computation not only of the effect of topographic and bathymetric masses but also those due to sedimentary layers or to the Earth crust-mantle discontinuity (the so-called Moho). In the present contribution, after recalling the main classical algorithms for the computation of the terrain correction we summarize the basic theory of the software and its practical implementation. Some tests to prove its performances are also described showing GTE capability to compute high accurate terrain corrections in a very short time: results obtained for a real airborne survey with GTE ranges between few hours and few minutes, according to the GTE profile used, with differences with respect to both planar and spherical computations (performed by prism and tesseroid respectively) of the order of 0.02 mGal even when using fastest profiles." .
<http://www.springernature.com/scigraph/things/articles/7e56a1a695b52b4d650bd13c8be93a62> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract The characteristics of MANET such as decentralization, dynamic topology and openness are susceptible for security threats. To overcome the security threats and to provide a reliable network to transmit packets, a need for trust based routing arises. Moreover, the trust along with energy requirement on ad hoc on demand distance vector have paved way for the development of the newly proposed algorithm named as refined trust and energy based ad hoc on demand distance vector algorithm which is the refined form of the existing trust and energy based ad hoc on demand distance vector algorithms and the classical AODV. In this paper, the refinement parameter is the trust. Moreover, Bayesian probability is introduced in this paper for trust management due to its ability to handle uncertainty for obtaining the refined form of Trust calculation. The proposed algorithm routes the packets from the source to destination not through the shortest route but by selecting a reliable route which consumes low energy and trustful for sending the packets. The simulation results obtained from this work show that the proposed algorithm performs better than the existing algorithms in terms of Trust based routing and energy efficiency." .
<http://www.springernature.com/scigraph/things/articles/bbbb9790d4b577a38bdf3afac642a570> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0803> "Abstract We developed a software package that incorporates integrated computational materials engineering principles to enable rapid development of new state-of-the-art atomistic potentials for metal behavior driven by ab initio and experimental data. The software features hand-tuning abilities as well as automated calibration of parameters to flexible target properties. Molecular statics simulations of target properties are done using a built-in LAMMPS library module to boost performance. The potential calibration method is flexible and intuitive allowing users to quickly develop potentials for complex alloys capturing a wide variety of behaviors. We demonstrate the validity of the software and technique by calibrating a new robust Mg potential." .
<http://www.springernature.com/scigraph/things/articles/abc5d54601164125ff1d0d08ca96fcb4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract An ordered set $${W = \\{w_1, . . . ,w_k\\} \\subseteqq V (G)}$$ W={w1,...,wk}⫅V(G) of vertices of G is called a resolving set or locating set for G if every vertex is uniquely determined by its vector of distances to the vertices in W. A resolving set of minimum cardinality is called a metric basis for G and this cardinality is the metric dimension or location number of G, denoted by $${\\beta(G)}$$ β(G) . The metric dimension of certain wheel related graphs has been studied recently in [22]. In this paper, we extend this study to infinite classes of convex polytopes generated by wheel related graphs. We prove that these infinite classes of convex polytopes generated by wheel related graphs have unbounded metric dimension. It is natural to ask for the characterization of graphs with unbounded metric dimension." .
<http://www.springernature.com/scigraph/things/articles/12d5e8606f3eee113f6e3aedcb43397c> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Declarative systems aim at solving tasks by running inference engines on a specification, to free their users from having to specify how a task should be tackled. In order to provide such functionality, declarative systems themselves apply complex reasoning techniques, and, as a consequence, the development of such systems can be laborious work. In this paper, we demonstrate that the declarative approach can be applied to develop such systems, by tackling the tasks solved inside a declarative system declaratively. In order to do this, a meta-level representation of those specifications is often required. Furthermore, by using the language of the system for the meta-level representation, it opens the door to bootstrapping: an inference engine can be improved using the inference it performs itself. One such declarative system is the IDP knowledge base system, based on the language $$\\rm FO(\\cdot)^{\\rm IDP}$$ FO(·)IDP , a rich extension of first-order logic. In this paper, we discuss how $$\\rm FO(\\cdot)^{\\rm IDP}$$ FO(·)IDP can support meta-level representations in general and which language constructs make those representations even more natural. Afterwards, we show how meta-$$\\rm FO(\\cdot)^{\\rm IDP}$$ FO(·)IDP can be applied to bootstrap its model expansion inference engine. We discuss the advantages of this approach: the resulting program is easier to understand, easier to maintain, and more flexible." .
<http://www.springernature.com/scigraph/things/articles/e8376e69e2e990e7fe4bae0ce9f749a0> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract The health monitoring component is the essential block, a pillar of several e-health systems. Plenty of health tracking applications and specific technologies such as smart devices, wearables, and data management systems are available. To be effective, promptly reacting to issues, a health monitoring service must ensure short delays in data sensing, collection, and processing activities. This is an open problem that distributed computing paradigms, such as Internet of Things (IoT), Cloud, and Edge computing, could address. The solution proposed in this paper is based on Stack4Things, an IoT-Cloud framework to manage edge nodes such as mobiles, smart objects, network devices, workstations, as a whole, a computing infrastructure allowing to provide resources on-demand, as services, to end users. Through Stack4Things facilities, the health tracking system can locate the closer computing resource to offload processing and thus reducing latency per the Edge computing paradigm." .
<http://www.springernature.com/scigraph/things/articles/74b8a87549603bbafe9f48b71b37a07b> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract With the rapid expansion of the human-centric ubiquitous environment, wireless sensor networks (WSN) will continue to be part of our everyday life and increase the amount and the type of data generated and transmitted by the WSN. As sensors become more essential in our daily life, the data from the sensors will become more private and need to be handled more sensitively. Therefore, the security of not only the data transmission between sensor nodes, but also the software system handling the data from sensor nodes will become more important. In this study, I concentrated on the security characteristics of the overall application systems in WSNs and derived the security attributes from the security requirements and standards of the existing network-based software systems. In the software development process, security must be considered throughout the whole process and, according to the applications the priority of each security attribute can be changed. I demonstrated the relative priority change in a web-based system and a WSN application system with an Analytic Hierarchy Process. The evaluation results showed that the difference of the relative priority of the security attributes in each sample system results not from the difference between the existing network-based system and the WSN but the type of the application. Therefore, the Multimedia security requirements and standards of the existing network-based software development process can be applied to the WSN application system through proper selection and modification." .
<http://www.springernature.com/scigraph/things/articles/fa65c3e683c21cb7849b01ceeb652494> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Cognitive Radio (CR) is a promising and potential technique to enable secondary users or unlicenced users to exploit the unused spectrum resources effectively possessed by primary users (PUs) or licenced users. The proven clustering approach is used to organize nodes in the network into logical groups to attain energy efficiency, network scalability, and stability for improving the sensing accuracy in CR through cooperative spectrum sensing. In this paper, a distributed dynamic load-balanced clustering algorithm is proposed. In this algorithm, each member in the cluster is to calculate the cooperative gain, residual energy, distance, and sensing cost from the neighboring clusters to perform the optimal decision. Each member in a cluster participates in selecting a cluster head through cooperative gain, and residual energy that minimise network energy consumption and enhances the channel sensing. First, we form the number of clusters using the Markov decision process model to reduce the energy consumption in a network. In this algorithm, CR users effectively utilize the PUs’ reporting time slots when PUs are not available. The simulation results reveal that the cluster convergence, energy efficiency, and accuracy of channel sensing increased considerably by using the proposed algorithm." .
<http://www.springernature.com/scigraph/things/articles/05a65a42b77bb3b9e79224b687d57afc> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract Simulations in neuroscience are performed on local servers or High Performance Computing (HPC) facilities. Recently, cloud computing has emerged as a potential computational platform for neuroscience simulation. In this paper we compare and contrast HPC and cloud resources for scientific computation, then report how we deployed NEURON, a widely used simulator of neuronal activity, in three clouds: Chameleon Cloud, a hybrid private academic cloud for cloud technology research based on the OpenStack software; Rackspace, a public commercial cloud, also based on OpenStack; and Amazon Elastic Cloud Computing, based on Amazon’s proprietary software. We describe the manual procedures and how to automate cloud operations. We describe extending our simulation automation software called NeuroManager (Stockton and Santamaria, Frontiers in Neuroinformatics, 2015), so that the user is capable of recruiting private cloud, public cloud, HPC, and local servers simultaneously with a simple common interface. We conclude by performing several studies in which we examine speedup, efficiency, total session time, and cost for sets of simulations of a published NEURON model." .
<http://www.springernature.com/scigraph/things/articles/031de535516b80553022a384d6600774> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The concept of symbolic sequences play important role in study of complex systems. In the work we are interested in ultrametric structure of the set of cyclic sequences naturally arising in theory of dynamical systems. Aimed at construction of analytic and numerical methods for investigation of clusters we introduce operator language on the space of symbolic sequences and propose an approach based on wavelet analysis for study of the cluster hierarchy. The analytic power of the approach is demonstrated by derivation of a formula for counting of two-fold de Bruijn sequences, the extension of the notion of de Bruijn sequences. Possible advantages of the developed description is also discussed in context of applied problem of construction of efficient DNA sequence assembly algorithms." .
<http://www.springernature.com/scigraph/things/articles/c7f9df0112dac1b242703497453704e6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The Weighted Vertex Integrity (wVI) problem takes as input an n-vertex graph G, a weight function $$w:V(G)\\rightarrow {\\mathbb {N}}$$ w:V(G)→N , and an integer p. The task is to decide if there exists a set $$X\\subseteq V(G)$$ X⊆V(G) such that the weight of X plus the weight of a heaviest component of $$G-X$$ G-X is at most p. Among other results, we prove that:(1)wVI is NP-complete on co-bipartite graphs, even if each vertex has weight 1;(2)wVI can be solved in $$O(p^{p+1}n)$$ O(pp+1n) time;(3)wVI admits a kernel with at most $$p^3$$ p3 vertices. Result (1) refutes a conjecture by Ray and Deogun (J Comb Math Comb Comput 16:65–73, 1994) and answers an open question by Ray et al. (Ars Comb 79:77–95, 2006). It also complements a result by Kratsch et al. (Discret Appl Math 77(3):259–270, 1997), stating that the unweighted version of the problem can be solved in polynomial time on co-comparability graphs of bounded dimension, provided that an intersection model of the input graph is given as part of the input. An instance of the Weighted Component Order Connectivity (wCOC) problem consists of an n-vertex graph G, a weight function $$w:V(G)\\rightarrow {\\mathbb {N}}$$ w:V(G)→N , and two integers k and $$\\ell $$ ℓ , and the task is to decide if there exists a set $$X\\subseteq V(G)$$ X⊆V(G) such that the weight of X is at most k and the weight of a heaviest component of $$G-X$$ G-X is at most $$\\ell $$ ℓ . In some sense, the wCOC problem can be seen as a refined version of the wVI problem. We obtain several classical and parameterized complexity results on the wCOC problem, uncovering interesting similarities and differences between wCOC and wVI. We prove, among other results, that:(4)wCOC can be solved in $$O(\\min \\{k,\\ell \\}\\cdot n^3)$$ O(min{k,ℓ}·n3) time on interval graphs, while the unweighted version can be solved in $$O(n^2)$$ O(n2) time on this graph class;(5)wCOC is W[1]-hard on split graphs when parameterized by k or by $$\\ell $$ ℓ ;(6)wCOC can be solved in $$2^{O(k\\log \\ell )} n$$ 2O(klogℓ)n time;(7)wCOC admits a kernel with at most $$k\\ell (k+\\ell )+k$$ kℓ(k+ℓ)+k vertices. We also show that result (6) is essentially tight by proving that wCOC cannot be solved in $$2^{o(k \\log \\ell )}n^{O(1)}$$ 2o(klogℓ)nO(1) time, even when restricted to split graphs, unless the Exponential Time Hypothesis fails." .
<http://www.springernature.com/scigraph/things/articles/a9b4c9dba06e665b7e7a1d7958c5584a> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We consider the problems of finding optimal identifying codes, (open) locating-dominating sets and resolving sets (denoted Identifying Code, (Open) Open Locating-Dominating Set and Metric Dimension) of an interval or a permutation graph. In these problems, one asks to distinguish all vertices of a graph by a subset of the vertices, using either the neighbourhood within the solution set or the distances to the solution vertices. Using a general reduction for this class of problems, we prove that the decision problems associated to these four notions are NP-complete, even for interval graphs of diameter 2 and permutation graphs of diameter 2. While Identifying Code and (Open) Locating-Dominating Set are trivially fixed-parameter-tractable when parameterized by solution size, it is known that in the same setting Metric Dimension is W[2]-hard. We show that for interval graphs, this parameterization of Metric Dimension is fixed-parameter-tractable." .
<http://www.springernature.com/scigraph/things/articles/d7cd700af284a9e12dc6d9a7402a48ed> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract This paper considers the finite-time stability and finite-time boundedness problems for switched neural networks subject to $$L_2$$ L2 -gain disturbances. Sufficient conditions for the switched neural networks to be finite-time stable and finite-time bounded are derived. These conditions are delay-dependent and are given in terms of linear matrix inequalities. Average dwell time of switching signals is also given such that switched neural networks are finite-time stable or finite-time bounded. By resorting to the average dwell time approach and Lyapunov–Krasovskii functional technology, some new delay-dependent criteria guaranteeing finite-time boundedness and stabilizability with $$L_2$$ L2 -gain analysis performance are developed. An illustrative example is given to demonstrate the effectiveness of the proposed state estimator." .
<http://www.springernature.com/scigraph/things/articles/868c5fbc05f4f9fdc127b6c86626e3d7> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We study the problem of determining the majority type in an arbitrary connected network, each vertex of which has initially two possible types. The vertices may later change into other types, out of a set of a few additional possible types, and can interact in pairs only if they share an edge. Any (population) protocol is required to stabilize in the initial majority. First we prove that there does not exist any population protocol that always computes majority in any interaction graph by using at most 3 types per vertex. However this does not rule out the existence of a protocol with 3 types per vertex that is correct with high probability (whp). To this end, we examine an elegant and very natural majority protocol with 3 types per vertex, introduced in Angluin et al. (Distrib. Computing 21(2):87–102, 2008), whose performance has been analyzed for the clique graph. In particular, we study the performance of this protocol in arbitrary networks, under the probabilistic scheduler. We prove that, if the initial assignement of types to vertices is random, the protocol of Angluin et al. (Distrib. Computing 21(2):87–102, 2008) converges to the initial majority with probability higher than the probability of converging to the initial minority. In contrast, we show that the resistance of the protocol to failure when the underlying graph is a clique causes the failure of the protocol in general graphs." .
<http://www.springernature.com/scigraph/things/articles/42ea8f2a97ca7f6f35ad6bb2602613c3> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Humanitarian supply chains involve many different entities, such as government, military, private, and non‐governmental organizations and individuals. Well‐coordinated interactions between entities can lead to synergies and improved humanitarian outcomes. Information technology (IT) tools can help facilitate collaboration, but cost and other barriers have limited their use. We document the use of an IT tool to improve last‐mile supply distribution and data management in one of many camps for internally displaced persons after the January 2010 earthquake in Haiti, and we describe other current uses of technology in camp management. Motivated by these examples and the interest among humanitarian organizations in expanding the use of such tools to facilitate coordination, we introduce a cooperative game theory model and explore insights about the conditions under which multi‐agency coordination is feasible and desirable. We also outline an agenda for future research in the area of technology‐enabled collaboration in the humanitarian sector." .
<http://www.springernature.com/scigraph/things/articles/2d8fb31dfa638f083af7fc0b72830fb5> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Data Security and speed is very important in many on line transaction applications. It is necessary to provide security to all the on line transaction which is done on wireless medium. Cryptography is a technique used to give protection to all the confidential data. In this paper an efficient AES cryptographic algorithm is proposed. To achieve high speed in AES algorithm an eight stage Parallel accessing technique is used in SubByte transformation S-box and an eight stage parallel computation is applied in MixColumn transformation round. The results show that AES architecture with eight stage parallelism introduced in SubByte transformation and MixColumn transformation achieves high throughput than the other architectures. In S-box eight stage parallelism gives delay of 1.013 ns and in MixColumn it gives 0.835 ns delay. Parallel processing is used AES algorithm is used to increase the throughput with the trade off of increase in area. Using the proposed architecture 58.764 Gbps throughput is achieved with the expense of 6568 slices usage when implemented on virtex5 architecture which is recorded as a higher throughput than other architectures in the literature." .
<http://www.springernature.com/scigraph/things/articles/47aa353bda05ee470ae0106830be5e4c> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Information systems are very crucial in today’s organizations, and hence the selection of the right system has become a very critical decision. As time has progressed, with new issues affecting the supply chain and the performance metrics being continually rewritten, the responsibility of the information systems has increased manifold. Nowadays, information systems are expected to perform a number of functions such as information security, big data handling, green supply chain and risk management and thus the basic problem of system selection is now more complex. Also, adding to the complexity is the fact that these new issues are interdependent and most of the times influence other issues in a variety of direct or indirect ways. This study addresses this problem by proposing a new model for information system selection by incorporating the latest trends in the supply chain. It also proposes an integrated methodology, to solve such a problem where interdependence between criteria exists. The advantages of this methodology over other existing techniques are delinking the evaluation of interdependent criteria weights from performance evaluation, flexibility of inputs, ability to handle vagueness and uncertainty in judgements. The methodology is illustrated using a numerical example." .
<http://www.springernature.com/scigraph/things/articles/9198b655ea707766a30014890d5c9f3d> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract An application for the recently introduced Google Project Tango Tablet Development Kit to assist visually impaired (VI) users in understanding their environmental context by identifying and locating multiple faces and objects in their vicinity in real-time is presented. CUDA-based GPU-accelerated algorithms would be utilized to detect and recognize faces and objects from the visual data, while the locations of these entities relative to the user would be estimated from the depth data acquired via the tablet. The interaction would be speech based with the user being offered several options for requesting information about the identities and/or relative locations of face and objects. The aim is to create a portable, affordable, power-efficient, standalone assistive application to increase the autonomy of VI users which can run in real time on the device itself." .
<http://www.springernature.com/scigraph/things/articles/59ed63ccfadbaac56613eeb1269d0d58> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The data contained within the electronic health record (EHR) is “big” from the standpoint of volume, velocity, and variety. These circumstances and the pervasive trend towards EHR adoption have sparked interest in applying big data predictive analytic techniques to EHR data. Acute kidney injury (AKI) is a condition well suited to prediction and risk forecasting; not only does the consensus definition for AKI allow temporal anchoring of events, but no treatments exist once AKI develops, underscoring the importance of early identification and prevention. The Acute Dialysis Quality Initiative (ADQI) convened a group of key opinion leaders and stakeholders to consider how best to approach AKI research and care in the “Big Data” era. This manuscript addresses the core elements of AKI risk prediction and outlines potential pathways and processes. We describe AKI prediction targets, feature selection, model development, and data display." .
<http://www.springernature.com/scigraph/things/articles/9b21bab62db8d173886922ccfa26ce0a> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Let $$P$$ P and $$Q$$ Q be two simple polygons in the plane of total complexity n, each of which can be decomposed into at most k convex parts. We present a $$(1-\\varepsilon )$$ (1-ε) -approximation algorithm, for finding the translation of $$Q$$ Q , which maximizes its area of overlap with $$P$$ P . Our algorithm runs in $$O\\left( {c n}\\right) $$ Ocn time, where c is a constant that depends only on k and $$\\varepsilon $$ ε . This suggests that for polygons that are “close” to being convex, the problem can be solved (approximately), in near linear time." .
<http://www.springernature.com/scigraph/things/articles/c2f12ab4883767db2f9f5c5175e8c2e9> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Automatic detection and recognition of traffic sign has been a topic of great interest in advanced driver assistance system. It enhances vehicle and driver safety by providing the condition and state of the road to the drivers. However, visual occlusion and ambiguities in the real-world scenario make the traffic sign recognition a challenging task. This paper presents an Automatic Traffic Sign Detection and Recognition (ATSDR) system, involving three modules: segmentation, detection, and recognition. Region of Interest (ROI) is extracted using multiple thresholding schemes with a novel environmental selection strategy. Then, the traffic sign detection is carried out using correlation computation between log-polar mapped inner regions and the reference template. Finally, recognition is performed using Support Vector Machine (SVM) classifier. Our proposed system achieved a recognition accuracy of 98.3 % and the experimental results demonstrates the robustness of traffic sign detection and recognition in real-world scenario." .
<http://www.springernature.com/scigraph/things/articles/985405bb89f960c5f578cfe6bd31c0ec> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "In this paper, we study the relationship between the fitted parameters in a Gaussian process (kriging) model and the complexity of the resulting response surface. This study is done for models with one response and two input variables. An analytical calculation of surface roughness is used as a measure of the complexity of the response surface fit by the Gaussian process model. Our findings indicate that the size of the fitted model parameters as measured across different fits and data sets do not give indication as to the complexity of the surface. We do, however, show that the magnitude of each of the parameters in a single fitted model gives indication about the amount of variability in the direction of that fitted parameter." .
<http://www.springernature.com/scigraph/things/articles/74b45b39ddcd3abc4e84574e65fd55ae> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Bat algorithm (BA) is a new approach designed by imitating bat’s behavior of searching and capturing preys. The existing results have demonstrated the effectiveness and efficiency in comparison with other heuristic algorithms such as genetic algorithms and particle swarm optimization. In this paper, we design a novel framework for bat algorithm named two-stage bat algorithm (TSBA) using a trade-off strategy which balances the relationship between exploration and exploitation at the most extent. Inspired by the multi-population methods (e.g., artificial bee colony), we not only concern some technologies to avoid premature inevitably encountered when using BA, but also use a trade-off strategy to improve the comprehensive search performance for optimization. Some typical test sets which consist of 27 benchmark functions are utilized in comparative experiment, and the simulation results in terms of convergence rate and accuracy illustrate that the TSBA has a competitive performance than other swarm intelligent optimization algorithms. In addition, the proposed algorithm will not lend to the tremendous increase in computing time and thus will be a powerful tool in practical applications." .
<http://www.springernature.com/scigraph/things/articles/eef6a4fe587b012ec7112279232daadd> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract Recent advances in medical treatment and emergency applications, the need of integrating wireless body area network (WBAN) with cloud computing can be motivated by providing useful and real time information about patients’ health state to the doctors and emergency staffs. WBAN is a set of body sensors carried by the patient to collect and transmit numerous health items to medical clouds via wireless and public communication channels. Therefore, a cloud-assisted WBAN facilitates response in case of emergency which can save patients’ lives. Since the patient’s data is sensitive and private, it is important to provide strong security and protection on the patient’s medical data over public and insecure communication channels. In this paper, we address the challenge of participant authentication in mobile emergency medical care systems for patients supervision and propose a secure cloud-assisted architecture for accessing and monitoring health items collected by WBAN. For ensuring a high level of security and providing a mutual authentication property, chaotic maps based authentication and key agreement mechanisms are designed according to the concept of Diffie-Hellman key exchange, which depends on the CMBDLP and CMBDHP problems. Security and performance analyses show how the proposed system guaranteed the patient privacy and the system confidentiality of sensitive medical data while preserving the low computation property in medical treatment and remote medical monitoring." .
<http://www.springernature.com/scigraph/things/articles/a58f228512e7d43fe27c2c982ea0ed2f> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0803> "Abstract The paper studies a lacquer production scheduling problem formulated as a resource constrained project scheduling problem with general temporal constraints (i.e., positive and negative time-lags). This real-world scheduling problem requires so-called take-give resources that are needed from the beginning of an activity to the completion of another activity of the production process. Furthermore, we consider sequence dependent changeover times on take-give resources. We formulate this problem by mixed integer linear programming and we suggest a parallel heuristic to solve the problem. This heuristic exploits a time symmetry mapping which allows an easy construction of a schedule in the backward time orientation. In the second part of the paper, it is proven that the time symmetry mapping is bijective and involutive even for the problem with general temporal constraints, changeover times, and take-give resources. The motivation to use this mapping is to improve the performance of the heuristic and to simplify its implementation. Finally, the performance of the heuristic algorithm is evaluated on a set of lacquer production benchmarks requiring take-give resources and on standard benchmarks for the resource constrained project scheduling problem with general temporal constraints where we found new better solutions in 16 and 12 instances out of 90 for UBO500 and UBO1000 respectively." .
<http://www.springernature.com/scigraph/things/articles/7c2b7f850c02600900fec5d753810fbf> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0803> "Abstract Software reuse can be defined as the process of creating software products from the existing ones rather than developing software from scratch. Thus, software reuse is normally proposed to increase software productivity and quality and leads to economic benefits. In this sense, the reuse of software requirements has received important attention because it provides a solid support to develop quality software through obtaining and reusing quality software requirements [i.e., software product line (SPL) approach used in large-sized software enterprises]. However, the small-sized enterprises—which represent up to 85 % of all software organizations in many countries around the world—cannot implement a SPL approach because it does not fit with the context, properties, and complexity of their software projects. Moreover, the software engineering community has not adequately explored a more proper approach in the context of small-sized software enterprises. The use of a software requirements catalog could be this proper approach. In this context, the aim of this paper was to introduce the requirements reuse model for software requirements catalog (RRMSRC). Also, a set of guidelines to perform the main activities defined for reusing functional requirements within small-sized software enterprises is provided. As evidence of its feasibility, RRMSRC has been used in an industrial context, and the obtained results and learned lessons are summarized." .
<http://www.springernature.com/scigraph/things/articles/2028c5f02fcd24bb7f1ba4424954cf42> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Fuzzy sets extend deterministic multi-criteria decision-making (MCDM) methods to deal with uncertainty and imprecision in decision making. Over the years, many generalizations have been proposed to the classical Fuzzy sets to deal with different kinds of imprecise and subjective data. One such generalization is Atanassov’s Intuitionistic Fuzzy Set (IFS) which is becoming increasingly popular in MCDM research. Together, the two notions of uncertainty modeling: ‘classical fuzzy set’ (Zadeh) and intuitionistic fuzzy set (Atanassov) have been utilized in many real-world MCDM applications spanning diverse disciplines. As IFS grows in popularity by the day, this paper conducts a literature survey to (1) compare the trend of publications of ‘classical fuzzy’ set theory and its generalized form, the intuitionistic fuzzy set (IFS) as used in MCDM methods from 2000 to 2015; (2) classify their contributions into three novel tracks of applications, hybrid, and extended approaches; (3) determine which MCDM method is the most used together with the two forms of fuzzy modeling; and (4) report on other measures such as leading authors and their country affiliations, yearly scholarly contributions, and the subject areas where most of the two fuzzy notions in MCDM approaches are applied. Finally, the study presents trends and directions as far as the applications of classical fuzzy set and intuitionistic fuzzy sets in MCDM are concerned." .
<http://www.springernature.com/scigraph/things/articles/fdd5c429c24228a55a136739eacb2984> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Distributed generalized assignment problem (D-GAP) is very popular in scalable multi-agent systems. However, existing algorithms are either not effective or efficient in large-scale or highly dynamic domains owing to limited communications and computational resources. In this paper, we present a novel approach named intelligent routing algorithm (IRA) to address this issue. In IRA, in order to reduce communication load, a decentralized model for agents is proposed to jointly search for optimized solutions. Moreover, due to the complexity of distributed generalized assignment problem (D-GAP) in a massive multi-agent system where agents cannot perform optimal search based on their local views, we propose a heuristic algorithm that can find an approximate optimized solution. By inferring knowledge from their previous communicated searches, agents are able to predict how to deploy future similar searches more efficiently. If an agent can solve some parts of D-GAP well, similar searches will be sent to it. By taking advantage of the accumulation effect to agents’ local knowledge, agents can independently make simple decisions with highly reliable performance and limited communication overheads. The simulation and the experimental results demonstrate the feasibility and efficiency of our algorithm." .
<http://www.springernature.com/scigraph/things/articles/7f6a5d7746e024a9a69fc4d9b8167578> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract In this paper, we consider the problem (denoted as EMDRT) of minimizing the earth mover’s distance between two sets of weighted points A and B in $${\\mathbb {R}}^{d}$$ Rd under rigid transformation. EMDRT is an important problem in both theory and applications and has received considerable attentions in recent years. Previous research on this problem has resulted in only constant factor approximations and it has been an open problem for a long time to achieve PTAS solution. In this paper, we present the first FPTAS algorithm for EMDRT. Our algorithm runs roughly in $$O((nm)^{d+2}(\\log nm)^{2d})$$ O((nm)d+2(lognm)2d) time (which is close to a lower bound on any PTAS for this problem), where n and m are the sizes of A and B, respectively. Our result is based on several new techniques, such as the Sequential Orthogonal Decomposition and Optimum Guided Base, and can be extended to several related problems, such as the problem of earth mover’s distance under similarity transformation and the alignment problem, to achieve FPTAS for each of them." .
<http://www.springernature.com/scigraph/things/articles/8e3c13b8e24b660e5ae8d310251cbb84> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract BackgroundLarge-scale sequencing experiments are complex and require a wide spectrum of computational tools to extract and interpret relevant biological information. This is especially true in projects where individual processing and integrated analysis of both small RNA and complementary RNA data is needed. Such studies would benefit from a computational workflow that is easy to implement and standardizes the processing and analysis of both sequenced data types. ResultsWe developed SePIA (Sequence Processing, Integration, and Analysis), a comprehensive small RNA and RNA workflow. It provides ready execution for over 20 commonly known RNA-seq tools on top of an established workflow engine and provides dynamic pipeline architecture to manage, individually analyze, and integrate both small RNA and RNA data. Implementation with Docker makes SePIA portable and easy to run. We demonstrate the workflow’s extensive utility with two case studies involving three breast cancer datasets. SePIA is straightforward to configure and organizes results into a perusable HTML report. Furthermore, the underlying pipeline engine supports computational resource management for optimal performance. ConclusionSePIA is an open-source workflow introducing standardized processing and analysis of RNA and small RNA data. SePIA’s modular design enables robust customization to a given experiment while maintaining overall workflow structure. It is available at http://anduril.org/sepia." .
<http://www.springernature.com/scigraph/things/articles/f1344b72bc44849b90a8e51b86d30083> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Telepresence robotic systems are proposed in different contexts and specifically in the area of social robotics for assisting older adults at home. Similarly to other robotic systems, such robots are often designed and then evaluated in laboratory settings for a limited period of time. Lab-based evaluations present limitations because they do not take into account the different challenges imposed by the fielding of robotic solutions into real contexts for longer periods. In order to perform long-term experiments in real ecological settings it is very important to define a structured approach to assess the impact of a prolonged and constant use of the telepresence robot. This paper proposes a methodology in the area of elderly people support, called MARTA, for M ultidimensional A ssessment of telepresence R obo T for older A dults. It introduces the main variables of interest as well as the instruments and administration timeline for assessing relevant changes that may occur over time. MARTA is also validated in a one year-long case study during which a telepresence robot, called Giraff, has been deployed and iteratively assessed. The paper also provides remarks on the technology readiness and suggestions for its improvements." .
<http://www.springernature.com/scigraph/things/articles/d2e09635f2b6e41769f14c6930857870> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The fastest known algorithms for computing the R* consensus tree of k rooted phylogenetic trees with n leaves each and identical leaf label sets run in $$O(n^{2} \\sqrt{\\log n})$$ O(n2logn) time when $$k = 2$$ k=2 (Jansson and Sung in Algorithmica 66(2):329–345, 2013) and $$O(k n^{3})$$ O(kn3) time when $$k \\ge 3$$ k≥3 (Bryant in Bioconsensus, volume 61 of DIMACS series in Discrete Mathematics and Theoretical Computer Science. American Mathematical Society, pp 163–184, 2003). This paper shows how to compute it in $$O(n^{2})$$ O(n2) time for $$k = 2, O(n^{2} \\log ^{4/3} n)$$ k=2,O(n2log4/3n) time for $$k = 3$$ k=3 , and $$O(n^{2} \\log ^{k+2} n)$$ O(n2logk+2n) time for unbounded k." .
<http://www.springernature.com/scigraph/things/articles/bb540d48770f50e20f3ba1536967cdd7> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The grouping of parts and machines into manufacturing cells with the objective to improve grouping efficacy is the prime focus of cell formation problem. This paper presents the hybridization of simulated annealing (SA) with genetic algorithm (GA), where exploration power of GA, to broaden the search space, is combined with the intensification power of SA. A certain percentage of best solution in each generation of GA is sent, for further intensification and trajectory search, to SA. In intensification phase (with SA), Boltzmann probability distribution functions are used to allow a downhill move, with variable temperature. Starting temperature is chosen to be a small value with rapid cooling rate to keep search in a narrow region. If same solution is repeated for a certain number of generations, then shake-off is given to escape local maxima. During this shake-off, the SA parameters are relaxed to broaden the search for best neighbourhood solution. The effectiveness of proposed hybrid heuristic algorithm is evaluated through 35 benchmark problems from the literature. The GA with intensification through SA along with shake-off performed well in terms of solution quality, i.e. produced 24 best results with overall mean of 66.20. The overall comparative study shows that the proposed approach not only achieves the best solutions consistently, with minimum computational time, but also improves the results of two problems (problems 29 and 33), reporting it for the first time." .
<http://www.springernature.com/scigraph/things/articles/9b62d75a66484d2539c327fa5f46a2e7> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract The paper proposes an efficient method for solving a one- norm equality constrained optimization problem. In fact, this kind of optimization problems is nonconvex. First, the problem is formulated as the least absolute shrinkage and selection operator (LASSO) optimization problem. Then, it is solved by iterative shrinkage algorithms such as the fast iterative shrinkage thresholding algorithm. Next, the solution of the LASSO optimization problem is employed for formulating the constraint of the corresponding least-squares constrained optimization problem. The solution of the least-squares constrained optimization problem is taken as a near globally optimal solution of the one-norm equality constrained optimization problem. The main advantage of this proposed method is that a solution with both lower one-norm constraint error and two-norm reconstruction error can be obtained compared to those of the LASSO problem, while the required computational power is significantly reduced compared to the full search approach. Computer numerical simulation results are illustrated." .
<http://www.springernature.com/scigraph/things/articles/b9643abb26e0aefab2aad231baf99861> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract Augmented Reality (AR)–based video telephony service can allow mobile users a better user experience (UX) since it allows participants to place and transmit augmented objects on video frames to a peer. However, there are quite a few AR-based mobile video communication models today, yet the existing models are limited and insufficient in supporting technical service such as real-time object detection, dynamic data selection, and discrimination between local data augmentation and remote data augmentation. This paper presents an enhanced AR–based mobile video telephony scheme, in which the object of interest can be dynamically combined with a video frame through real-time object detection, and users can immediately share their experience with their friend during a video call. In order to evaluate the effectiveness and feasibility of the proposed scheme, an application has been implemented on the mobile system and the computational time has been measured. Experimental results show that the proposed system can give customers better UX with small increase of computational time." .
<http://www.springernature.com/scigraph/things/articles/75259309d941bb001bd0a67576db5751> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Multi-label learning is an effective framework for learning with objects that have multiple semantic labels, and has been successfully applied into many real-world tasks. In contrast with traditional single-label learning, the cost of labeling a multi-label example is rather high, thus it becomes an important task to train an effectivemulti-label learning model with as few labeled examples as possible. Active learning, which actively selects the most valuable data to query their labels, is the most important approach to reduce labeling cost. In this paper, we propose a novel approach MADM for batch mode multi-label active learning. On one hand, MADM exploits representativeness and diversity in both the feature and label space by matching the distribution between labeled and unlabeled data. On the other hand, it tends to query predicted positive instances, which are expected to be more informative than negative ones. Experiments on benchmark datasets demonstrate that the proposed approach can reduce the labeling cost significantly." .
<http://www.springernature.com/scigraph/things/articles/f5d0697787a6e0730e1d5f67d6088e28> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0806> "Abstract The Information propagation process is one the main challenges in delay tolerant networks especially in vehicular ad hoc networks (VANETs). A cycle of information propagation in a time-varying vehicular speed situation starts with physical movement of the vehicles as a catch-up process and ends with multihop transmission through connected vehicles as a forwarding process. Based on these two alternating processes information propagation cyclically renews. In the literature of VANET information propagation speed (IPS) is formulated based on one propagation cycle. This motivated us to develop more a realistic analytical model which investigates the average IPS based on the number of renewal cycles that a piece of information needs to be delivered. Using this renewal process, unlike traditional models, the expected length and expected duration of renewal cycles are formulated mathematically and subsequent closed-form equations are proposed for average IPS. The accuracy of the proposed model is confirmed using simulation. The concluded results provide helpful insights towards designing new applications on VANETs." .
<http://www.springernature.com/scigraph/things/articles/7005c84580a254fa3fbe744417048be2> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract A graph is Hamiltonian if it contains a cycle passing through every vertex exactly once. A celebrated theorem of Dirac from 1952 asserts that every graph on n≥3 vertices with minimum degree at least n/2 is Hamiltonian. We refer to such graphs as Dirac graphs. In this paper we obtain the following strengthening of this result. Given a graph G=(V,E), an incompatibility system F over G is a family F = {F v } v∈V such that for every v∈V, the set F v is a family of unordered pairs F v ⊆ {{e,e′}}: e ≠ e′ ∈ E,e ∩ e′ = {v}}. An incompatibility system is Δ-bounded if for every vertex v and an edge e incident to v, there are at most Δ pairs in F v containing e. We say that a cycle C in G is compatible with F if every pair of incident edges e,e′ of C satisfies {e,e′}∉F v , where v=e ∩ e′. This notion is partly motivated by a concept of transition systems defined by Kotzig in 1968, and can be viewed as a quantitative measure of robustness of graph properties. We prove that there is a constant μ>0 such that for every μn-bounded incompatibility system F over a Dirac graph G, there exists a Hamilton cycle compatible with F. This settles in a very strong form a conjecture of Häggkvist from 1988." .
<http://www.springernature.com/scigraph/things/articles/c4faf7602084b94f3ebf8bafbd6722e6> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0803> "Abstract BackgroundThe importance of quality assurance in the software development process cannot be overemphasized because its adoption results in high reliability and easy maintenance of the software system and other software products. Software quality assurance includes different activities such as quality control, quality management, quality standards, quality planning, process standardization and improvement amongst others. The aim of this work is to further investigate the software quality assurance practices of practitioners in Nigeria. While our previous work covered areas on quality planning, adherence to standardized processes and the inherent challenges, this work has been extended to include quality control, software process improvement and international quality standard organization membership. It also makes comparison based on a similar study carried out in Turkey. The goal is to generate more robust findings that can properly support decision making by the software community. The qualitative research approach, specifically, the use of questionnaire research instruments was applied to acquire data from software practitioners. ResultsIn addition to the previous results, it was observed that quality assurance practices are quite neglected and this can be the cause of low patronage. Moreover, software practitioners are neither aware of international standards organizations or the required process improvement techniques; as such their claimed standards are not aligned to those of accredited bodies, and are only limited to their local experience and knowledge, which makes it questionable. The comparison with Turkey also yielded similar findings, making the results typical of developing countries. The research instrument used was tested for internal consistency using the Cronbach’s alpha, and it was proved reliable. ConclusionFor the software industry in developing countries to grow strong and be a viable source of external revenue, software assurance practices have to be taken seriously because its effect is evident in the final product. Moreover, quality frameworks and tools which require minimum time and cost are highly needed in these countries." .
<http://www.springernature.com/scigraph/things/articles/4740ff6bc408709955a912e81314ae94> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "This work sheds important light on how the initial level of visibility and limited resource might affect the evolution of the players’ strategies under different network structure. We perform the prisoner’s dilemma game in the lattice network and the scale-free network, the simulation results indicate that the average density of death in lattice network decreases with the increases of the initial proportion of visibility. However, the contrary phenomenon is observed in the scale-free network. Further results reflect that the individuals’ payoff in lattice network is significantly larger than the one in the scale-free network. In the lattice network, the visibility individuals could earn much more than the invisibility one. However, the difference is not apparent in the scale-free network. We also find that a high Successful-Defection-Payoff (SDB) and a rich natural environment have relatively larger deleterious cooperation effects. A high SDB is beneficial to raising the level of visibility in the heterogeneous network, however, that has adverse visibility consequences in homogeneous network. Our result reveals that players are more likely to cooperate voluntarily under homogeneous network structure." .
<http://www.springernature.com/scigraph/things/articles/6028a02f9ecbd707abd00a7cf3649fbe> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0804> "Abstract This paper examines various methods encompassing the authentication of users in accessing Electronic Medical Records (EMRs). From a methodological perspective, multiple authentication methods have been researched from both a desktop and mobile accessibility perspective. Each method is investigated at a high level, along with comparative analyses, as well as real world examples. The projected outcome of this examination is a better understanding of the sophistication required in protecting the vital privacy constraints of an individual’s Protected Health Information (PHI). In understanding the implications of protecting healthcare data in today’s technological world, the scope of this paper is to grasp an overview of confidentiality as it pertains to information security. In addressing this topic, a high level overview of the three goals of information security are examined; in particular, the goal of confidentiality is the primary focus. Expanding upon the goal of confidentiality, healthcare accessibility legal aspects are considered, with a focus upon the Health Insurance Portability and Accountability Act of 1996 (HIPAA). With the primary focus of this examination being access to EMRs, the paper will consider two types of accessibility of concern: access from a physician, or group of physicians; and access from an individual patient." .
<http://www.springernature.com/scigraph/things/articles/fffe4f3a3f83afea89f3dc8775791478> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We propose a solution based on networks of picture processors to the problem of picture pattern matching. The network solving the problem can be informally described as follows: it consists of two subnetworks, one of them extracts at each step, simultaneously, all subpictures of identical (progressively decreasing) size from the input picture and sends them to the other subnetwork which checks whether any of the received pictures is identical to the pattern. We present an efficient solution based on networks with evolutionary processors only, for patterns with at most three rows or columns. Afterward, we present a solution based on networks containing both evolutionary and hiding processors running in $${\\mathcal {O}}(n+m+kl)$$ O(n+m+kl) computational (processing and communication) steps, for any size (n, m) of the input picture and (k, l) of the pattern. From the proofs of these results, we infer that any (k, l)-local language with $$1\\le k\\le 3$$ 1≤k≤3 can be decided in $${\\mathcal {O}}(n+m+l)$$ O(n+m+l) computational steps by networks with evolutionary processors only, while any (k, l)-local language with arbitrary k, l can be decided in $${\\mathcal {O}}(n+m+kl)$$ O(n+m+kl) computational steps by networks containing both evolutionary and hiding processors." .
<http://www.springernature.com/scigraph/things/articles/9704c38be00ccaf8b6c87a93457d6156> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "Abstract Robot technology is expected to become applicable to missions on rough terrain, such as search and rescue activities, planetary exploration, and environmental investigations. The robots in such environments need high mobility against extremely rough terrain. Tracked vehicles are effective against rough terrain because the contact pressure of the vehicle can be distributed more widely. However, it is difficult for a typical tracked vehicle composed of a pair of tracks to significantly change its length/width ratio from 1:1 because of its turning property. To improve mobility, serpentine tracked robots are designed to move on rough terrain. We proposed a flexible mono-tread mobile track (FMT). An FMT is a mono-track system, and its body has a vertebral structure composed of rigid segments (called vertebrae) connected by flexible segments (called intervertebral disks). An FMT can flex more widely in three dimensions, thereby turning and climbing over obstacles. This feature is an advantage over previous mono-track systems. Prototypes of FMTs called RT02-WORMY and RT03-LIPAN have been developed and validated the system’s mobility. The body of an FMT, except for both sidewalls, is completely surrounded by only a track belt. However, the prototypes have a problem with interference and derailing in the track belt that is caused by flexion and the surface profile of the ground. The objective of this study, therefore, is to develop a new prototype of an FMT called RT04-NAGA. NAGA adopts a combination of one-degree-of-freedom (DoF) rotational joints instead of flexible components and an accurately designed guide rail system to prevent the belt from interfering with operation or derailing. To validate the performance of the prototype, we conducted the fundamental tests of the prototype, such as energy consumption; mobility with a ditch, a vertical wall, a stairway and a spiral stairway; and the standard tests following the regulations of the National Institute of Standards and Technology (NIST)." .
<http://www.springernature.com/scigraph/things/articles/e5b125ec2c75841e4dfa05b5591fd103> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0805> "Abstract Virtualization plays a vital role in the construction of cloud computing. However, various vulnerabilities are existing in current virtualization implementations, and thus there are various security challenges at virtualization layer. In this paper, we investigate different vulnerabilities and attacks at virtualization layer of cloud computing. We examine the proposals of cloud intrusion detection system (IDS) and intrusion detection and prevention system frameworks. We recommend the cloud IDS requirements and research scope to achieve desired level of security at virtualization layer of cloud computing." .
<http://www.springernature.com/scigraph/things/articles/6a91494b1f918566de86fe1e35c7f8b4> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0801> "We present a pipeline for the visual localization and classification of agricultural pest insects by computing a saliency map and applying deep convolutional neural network (DCNN) learning. First, we used a global contrast region-based approach to compute a saliency map for localizing pest insect objects. Bounding squares containing targets were then extracted, resized to a fixed size, and used to construct a large standard database called Pest ID. This database was then utilized for self-learning of local image features which were, in turn, used for classification by DCNN. DCNN learning optimized the critical parameters, including size, number and convolutional stride of local receptive fields, dropout ratio and the final loss function. To demonstrate the practical utility of using DCNN, we explored different architectures by shrinking depth and width, and found effective sizes that can act as alternatives for practical applications. On the test set of paddy field images, our architectures achieved a mean Accuracy Precision (mAP) of 0.951, a significant improvement over previous methods." .
<http://www.springernature.com/scigraph/things/articles/44e577bb8b56692a5f3425e29810f9ca> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract Efficient symbolic and explicit-state model checking approaches have been developed for the verification of linear time temporal logic (LTL) properties. Several attempts have been made to combine the advantages of the various algorithms. Model checking LTL properties usually poses two challenges: one must compute the synchronous product of the state space and the automaton model of the desired property, then look for counterexamples that is reduced to finding strongly connected components (SCCs) in the state space of the product. In case of concurrent systems, where the phenomenon of state space explosion often prevents the successful verification, the so-called saturation algorithm has proved its efficiency in state space exploration. This paper proposes a new approach that leverages the saturation algorithm both as an iteration strategy constructing the product directly, as well as in a new fixed-point computation algorithm to find strongly connected components on-the-fly by incrementally processing the components of the model. Complementing the search for SCCs, explicit techniques and component-wise abstractions are used to prove the absence of counterexamples. The resulting on-the-fly, incremental LTL model checking algorithm proved to scale well with the size of models, as the evaluation on models of the Model Checking Contest suggests." .
<http://www.springernature.com/scigraph/things/articles/4eb82c0e31fdd089c2109cd3b98d831e> <http://purl.org/au-research/vocabulary/anzsrc-for/2008/0802> "Abstract We study the linear-time model checking problem for boolean concurrent programs with recursive procedure calls. While sequential recursive programs are usually modeled as pushdown automata, concurrent recursive programs involve several processes and can be naturally abstracted as pushdown automata with multiple stacks. Their behavior can be understood as words with multiple nesting relations, each relation connecting a procedure call with its corresponding return. To reason about multiply nested words, we consider the class of all temporal logics as defined in the book by Gabbay, Hodkinson, and Reynolds (18). The unifying feature of these temporal logics is that their modalities are defined in monadic second-order (MSO) logic. In particular, this captures numerous temporal logics over concurrent and/or recursive programs that have been defined so far. Since the general model checking problem is undecidable, we restrict attention to phase bounded executions as proposed by La Torre, Madhusudan, and Parlato (LICS 24). While the MSO model checking problem in this case is non-elementary, our main result states that the model checking (and satisfiability) problem for all MSO-definable temporal logics is decidable in elementary time. More precisely, it is solvable in time exponential in the formula and (n+2)-fold exponential in the number of phases where n is the maximal level of the MSO modalities in the monadic quantifier alternation hierarchy (which is a vast improvement over the conference version of this paper from LICS 2013 where the space was also (n+2)-fold exponential in the size of the temporal formula). We complement this result and provide, for each level n, a temporal logic whose model checking problem is n-EXPSPACE-hard." .
